{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# def sinusoidal_objectives(X, variation_factor):\n",
    "#     objective1 = torch.sum(torch.sin(X * 2 * torch.pi) + variation_factor * torch.cos(X * 2 * torch.pi), dim=1)\n",
    "#     objective2 = torch.sum(torch.sin(X * 4 * torch.pi + variation_factor) - variation_factor * torch.cos(X * 4 * torch.pi), dim=1)\n",
    "#     return objective1, objective2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# # Define the bounds tensor (2 x d) for d=3 input dimensions\n",
    "# bounds = torch.tensor([[0.0, 0.0, 0.0],  # Lower bounds for each dimension\n",
    "#                        [1.0, 1.0, 1.0]]) # Upper bounds for each dimension\n",
    "\n",
    "# def generate_single_dataset(bounds, num_samples, variation_factor):\n",
    "#     # Generate random input data within the specified bounds\n",
    "#     X = bounds[0] + (bounds[1] - bounds[0]) * torch.rand(num_samples, bounds.shape[1])\n",
    "    \n",
    "#     # Calculate the objective values using the sinusoidal_objectives function\n",
    "#     objective1, objective2 = sinusoidal_objectives(X, variation_factor)\n",
    "    \n",
    "#     # Combine the objectives to form the output dataset (train_Y)\n",
    "#     Y = torch.stack([objective1, objective2], dim=1)\n",
    "    \n",
    "#     return X, Y\n",
    "\n",
    "# # Number of samples for each dataset\n",
    "# num_samples_1 = 50\n",
    "# num_samples_2 = 100\n",
    "# num_samples_3 = 5\n",
    "\n",
    "# # Different variation factors for each dataset\n",
    "# variation_factor_1 = 0.5\n",
    "# variation_factor_2 = 1.0\n",
    "# variation_factor_3 = 1.5\n",
    "\n",
    "# # Generate the three datasets\n",
    "# train_X1, train_Y1 = generate_single_dataset(bounds, num_samples_1, variation_factor_1)\n",
    "# train_X2, train_Y2 = generate_single_dataset(bounds, num_samples_2, variation_factor_2)\n",
    "# train_X3, train_Y3 = generate_single_dataset(bounds, num_samples_3, variation_factor_3)\n",
    "\n",
    "# # Now you have three separate datasets:\n",
    "# # - train_X1, train_Y1: First dataset with `num_samples_1` points\n",
    "# # - train_X2, train_Y2: Second dataset with `num_samples_2` points\n",
    "# # - train_X3, train_Y3: Third dataset with `num_samples_3` points\n",
    "\n",
    "# print(\"First dataset:\")\n",
    "# print(train_X1.shape, train_Y1.shape)\n",
    "\n",
    "# print(\"Second dataset:\")\n",
    "# print(train_X2.shape, train_Y2.shape)\n",
    "\n",
    "# print(\"Third dataset:\")\n",
    "# print(train_X3.shape, train_Y3.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# # Assume train_X1, train_X2, train_X3, train_Y1, train_Y2, train_Y3 are already defined\n",
    "\n",
    "# def prepare_multitask_data(train_X_list, train_Y_list):\n",
    "#     all_X = []\n",
    "#     all_Y1 = []\n",
    "#     all_Y2 = []\n",
    "    \n",
    "#     for i, (X, Y) in enumerate(zip(train_X_list, train_Y_list)):\n",
    "#         # Add task feature as the last column in train_X\n",
    "#         task_feature = torch.full((X.shape[0], 1), i, dtype=X.dtype)\n",
    "#         X_augmented = torch.cat([X, task_feature], dim=1)\n",
    "#         all_X.append(X_augmented)\n",
    "        \n",
    "#         # Split train_Y into two columns and store separately\n",
    "#         all_Y1.append(Y[:, 0:1])  # Objective 1\n",
    "#         all_Y2.append(Y[:, 1:2])  # Objective 2\n",
    "    \n",
    "#     # Concatenate all data across datasets\n",
    "#     combined_X = torch.cat(all_X, dim=0)\n",
    "#     combined_Y1 = torch.cat(all_Y1, dim=0)\n",
    "#     combined_Y2 = torch.cat(all_Y2, dim=0)\n",
    "    \n",
    "#     return combined_X, combined_Y1, combined_Y2\n",
    "\n",
    "# # Prepare data for two multi-task GP models\n",
    "# train_X_list = [train_X1, train_X2, train_X3]\n",
    "# train_Y_list = [train_Y1, train_Y2, train_Y3]\n",
    "\n",
    "# # Call the function to prepare the data\n",
    "# combined_X, combined_Y1, combined_Y2 = prepare_multitask_data(train_X_list, train_Y_list)\n",
    "\n",
    "# # Now combined_X is your input tensor, and combined_Y1, combined_Y2 are the target tensors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEW NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "def generate_car_crash_synthetic_data(outputs, variation_factor):\n",
    "        '''\n",
    "        Generate synthetic data for the vehicle safety design function.\n",
    "        Variation factor is used to introduce noise to the data. It is a factor that is multiplied with the coefficients of the function.\n",
    "        '''\n",
    "        def evaluate_true(X: Tensor, coeffs) -> Tensor:\n",
    "            X1, X2, X3, X4, X5 = torch.split(X, 1, -1)\n",
    "            f1 = (\n",
    "                coeffs[0] \n",
    "                + coeffs[1] * X1\n",
    "                + coeffs[2] * X2\n",
    "                + coeffs[3] * X3\n",
    "                + coeffs[4] * X4\n",
    "                + coeffs[5] * X5\n",
    "            )\n",
    "            f2 = (\n",
    "                coeffs[6]\n",
    "                + coeffs[7] * X1\n",
    "                - coeffs[8] * X2\n",
    "                + coeffs[9] * X3\n",
    "                + coeffs[10] * X4\n",
    "                - coeffs[11] * X1 * X4\n",
    "                + coeffs[12] * X1 * X5\n",
    "                + coeffs[13] * X2 * X4\n",
    "                - coeffs[14] * X1.pow(2)\n",
    "                - coeffs[15] * X3.pow(2)\n",
    "                + coeffs[16] * X4.pow(2)\n",
    "            )\n",
    "            f3 = (\n",
    "                coeffs[17]\n",
    "                + coeffs[18] * X1\n",
    "                + coeffs[19] * X2\n",
    "                + coeffs[20] * X3\n",
    "                - coeffs[21] * X1 * X2\n",
    "                + coeffs[22] * X2 * X3\n",
    "                - coeffs[23] * X2 * X4\n",
    "                - coeffs[24] * X3 * X4\n",
    "                - coeffs[25] * X3 * X5\n",
    "                - coeffs[26] * X2.pow(2)\n",
    "                + coeffs[27] * X4.pow(2)\n",
    "            )\n",
    "            f_X = torch.cat([f1, f2, f3], dim=-1)\n",
    "            return f_X\n",
    "\n",
    "        base_coeffs = [\n",
    "            1640.2823, 2.3573285, 2.3220035, 4.5688768, 7.7213633, 4.4559504,\n",
    "            6.5856, 1.15, 1.0427, 0.9738, 0.8364, 0.3695, 0.0861, 0.3628, 0.1106,\n",
    "            0.3437, 0.1764, -0.0551, 0.0181, 0.1024, 0.0421, 0.0073, 0.024,\n",
    "            0.0118, 0.0204, 0.008, 0.0241, 0.0109\n",
    "        ]\n",
    "        \n",
    "        # Apply variation to coefficients\n",
    "        varied_coeffs = [coeff * (1 + variation_factor) for coeff in base_coeffs]\n",
    "        \n",
    "        outputs = evaluate_true(outputs, varied_coeffs)\n",
    "        expected_output_shape = 3\n",
    "\n",
    "        outputs = -outputs \n",
    "\n",
    "        return outputs, expected_output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First dataset shapes:\n",
      "torch.Size([50, 5]) torch.Size([50, 3])\n",
      "Second dataset shapes:\n",
      "torch.Size([100, 5]) torch.Size([100, 3])\n",
      "Third dataset shapes:\n",
      "torch.Size([1, 5]) torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define the bounds tensor (2 x d) for d=5 input dimensions\n",
    "bounds = torch.tensor([[1.0, 1.0, 1.0, 1.0, 1.0],  # Lower bounds for each dimension\n",
    "                       [3.0, 3.0, 3.0, 3.0, 3.0]]) # Upper bounds for each dimension\n",
    "\n",
    "def generate_synthetic_dataset(bounds, num_samples, variation_factor):\n",
    "    # Generate random input data within the specified bounds\n",
    "    X = bounds[0] + (bounds[1] - bounds[0]) * torch.rand(num_samples, bounds.shape[1])\n",
    "    \n",
    "    # Generate synthetic outputs using the provided function\n",
    "    outputs, expected_output_shape = generate_car_crash_synthetic_data(X, variation_factor)\n",
    "    \n",
    "    return X, outputs\n",
    "\n",
    "# Example number of samples for each dataset\n",
    "num_samples_1 = 50\n",
    "num_samples_2 = 100\n",
    "num_samples_3 = 1\n",
    "\n",
    "# Different variation factors for each dataset\n",
    "variation_factor_1 = 0.1\n",
    "variation_factor_2 = 0.2\n",
    "variation_factor_3 = 0.0\n",
    "\n",
    "# Generate the three datasets\n",
    "train_X1, train_Y1 = generate_synthetic_dataset(bounds, num_samples_1, variation_factor_1)\n",
    "train_X2, train_Y2 = generate_synthetic_dataset(bounds, num_samples_2, variation_factor_2)\n",
    "train_X3, train_Y3 = generate_synthetic_dataset(bounds, num_samples_3, variation_factor_3)\n",
    "\n",
    "# Now you have three separate datasets:\n",
    "# - train_X1, train_Y1: First dataset with `num_samples_1` points\n",
    "# - train_X2, train_Y2: Second dataset with `num_samples_2` points\n",
    "# - train_X3, train_Y3: Third dataset with `num_samples_3` points\n",
    "\n",
    "print(\"First dataset shapes:\")\n",
    "print(train_X1.shape, train_Y1.shape)\n",
    "\n",
    "print(\"Second dataset shapes:\")\n",
    "print(train_X2.shape, train_Y2.shape)\n",
    "\n",
    "print(\"Third dataset shapes:\")\n",
    "print(train_X3.shape, train_Y3.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.8623e+03, -1.1617e+01, -1.5922e-01],\n",
      "        [-1.8447e+03, -8.8363e+00, -2.2371e-01],\n",
      "        [-1.8574e+03, -1.1901e+01, -1.2755e-01],\n",
      "        [-1.8566e+03, -1.2201e+01, -9.8456e-02],\n",
      "        [-1.8404e+03, -9.5732e+00, -1.6346e-01],\n",
      "        [-1.8490e+03, -1.1651e+01, -9.2886e-02],\n",
      "        [-1.8530e+03, -1.1485e+01, -9.9348e-02],\n",
      "        [-1.8532e+03, -1.1167e+01, -1.4426e-01],\n",
      "        [-1.8473e+03, -9.5117e+00, -1.7538e-01],\n",
      "        [-1.8531e+03, -1.1727e+01, -8.4022e-02],\n",
      "        [-1.8519e+03, -1.0317e+01, -1.6875e-01],\n",
      "        [-1.8487e+03, -1.1069e+01, -1.1899e-01],\n",
      "        [-1.8443e+03, -9.9833e+00, -1.0182e-01],\n",
      "        [-1.8466e+03, -9.5695e+00, -1.1908e-01],\n",
      "        [-1.8538e+03, -1.1255e+01, -9.3466e-02],\n",
      "        [-1.8432e+03, -9.3707e+00, -9.4814e-02],\n",
      "        [-1.8520e+03, -1.1787e+01, -1.0707e-01],\n",
      "        [-1.8583e+03, -1.0796e+01, -1.8041e-01],\n",
      "        [-1.8483e+03, -9.6802e+00, -9.8940e-02],\n",
      "        [-1.8465e+03, -1.0532e+01, -1.0594e-01],\n",
      "        [-1.8466e+03, -8.8209e+00, -2.0776e-01],\n",
      "        [-1.8554e+03, -1.1629e+01, -1.2036e-01],\n",
      "        [-1.8487e+03, -9.4051e+00, -1.6231e-01],\n",
      "        [-1.8572e+03, -1.1604e+01, -1.2283e-01],\n",
      "        [-1.8562e+03, -1.2222e+01, -1.2931e-01],\n",
      "        [-1.8543e+03, -1.0451e+01, -1.5723e-01],\n",
      "        [-1.8398e+03, -9.1002e+00, -1.5655e-01],\n",
      "        [-1.8576e+03, -1.0072e+01, -1.4586e-01],\n",
      "        [-1.8568e+03, -1.1372e+01, -9.3589e-02],\n",
      "        [-1.8572e+03, -9.5934e+00, -1.6006e-01],\n",
      "        [-1.8508e+03, -8.4198e+00, -2.1745e-01],\n",
      "        [-1.8432e+03, -1.0216e+01, -1.0916e-01],\n",
      "        [-1.8508e+03, -1.0805e+01, -1.0921e-01],\n",
      "        [-1.8504e+03, -1.0200e+01, -1.3529e-01],\n",
      "        [-1.8433e+03, -1.0832e+01, -8.2839e-02],\n",
      "        [-1.8419e+03, -9.2563e+00, -1.5371e-01],\n",
      "        [-1.8594e+03, -1.0219e+01, -1.1704e-01],\n",
      "        [-1.8430e+03, -9.8650e+00, -1.4843e-01],\n",
      "        [-1.8420e+03, -8.5204e+00, -1.4735e-01],\n",
      "        [-1.8434e+03, -9.2475e+00, -1.1610e-01],\n",
      "        [-1.8520e+03, -1.0433e+01, -1.7816e-01],\n",
      "        [-1.8533e+03, -1.1392e+01, -9.8899e-02],\n",
      "        [-1.8513e+03, -1.0095e+01, -1.7486e-01],\n",
      "        [-1.8466e+03, -1.0793e+01, -8.2794e-02],\n",
      "        [-1.8404e+03, -1.0650e+01, -7.9567e-02],\n",
      "        [-1.8534e+03, -1.1432e+01, -1.0091e-01],\n",
      "        [-1.8488e+03, -1.0903e+01, -1.0258e-01],\n",
      "        [-1.8635e+03, -1.1806e+01, -1.1717e-01],\n",
      "        [-1.8491e+03, -1.1362e+01, -9.7722e-02],\n",
      "        [-1.8603e+03, -1.1872e+01, -1.1301e-01]])\n",
      "tensor([[-2.0226e+03, -1.3303e+01, -1.1937e-01],\n",
      "        [-2.0114e+03, -9.6207e+00, -1.9750e-01],\n",
      "        [-2.0066e+03, -1.0685e+01, -1.0446e-01],\n",
      "        [-2.0076e+03, -1.0961e+01, -1.2625e-01],\n",
      "        [-2.0138e+03, -1.0999e+01, -1.3440e-01],\n",
      "        [-2.0274e+03, -1.2489e+01, -1.5104e-01],\n",
      "        [-2.0196e+03, -1.0674e+01, -1.4399e-01],\n",
      "        [-2.0200e+03, -1.0866e+01, -1.3934e-01],\n",
      "        [-2.0257e+03, -1.1504e+01, -1.8030e-01],\n",
      "        [-2.0158e+03, -1.0782e+01, -1.7238e-01],\n",
      "        [-2.0237e+03, -1.0759e+01, -1.8317e-01],\n",
      "        [-2.0283e+03, -1.0365e+01, -1.8720e-01],\n",
      "        [-2.0159e+03, -8.8511e+00, -1.9299e-01],\n",
      "        [-2.0192e+03, -1.3088e+01, -1.3610e-01],\n",
      "        [-2.0359e+03, -1.2925e+01, -1.3246e-01],\n",
      "        [-2.0191e+03, -9.3724e+00, -1.8499e-01],\n",
      "        [-2.0136e+03, -1.1496e+01, -1.0926e-01],\n",
      "        [-2.0183e+03, -1.0024e+01, -2.0133e-01],\n",
      "        [-2.0129e+03, -1.1636e+01, -1.0532e-01],\n",
      "        [-2.0285e+03, -1.2826e+01, -1.0950e-01],\n",
      "        [-2.0290e+03, -1.3796e+01, -1.0770e-01],\n",
      "        [-2.0223e+03, -1.0252e+01, -1.9801e-01],\n",
      "        [-2.0253e+03, -1.0112e+01, -2.0655e-01],\n",
      "        [-2.0033e+03, -9.1992e+00, -1.4966e-01],\n",
      "        [-2.0214e+03, -1.0872e+01, -1.3972e-01],\n",
      "        [-2.0176e+03, -1.2747e+01, -1.2381e-01],\n",
      "        [-2.0131e+03, -1.0399e+01, -1.1453e-01],\n",
      "        [-2.0194e+03, -1.1702e+01, -1.5545e-01],\n",
      "        [-2.0166e+03, -9.1534e+00, -2.1061e-01],\n",
      "        [-2.0224e+03, -1.2579e+01, -7.6450e-02],\n",
      "        [-2.0361e+03, -1.2569e+01, -1.2831e-01],\n",
      "        [-2.0093e+03, -1.0738e+01, -1.4551e-01],\n",
      "        [-2.0332e+03, -1.2884e+01, -1.2610e-01],\n",
      "        [-2.0226e+03, -1.0264e+01, -2.0226e-01],\n",
      "        [-2.0091e+03, -1.1038e+01, -1.1311e-01],\n",
      "        [-2.0068e+03, -1.0758e+01, -1.1930e-01],\n",
      "        [-2.0275e+03, -1.2863e+01, -1.3309e-01],\n",
      "        [-2.0050e+03, -1.0544e+01, -1.3506e-01],\n",
      "        [-2.0359e+03, -1.2310e+01, -1.4848e-01],\n",
      "        [-2.0270e+03, -1.2813e+01, -1.4192e-01],\n",
      "        [-2.0229e+03, -1.3163e+01, -1.3918e-01],\n",
      "        [-2.0097e+03, -1.0430e+01, -1.1131e-01],\n",
      "        [-2.0119e+03, -9.6632e+00, -2.3103e-01],\n",
      "        [-2.0085e+03, -1.1326e+01, -1.1459e-01],\n",
      "        [-2.0263e+03, -1.2575e+01, -6.6410e-02],\n",
      "        [-2.0157e+03, -1.2051e+01, -1.0910e-01],\n",
      "        [-2.0101e+03, -9.3492e+00, -1.2344e-01],\n",
      "        [-2.0107e+03, -1.1092e+01, -1.5344e-01],\n",
      "        [-2.0069e+03, -1.0603e+01, -1.3610e-01],\n",
      "        [-2.0102e+03, -1.0903e+01, -1.4476e-01],\n",
      "        [-2.0126e+03, -1.1000e+01, -1.2753e-01],\n",
      "        [-2.0207e+03, -1.1656e+01, -1.4429e-01],\n",
      "        [-2.0201e+03, -1.3161e+01, -1.0272e-01],\n",
      "        [-2.0277e+03, -1.1158e+01, -1.6297e-01],\n",
      "        [-2.0186e+03, -1.1075e+01, -1.1588e-01],\n",
      "        [-2.0155e+03, -1.2835e+01, -1.0855e-01],\n",
      "        [-2.0182e+03, -9.9764e+00, -2.3113e-01],\n",
      "        [-2.0330e+03, -1.2154e+01, -1.4140e-01],\n",
      "        [-2.0143e+03, -9.8784e+00, -1.4608e-01],\n",
      "        [-2.0194e+03, -1.1881e+01, -9.2424e-02],\n",
      "        [-2.0105e+03, -1.0896e+01, -1.1131e-01],\n",
      "        [-2.0228e+03, -1.3697e+01, -1.0142e-01],\n",
      "        [-2.0216e+03, -1.2082e+01, -1.0720e-01],\n",
      "        [-2.0104e+03, -1.0496e+01, -1.4348e-01],\n",
      "        [-2.0265e+03, -1.1666e+01, -9.1995e-02],\n",
      "        [-2.0153e+03, -9.2419e+00, -2.1012e-01],\n",
      "        [-2.0320e+03, -1.3303e+01, -1.1655e-01],\n",
      "        [-2.0175e+03, -1.0280e+01, -2.0456e-01],\n",
      "        [-2.0309e+03, -1.3443e+01, -1.0338e-01],\n",
      "        [-2.0317e+03, -1.3248e+01, -1.2096e-01],\n",
      "        [-2.0145e+03, -1.0526e+01, -1.5854e-01],\n",
      "        [-2.0168e+03, -1.1787e+01, -1.3965e-01],\n",
      "        [-2.0035e+03, -9.2787e+00, -1.9581e-01],\n",
      "        [-2.0167e+03, -1.1151e+01, -1.5690e-01],\n",
      "        [-2.0302e+03, -1.3110e+01, -1.3749e-01],\n",
      "        [-2.0324e+03, -1.3042e+01, -1.3255e-01],\n",
      "        [-2.0276e+03, -1.0655e+01, -1.8193e-01],\n",
      "        [-2.0130e+03, -1.1558e+01, -1.0499e-01],\n",
      "        [-2.0032e+03, -1.0533e+01, -1.2062e-01],\n",
      "        [-2.0187e+03, -1.1443e+01, -1.4824e-01],\n",
      "        [-2.0154e+03, -1.1738e+01, -1.1643e-01],\n",
      "        [-2.0171e+03, -1.1625e+01, -1.4019e-01],\n",
      "        [-2.0131e+03, -1.0901e+01, -1.3082e-01],\n",
      "        [-2.0243e+03, -1.1837e+01, -1.3767e-01],\n",
      "        [-2.0301e+03, -1.2594e+01, -1.4192e-01],\n",
      "        [-2.0160e+03, -9.2654e+00, -2.6920e-01],\n",
      "        [-2.0121e+03, -1.0692e+01, -1.7520e-01],\n",
      "        [-2.0249e+03, -9.8861e+00, -1.8957e-01],\n",
      "        [-2.0067e+03, -1.0317e+01, -1.6939e-01],\n",
      "        [-2.0115e+03, -1.0290e+01, -1.2040e-01],\n",
      "        [-2.0186e+03, -1.3262e+01, -1.1723e-01],\n",
      "        [-2.0185e+03, -1.1678e+01, -1.6776e-01],\n",
      "        [-2.0211e+03, -1.1071e+01, -1.8268e-01],\n",
      "        [-2.0081e+03, -1.0543e+01, -1.3548e-01],\n",
      "        [-2.0241e+03, -1.1701e+01, -1.6039e-01],\n",
      "        [-2.0175e+03, -1.1072e+01, -1.3958e-01],\n",
      "        [-2.0225e+03, -1.1285e+01, -1.5665e-01],\n",
      "        [-2.0084e+03, -1.1688e+01, -1.0938e-01],\n",
      "        [-2.0288e+03, -1.0592e+01, -1.8305e-01],\n",
      "        [-2.0273e+03, -1.1398e+01, -1.6828e-01]])\n",
      "tensor([[-1.6811e+03, -9.6034e+00, -1.1273e-01]])\n"
     ]
    }
   ],
   "source": [
    "print(train_Y1)\n",
    "print(train_Y2)\n",
    "print(train_Y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared train_X shape: torch.Size([151, 6])\n",
      "Prepared train_Y1 shape: torch.Size([151, 1])\n",
      "Prepared train_Y2 shape: torch.Size([151, 1])\n",
      "Prepared train_Y3 shape: torch.Size([151, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def prepare_multitask_gp_data(train_X1, train_Y1, train_X2, train_Y2, train_X3, train_Y3):\n",
    "    # Number of samples for each task\n",
    "    n1 = train_X1.shape[0]\n",
    "    n2 = train_X2.shape[0]\n",
    "    n3 = train_X3.shape[0]\n",
    "    \n",
    "    # Add the task feature column to each train_X\n",
    "    task_feature_1 = torch.zeros(n1, 1)  # Task 0 for the first objective\n",
    "    task_feature_2 = torch.ones(n2, 1)   # Task 1 for the second objective\n",
    "    task_feature_3 = torch.full((n3, 1), 2)  # Task 2 for the third objective\n",
    "    \n",
    "    # Concatenate the task feature with the input data\n",
    "    train_X1 = torch.cat([train_X1, task_feature_1], dim=-1)\n",
    "    train_X2 = torch.cat([train_X2, task_feature_2], dim=-1)\n",
    "    train_X3 = torch.cat([train_X3, task_feature_3], dim=-1)\n",
    "    \n",
    "    # Concatenate all the input data\n",
    "    train_X = torch.cat([train_X1, train_X2, train_X3], dim=0)\n",
    "    \n",
    "    # Concatenate all the output data separately for each objective\n",
    "    train_Y1_obj = torch.cat([train_Y1[:, 0:1], train_Y2[:, 0:1], train_Y3[:, 0:1]], dim=0)\n",
    "    train_Y2_obj = torch.cat([train_Y1[:, 1:2], train_Y2[:, 1:2], train_Y3[:, 1:2]], dim=0)\n",
    "    train_Y3_obj = torch.cat([train_Y1[:, 2:3], train_Y2[:, 2:3], train_Y3[:, 2:3]], dim=0)\n",
    "    \n",
    "    return train_X, train_Y1_obj, train_Y2_obj, train_Y3_obj\n",
    "\n",
    "# Example of how to use the function:\n",
    "train_X, train_Y1, train_Y2, train_Y3 = prepare_multitask_gp_data(train_X1, train_Y1, train_X2, train_Y2, train_X3, train_Y3)\n",
    "\n",
    "print(\"Prepared train_X shape:\", train_X.shape)\n",
    "print(\"Prepared train_Y1 shape:\", train_Y1.shape)\n",
    "print(\"Prepared train_Y2 shape:\", train_Y2.shape)\n",
    "print(\"Prepared train_Y3 shape:\", train_Y3.shape)\n",
    "\n",
    "\n",
    "train_X = train_X.to(dtype=torch.float64)\n",
    "train_Y1 = train_Y1.to(dtype=torch.float64)\n",
    "train_Y2 = train_Y2.to(dtype=torch.float64)\n",
    "train_Y3 = train_Y3.to(dtype=torch.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.6204, 2.3472, 2.9953, 2.9762, 1.5186, 0.0000],\n",
      "        [2.6656, 2.2683, 2.5190, 1.1619, 1.0419, 0.0000],\n",
      "        [2.4018, 2.4204, 1.8724, 2.8009, 1.5200, 0.0000],\n",
      "        [1.0161, 1.6814, 1.6505, 2.7558, 2.7840, 0.0000],\n",
      "        [2.5353, 1.6793, 1.8843, 1.0839, 1.3294, 0.0000],\n",
      "        [1.1692, 1.0779, 1.9147, 2.5501, 1.5524, 0.0000],\n",
      "        [2.6561, 1.3752, 1.1796, 2.2970, 2.6272, 0.0000],\n",
      "        [1.5908, 2.3015, 2.1672, 2.4537, 1.4588, 0.0000],\n",
      "        [1.5629, 2.3040, 2.3205, 1.6761, 1.4641, 0.0000],\n",
      "        [1.0165, 2.5430, 1.0532, 2.6084, 2.4998, 0.0000],\n",
      "        [2.0192, 1.8163, 2.7065, 2.2037, 1.0950, 0.0000],\n",
      "        [2.6155, 1.7412, 1.3462, 2.2454, 1.4994, 0.0000],\n",
      "        [1.2359, 1.0142, 2.3609, 1.6651, 1.6721, 0.0000],\n",
      "        [1.5878, 2.8481, 1.5674, 1.6535, 1.8351, 0.0000],\n",
      "        [2.9442, 1.0818, 1.7273, 2.0141, 2.7243, 0.0000],\n",
      "        [1.3564, 1.9644, 1.0080, 1.2941, 2.9225, 0.0000],\n",
      "        [1.6489, 1.9809, 1.2589, 2.5866, 2.0580, 0.0000],\n",
      "        [1.8714, 2.7065, 2.9087, 2.6321, 1.0773, 0.0000],\n",
      "        [2.4326, 2.5770, 1.1860, 1.3537, 2.7829, 0.0000],\n",
      "        [2.3263, 1.1667, 1.8164, 1.5566, 2.2149, 0.0000],\n",
      "        [2.1487, 2.3485, 2.4939, 1.2015, 1.6299, 0.0000],\n",
      "        [2.4597, 2.2671, 1.6415, 2.6024, 1.7554, 0.0000],\n",
      "        [2.2427, 1.4526, 2.6993, 1.1993, 2.2634, 0.0000],\n",
      "        [1.8621, 1.7951, 2.1807, 2.5833, 2.1528, 0.0000],\n",
      "        [2.2810, 1.7719, 1.7951, 2.9340, 1.5224, 0.0000],\n",
      "        [2.8787, 2.3956, 2.2393, 2.1678, 1.3769, 0.0000],\n",
      "        [1.3638, 1.4788, 2.2284, 1.1479, 1.4768, 0.0000],\n",
      "        [2.0898, 2.2523, 2.4636, 1.7983, 2.9483, 0.0000],\n",
      "        [2.1101, 1.1919, 2.2615, 2.3745, 2.5360, 0.0000],\n",
      "        [2.1285, 1.8328, 2.9889, 1.7411, 2.6220, 0.0000],\n",
      "        [2.1277, 2.5764, 2.7061, 1.0669, 2.3972, 0.0000],\n",
      "        [2.2565, 1.3144, 1.5110, 1.2908, 2.2702, 0.0000],\n",
      "        [2.4761, 2.3568, 1.3535, 2.1181, 1.8801, 0.0000],\n",
      "        [1.6581, 2.2791, 1.9176, 1.8500, 2.1731, 0.0000],\n",
      "        [1.5059, 1.0561, 1.3114, 1.9399, 1.8969, 0.0000],\n",
      "        [2.3975, 2.4293, 1.6416, 1.2360, 1.3115, 0.0000],\n",
      "        [2.5909, 1.3294, 2.9462, 1.9120, 2.8327, 0.0000],\n",
      "        [2.4397, 1.2286, 2.3035, 1.3385, 1.2914, 0.0000],\n",
      "        [1.4126, 2.8467, 1.6668, 1.1894, 1.6821, 0.0000],\n",
      "        [1.5237, 2.8419, 1.4165, 1.5187, 1.6116, 0.0000],\n",
      "        [1.2627, 2.2353, 2.7294, 2.3479, 1.0267, 0.0000],\n",
      "        [2.3524, 1.8326, 1.0849, 2.3047, 2.6802, 0.0000],\n",
      "        [2.8646, 1.9170, 2.4819, 1.9852, 1.0904, 0.0000],\n",
      "        [1.9378, 2.8327, 1.0601, 2.2829, 1.0793, 0.0000],\n",
      "        [1.1020, 1.0423, 1.2426, 1.9317, 1.6118, 0.0000],\n",
      "        [2.7956, 1.1322, 1.6631, 2.3031, 2.2408, 0.0000],\n",
      "        [2.4429, 1.1038, 1.8475, 1.9112, 1.9932, 0.0000],\n",
      "        [1.7184, 2.0958, 2.4451, 2.7283, 2.8345, 0.0000],\n",
      "        [2.5983, 1.0226, 1.4354, 2.2662, 1.8411, 0.0000],\n",
      "        [2.2592, 1.9236, 1.9250, 2.6269, 2.6932, 0.0000],\n",
      "        [1.8083, 1.3440, 1.7266, 2.8126, 1.8422, 1.0000],\n",
      "        [2.0264, 2.7619, 2.0504, 1.2680, 1.2511, 1.0000],\n",
      "        [1.3512, 1.1139, 1.6223, 1.2643, 2.0121, 1.0000],\n",
      "        [2.4769, 1.3743, 1.3626, 1.1421, 1.9394, 1.0000],\n",
      "        [1.8490, 1.3117, 2.1441, 1.5287, 1.9954, 1.0000],\n",
      "        [2.6417, 2.8108, 2.2241, 2.7552, 1.1289, 1.0000],\n",
      "        [1.8889, 2.3014, 1.8488, 1.4836, 2.9131, 1.0000],\n",
      "        [1.2965, 1.5361, 2.5786, 1.8382, 2.3552, 1.0000],\n",
      "        [2.8661, 1.7370, 2.8130, 2.5147, 1.0716, 1.0000],\n",
      "        [2.9453, 1.8158, 2.0236, 1.1924, 2.2302, 1.0000],\n",
      "        [2.3339, 2.1815, 2.6069, 1.7826, 2.2162, 1.0000],\n",
      "        [2.0286, 2.6375, 2.8233, 1.7873, 2.7811, 1.0000],\n",
      "        [1.0249, 2.5172, 2.2572, 1.0595, 2.8920, 1.0000],\n",
      "        [1.2627, 2.4532, 1.6471, 2.7555, 1.1101, 1.0000],\n",
      "        [2.1193, 2.1833, 2.6145, 2.8363, 2.7824, 1.0000],\n",
      "        [1.2776, 2.5726, 2.3164, 1.2406, 2.9591, 1.0000],\n",
      "        [1.3140, 2.5271, 1.1913, 2.1093, 1.5740, 1.0000],\n",
      "        [2.4496, 1.6904, 2.7651, 1.0817, 2.4511, 1.0000],\n",
      "        [2.8034, 1.0343, 1.4931, 1.3536, 2.4263, 1.0000],\n",
      "        [2.3330, 1.4563, 1.9691, 2.5114, 2.8896, 1.0000],\n",
      "        [2.0215, 2.4429, 1.3392, 2.9776, 2.4617, 1.0000],\n",
      "        [2.7375, 2.3104, 2.5039, 1.2836, 2.6391, 1.0000],\n",
      "        [2.8277, 2.8089, 2.7107, 1.6198, 2.1056, 1.0000],\n",
      "        [1.0009, 2.2485, 1.3864, 1.0607, 1.5847, 1.0000],\n",
      "        [2.6372, 1.0708, 2.9698, 1.8666, 1.6942, 1.0000],\n",
      "        [1.3995, 1.9352, 1.3612, 2.5636, 1.6188, 1.0000],\n",
      "        [1.3762, 1.1120, 2.2764, 1.1857, 2.6664, 1.0000],\n",
      "        [1.7174, 1.9391, 2.1805, 2.1788, 1.6236, 1.0000],\n",
      "        [1.4288, 2.5850, 2.4344, 1.1643, 2.4087, 1.0000],\n",
      "        [2.4637, 2.9216, 1.0727, 2.6125, 1.6592, 1.0000],\n",
      "        [1.5653, 2.0570, 2.8976, 2.7865, 2.9674, 1.0000],\n",
      "        [2.2365, 1.5629, 1.6613, 1.1954, 1.8848, 1.0000],\n",
      "        [2.7661, 1.6695, 2.3167, 2.7744, 2.6136, 1.0000],\n",
      "        [1.4446, 2.5135, 2.8047, 1.8688, 1.9656, 1.0000],\n",
      "        [2.0616, 1.4335, 1.2429, 1.3720, 2.1377, 1.0000],\n",
      "        [1.1023, 1.2127, 1.8324, 1.5299, 1.4545, 1.0000],\n",
      "        [2.7738, 2.6870, 1.8813, 2.8412, 1.3506, 1.0000],\n",
      "        [1.7625, 1.1836, 1.8289, 1.1008, 1.5153, 1.0000],\n",
      "        [2.9354, 2.8018, 2.6571, 2.7705, 2.0888, 1.0000],\n",
      "        [2.7007, 1.3454, 2.3537, 2.9537, 1.3068, 1.0000],\n",
      "        [2.0591, 1.4507, 2.0421, 2.8941, 1.2531, 1.0000],\n",
      "        [2.5044, 2.6428, 1.1017, 1.5338, 1.2540, 1.0000],\n",
      "        [2.0818, 1.7040, 2.8515, 1.2799, 1.0084, 1.0000],\n",
      "        [2.6000, 1.0286, 1.5530, 1.2574, 1.8215, 1.0000],\n",
      "        [2.6315, 2.9302, 1.0568, 2.5392, 2.4340, 1.0000],\n",
      "        [1.0730, 2.9400, 1.4190, 2.3948, 1.1537, 1.0000],\n",
      "        [1.3310, 2.6781, 1.2605, 1.1212, 2.4803, 1.0000],\n",
      "        [2.7890, 1.2109, 2.0645, 1.4923, 1.1221, 1.0000],\n",
      "        [2.0454, 1.4335, 1.5576, 1.0542, 1.9508, 1.0000],\n",
      "        [1.0141, 1.3531, 2.2906, 1.8328, 1.0677, 1.0000],\n",
      "        [2.1887, 1.1795, 2.0090, 1.2172, 2.3280, 1.0000],\n",
      "        [1.2315, 1.8772, 2.2568, 2.1899, 2.0496, 1.0000],\n",
      "        [1.1224, 1.2127, 1.7214, 2.7187, 1.9738, 1.0000],\n",
      "        [1.7691, 1.9600, 2.9111, 2.1780, 2.3792, 1.0000],\n",
      "        [1.1149, 2.9181, 1.6091, 1.9925, 2.1791, 1.0000],\n",
      "        [1.1452, 1.4361, 1.1339, 2.5847, 1.8258, 1.0000],\n",
      "        [1.4062, 2.6086, 2.8444, 1.8423, 1.1119, 1.0000],\n",
      "        [2.5467, 2.0053, 2.6294, 2.4924, 2.6906, 1.0000],\n",
      "        [1.4571, 2.6726, 1.6768, 1.3461, 2.3891, 1.0000],\n",
      "        [2.8067, 2.7391, 1.1095, 2.3288, 1.4658, 1.0000],\n",
      "        [2.0620, 2.1172, 1.0084, 1.6311, 1.8293, 1.0000],\n",
      "        [1.5065, 2.5835, 1.0807, 2.9642, 1.7928, 1.0000],\n",
      "        [2.8233, 1.2402, 1.6952, 1.8398, 2.8910, 1.0000],\n",
      "        [1.5859, 1.7626, 1.6986, 1.3414, 2.0494, 1.0000],\n",
      "        [1.6764, 1.0451, 2.9613, 2.3740, 2.2867, 1.0000],\n",
      "        [1.6406, 2.5924, 2.3302, 1.1049, 2.2534, 1.0000],\n",
      "        [2.8189, 2.7560, 1.8429, 2.9676, 1.9430, 1.0000],\n",
      "        [2.7948, 2.3237, 2.3541, 1.4204, 1.6276, 1.0000],\n",
      "        [1.4279, 2.9093, 1.8526, 2.8362, 2.6097, 1.0000],\n",
      "        [1.7017, 2.4773, 2.0479, 2.7847, 2.7259, 1.0000],\n",
      "        [2.7277, 1.0011, 2.7853, 1.0787, 1.9484, 1.0000],\n",
      "        [2.9671, 1.4515, 1.7143, 2.0508, 1.4243, 1.0000],\n",
      "        [1.0777, 2.0919, 1.9496, 1.1006, 1.0093, 1.0000],\n",
      "        [1.4243, 2.8457, 1.9825, 2.0699, 1.1930, 1.0000],\n",
      "        [2.1919, 1.6809, 2.4339, 2.9449, 1.9356, 1.0000],\n",
      "        [2.9549, 2.4269, 2.0097, 2.8904, 2.0895, 1.0000],\n",
      "        [2.8776, 2.2795, 2.6598, 1.5896, 2.8998, 1.0000],\n",
      "        [2.0494, 1.2822, 1.3716, 1.6634, 2.3142, 1.0000],\n",
      "        [1.5292, 1.7257, 1.0953, 1.4592, 1.1528, 1.0000],\n",
      "        [2.5325, 1.5371, 2.1599, 1.8425, 1.8670, 1.0000],\n",
      "        [2.7000, 1.1524, 1.7055, 1.7155, 2.0572, 1.0000],\n",
      "        [1.8869, 1.5652, 2.0564, 2.0062, 1.7252, 1.0000],\n",
      "        [2.3085, 1.0515, 2.2831, 1.1388, 2.2821, 1.0000],\n",
      "        [1.0696, 2.6196, 2.0952, 2.3100, 2.3806, 1.0000],\n",
      "        [2.5301, 1.5795, 2.6146, 2.8371, 1.7974, 1.0000],\n",
      "        [2.5903, 2.3383, 2.9345, 1.2482, 1.1481, 1.0000],\n",
      "        [2.8049, 1.4725, 2.1579, 1.0553, 1.8823, 1.0000],\n",
      "        [1.6417, 2.7321, 2.6468, 1.5617, 2.8653, 1.0000],\n",
      "        [1.9093, 1.7373, 1.8346, 1.2225, 1.2571, 1.0000],\n",
      "        [2.3423, 2.2371, 1.1141, 1.0683, 2.6769, 1.0000],\n",
      "        [1.6904, 1.2377, 1.4485, 2.7881, 1.5520, 1.0000],\n",
      "        [1.9906, 2.0794, 2.1724, 2.2208, 1.1715, 1.0000],\n",
      "        [2.7231, 2.0884, 2.4034, 1.9337, 1.5147, 1.0000],\n",
      "        [2.3862, 2.0351, 1.2459, 1.3048, 1.5737, 1.0000],\n",
      "        [2.9819, 2.0158, 2.1934, 2.2180, 1.7040, 1.0000],\n",
      "        [2.4676, 2.4065, 1.6328, 1.7167, 1.9895, 1.0000],\n",
      "        [2.5629, 1.8990, 2.2535, 1.7940, 2.3712, 1.0000],\n",
      "        [1.8253, 1.1291, 1.4105, 1.8992, 1.2056, 1.0000],\n",
      "        [2.8480, 2.9767, 2.6945, 1.9206, 2.1526, 1.0000],\n",
      "        [1.3147, 2.2442, 2.8404, 2.3388, 2.2044, 1.0000],\n",
      "        [2.1082, 1.4493, 2.0649, 1.8627, 1.9413, 2.0000]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.models import MultiTaskGP\n",
    "from botorch.models import ModelList\n",
    "from botorch.acquisition.multi_objective.logei import qLogNoisyExpectedHypervolumeImprovement\n",
    "\n",
    "# Create a multi-task GP model\n",
    "\n",
    "\n",
    "model1 = MultiTaskGP(train_X=train_X, train_Y=train_Y1, task_feature=-1, output_tasks=[2])\n",
    "model2 = MultiTaskGP(train_X=train_X, train_Y=train_Y2, task_feature=-1, output_tasks=[2])\n",
    "model3 = MultiTaskGP(train_X=train_X, train_Y=train_Y3, task_feature=-1, output_tasks=[2])\n",
    "\n",
    "new_modellist = ModelList(model1, model2, model3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(new_modellist.num_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([151, 6])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_modellist.models[2].train_inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\linear_operator\\utils\\interpolation.py:71: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:620.)\n",
      "  summing_matrix = cls(summing_matrix_indices, summing_matrix_values, size)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExactMarginalLogLikelihood(\n",
       "  (likelihood): GaussianLikelihood(\n",
       "    (noise_covar): HomoskedasticNoise(\n",
       "      (noise_prior): GammaPrior()\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "  )\n",
       "  (model): MultiTaskGP(\n",
       "    (likelihood): GaussianLikelihood(\n",
       "      (noise_covar): HomoskedasticNoise(\n",
       "        (noise_prior): GammaPrior()\n",
       "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "      )\n",
       "    )\n",
       "    (mean_module): ConstantMean()\n",
       "    (covar_module): ScaleKernel(\n",
       "      (base_kernel): MaternKernel(\n",
       "        (lengthscale_prior): GammaPrior()\n",
       "        (raw_lengthscale_constraint): Positive()\n",
       "      )\n",
       "      (outputscale_prior): GammaPrior()\n",
       "      (raw_outputscale_constraint): Positive()\n",
       "    )\n",
       "    (task_covar_module): IndexKernel(\n",
       "      (raw_var_constraint): Positive()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "mll1 = ExactMarginalLogLikelihood(new_modellist.models[0].likelihood, new_modellist.models[0])\n",
    "mll2 = ExactMarginalLogLikelihood(new_modellist.models[1].likelihood, new_modellist.models[1])\n",
    "mll3 = ExactMarginalLogLikelihood(new_modellist.models[2].likelihood, new_modellist.models[2])\n",
    "\n",
    "fit_gpytorch_mll(mll1)\n",
    "fit_gpytorch_mll(mll2)\n",
    "fit_gpytorch_mll(mll3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "def perform_optimization_step(model, train_X, bounds, num_restarts=10, raw_samples=512):\n",
    "    \n",
    "    X_baseline_no_task = train_X[:, :-1]\n",
    "\n",
    "    qNEHVI = qLogNoisyExpectedHypervolumeImprovement(\n",
    "        model=model,\n",
    "        ref_point=torch.tensor([-1864.72022, -11.81993945, -0.2903999384]),\n",
    "        X_baseline=X_baseline_no_task,\n",
    "        prune_baseline=True\n",
    "    )\n",
    "\n",
    "    # Optimize the acquisition function to find the next point to sample\n",
    "    new_X, acq_func_value = optimize_acqf(\n",
    "        acq_function=qNEHVI,\n",
    "        bounds=bounds,\n",
    "        q=1,\n",
    "        num_restarts=num_restarts,\n",
    "        raw_samples=raw_samples,\n",
    "        options={\"batch_limit\": 5, \"maxiter\": 200},\n",
    "    )\n",
    "\n",
    "    print(f\"Acquisition function value: {acq_func_value}\")\n",
    "    print(f\"Next point to sample: {new_X}\")    \n",
    "    return new_X, acq_func_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_train_multitask_model(train_X, train_Y1, train_Y2, train_Y3):\n",
    "    # data is here the data combined with tas feature\n",
    "    model1 = MultiTaskGP(train_X=train_X, train_Y=train_Y1, task_feature=-1, output_tasks=[2])\n",
    "    model2 = MultiTaskGP(train_X=train_X, train_Y=train_Y2, task_feature=-1, output_tasks=[2])\n",
    "    model3 = MultiTaskGP(train_X=train_X, train_Y=train_Y3, task_feature=-1, output_tasks=[2])\n",
    "\n",
    "    new_modellist = ModelList(model1, model2, model3)\n",
    "\n",
    "    mll1 = ExactMarginalLogLikelihood(new_modellist.models[0].likelihood, new_modellist.models[0])\n",
    "    mll2 = ExactMarginalLogLikelihood(new_modellist.models[1].likelihood, new_modellist.models[1])\n",
    "    mll3 = ExactMarginalLogLikelihood(new_modellist.models[2].likelihood, new_modellist.models[2])\n",
    "\n",
    "    fit_gpytorch_mll(mll1)\n",
    "    fit_gpytorch_mll(mll2)\n",
    "    fit_gpytorch_mll(mll3)\n",
    "\n",
    "    return new_modellist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_vehicle_safety(model, train_X, train_Y1, train_Y2, train_Y3, bounds, num_iterations=50):\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        print(f\"Iteration {iteration + 1}/{num_iterations}\")\n",
    "        new_X, acq_func_value = perform_optimization_step(model, train_X, bounds)\n",
    "        \n",
    "        # Evaluate new Y values\n",
    "        new_Y, exp_dim = generate_car_crash_synthetic_data(new_X, 0.0)\n",
    "        \n",
    "        # Update training datasets:\n",
    "        new_Y1, new_Y2, new_Y3 = torch.split(new_Y, 1, dim=-1)  # Split along the last dimension\n",
    "\n",
    "        # Add the corresponding new data to each training set\n",
    "        train_Y1 = torch.cat([train_Y1, new_Y1], dim=0)  # Concatenate along the first dimension\n",
    "        train_Y2 = torch.cat([train_Y2, new_Y2], dim=0)  # Concatenate along the first dimension\n",
    "        train_Y3 = torch.cat([train_Y3, new_Y3], dim=0)  # Concatenate along the first dimension\n",
    "        \n",
    "        task_feature = torch.tensor([[2.0]], dtype=torch.float64)  # Creating a tensor with value 2.0 and dtype float64\n",
    "        new_X_with_task = torch.cat([new_X, task_feature], dim=-1)  # Concatenating along the last dimension\n",
    "\n",
    "        # Concatenating new_X_with_task to train_X\n",
    "        train_X = torch.cat([train_X, new_X_with_task], dim=0)  # Concatenating along the first dimension\n",
    "\n",
    "        print(f\"Training data shapes: {train_X.shape}, {train_Y1.shape}, {train_Y2.shape}, {train_Y3.shape}\")\n",
    "\n",
    "        # Setup and Refit model with updated data\n",
    "        model = setup_train_multitask_model(train_X, train_Y1, train_Y2, train_Y3)\n",
    "    \n",
    "    return train_X, train_Y1, train_Y2, train_Y3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: 3.130997491998598\n",
      "Next point to sample: tensor([[1., 3., 3., 1., 1.]])\n",
      "Training data shapes: torch.Size([152, 6]), torch.Size([152, 1]), torch.Size([152, 1]), torch.Size([152, 1])\n",
      "Iteration 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: 2.9875103939161987\n",
      "Next point to sample: tensor([[1.0000, 3.0000, 1.0000, 1.0000, 1.9622]])\n",
      "Training data shapes: torch.Size([153, 6]), torch.Size([153, 1]), torch.Size([153, 1]), torch.Size([153, 1])\n",
      "Iteration 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: 1.4599843637017633\n",
      "Next point to sample: tensor([[1.3201, 3.0000, 1.0000, 1.6333, 2.7671]])\n",
      "Training data shapes: torch.Size([154, 6]), torch.Size([154, 1]), torch.Size([154, 1]), torch.Size([154, 1])\n",
      "Iteration 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: 1.2906021757655983\n",
      "Next point to sample: tensor([[1., 1., 1., 1., 1.]])\n",
      "Training data shapes: torch.Size([155, 6]), torch.Size([155, 1]), torch.Size([155, 1]), torch.Size([155, 1])\n",
      "Iteration 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: 1.4106834424360217\n",
      "Next point to sample: tensor([[1., 3., 3., 1., 3.]])\n",
      "Training data shapes: torch.Size([156, 6]), torch.Size([156, 1]), torch.Size([156, 1]), torch.Size([156, 1])\n",
      "Iteration 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: 0.8976546247830681\n",
      "Next point to sample: tensor([[2.1457, 3.0000, 1.0000, 2.0286, 2.5711]])\n",
      "Training data shapes: torch.Size([157, 6]), torch.Size([157, 1]), torch.Size([157, 1]), torch.Size([157, 1])\n",
      "Iteration 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: 0.5158887050818448\n",
      "Next point to sample: tensor([[1.0000, 1.0000, 1.0000, 1.3667, 2.3094]])\n",
      "Training data shapes: torch.Size([158, 6]), torch.Size([158, 1]), torch.Size([158, 1]), torch.Size([158, 1])\n",
      "Iteration 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: 0.5613847860784293\n",
      "Next point to sample: tensor([[1., 3., 1., 1., 1.]])\n",
      "Training data shapes: torch.Size([159, 6]), torch.Size([159, 1]), torch.Size([159, 1]), torch.Size([159, 1])\n",
      "Iteration 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: 0.09590475547497856\n",
      "Next point to sample: tensor([[1.0000, 3.0000, 1.0000, 1.1486, 3.0000]])\n",
      "Training data shapes: torch.Size([160, 6]), torch.Size([160, 1]), torch.Size([160, 1]), torch.Size([160, 1])\n",
      "Iteration 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: 0.025510871100006938\n",
      "Next point to sample: tensor([[1.0000, 1.0000, 1.6194, 1.9232, 3.0000]])\n",
      "Training data shapes: torch.Size([161, 6]), torch.Size([161, 1]), torch.Size([161, 1]), torch.Size([161, 1])\n",
      "Iteration 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -0.2742004181658775\n",
      "Next point to sample: tensor([[1., 1., 1., 1., 3.]])\n",
      "Training data shapes: torch.Size([162, 6]), torch.Size([162, 1]), torch.Size([162, 1]), torch.Size([162, 1])\n",
      "Iteration 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -0.20934730557553483\n",
      "Next point to sample: tensor([[1.0000, 1.0000, 1.0000, 1.6095, 3.0000]])\n",
      "Training data shapes: torch.Size([163, 6]), torch.Size([163, 1]), torch.Size([163, 1]), torch.Size([163, 1])\n",
      "Iteration 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -0.5058022826629829\n",
      "Next point to sample: tensor([[1.0000, 3.0000, 1.0000, 1.4059, 2.6801]])\n",
      "Training data shapes: torch.Size([164, 6]), torch.Size([164, 1]), torch.Size([164, 1]), torch.Size([164, 1])\n",
      "Iteration 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -0.5540553148040059\n",
      "Next point to sample: tensor([[2.9025, 3.0000, 1.0000, 2.2145, 3.0000]])\n",
      "Training data shapes: torch.Size([165, 6]), torch.Size([165, 1]), torch.Size([165, 1]), torch.Size([165, 1])\n",
      "Iteration 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -0.6734304295334441\n",
      "Next point to sample: tensor([[1.9486, 3.0000, 1.0000, 2.3034, 3.0000]])\n",
      "Training data shapes: torch.Size([166, 6]), torch.Size([166, 1]), torch.Size([166, 1]), torch.Size([166, 1])\n",
      "Iteration 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -0.841562477830033\n",
      "Next point to sample: tensor([[2.3664, 3.0000, 1.0000, 1.6966, 3.0000]])\n",
      "Training data shapes: torch.Size([167, 6]), torch.Size([167, 1]), torch.Size([167, 1]), torch.Size([167, 1])\n",
      "Iteration 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -1.157737001078782\n",
      "Next point to sample: tensor([[2.9763, 3.0000, 1.0000, 2.4595, 2.2941]])\n",
      "Training data shapes: torch.Size([168, 6]), torch.Size([168, 1]), torch.Size([168, 1]), torch.Size([168, 1])\n",
      "Iteration 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -0.9285856581258738\n",
      "Next point to sample: tensor([[1., 3., 1., 1., 3.]])\n",
      "Training data shapes: torch.Size([169, 6]), torch.Size([169, 1]), torch.Size([169, 1]), torch.Size([169, 1])\n",
      "Iteration 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -0.9773412412235674\n",
      "Next point to sample: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 2.0341]])\n",
      "Training data shapes: torch.Size([170, 6]), torch.Size([170, 1]), torch.Size([170, 1]), torch.Size([170, 1])\n",
      "Iteration 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -1.4603699189977575\n",
      "Next point to sample: tensor([[1.5270, 3.0000, 1.0000, 1.3183, 3.0000]])\n",
      "Training data shapes: torch.Size([171, 6]), torch.Size([171, 1]), torch.Size([171, 1]), torch.Size([171, 1])\n",
      "Iteration 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -2.41286313947126\n",
      "Next point to sample: tensor([[2.0897, 3.0000, 1.0000, 1.9986, 2.3687]])\n",
      "Training data shapes: torch.Size([172, 6]), torch.Size([172, 1]), torch.Size([172, 1]), torch.Size([172, 1])\n",
      "Iteration 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -1.4884218122234514\n",
      "Next point to sample: tensor([[1.0798, 3.0000, 1.0000, 2.2423, 3.0000]])\n",
      "Training data shapes: torch.Size([173, 6]), torch.Size([173, 1]), torch.Size([173, 1]), torch.Size([173, 1])\n",
      "Iteration 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -1.6664706728667502\n",
      "Next point to sample: tensor([[2.3874, 3.0000, 1.0000, 2.5596, 2.8124]])\n",
      "Training data shapes: torch.Size([174, 6]), torch.Size([174, 1]), torch.Size([174, 1]), torch.Size([174, 1])\n",
      "Iteration 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -1.693937135428679\n",
      "Next point to sample: tensor([[2.2150, 3.0000, 1.0000, 2.0274, 3.0000]])\n",
      "Training data shapes: torch.Size([175, 6]), torch.Size([175, 1]), torch.Size([175, 1]), torch.Size([175, 1])\n",
      "Iteration 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -2.174351969626374\n",
      "Next point to sample: tensor([[2.8463, 3.0000, 1.0000, 1.8214, 2.7164]])\n",
      "Training data shapes: torch.Size([176, 6]), torch.Size([176, 1]), torch.Size([176, 1]), torch.Size([176, 1])\n",
      "Iteration 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -1.2204013458945857\n",
      "Next point to sample: tensor([[1.0000, 1.9972, 1.0000, 1.0000, 1.0000]])\n",
      "Training data shapes: torch.Size([177, 6]), torch.Size([177, 1]), torch.Size([177, 1]), torch.Size([177, 1])\n",
      "Iteration 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -1.693511435344182\n",
      "Next point to sample: tensor([[1.0000, 3.0000, 1.0000, 1.2886, 3.0000]])\n",
      "Training data shapes: torch.Size([178, 6]), torch.Size([178, 1]), torch.Size([178, 1]), torch.Size([178, 1])\n",
      "Iteration 28/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -2.3512241657091497\n",
      "Next point to sample: tensor([[2.9683, 3.0000, 1.0000, 1.9149, 3.0000]])\n",
      "Training data shapes: torch.Size([179, 6]), torch.Size([179, 1]), torch.Size([179, 1]), torch.Size([179, 1])\n",
      "Iteration 29/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -1.986107555058291\n",
      "Next point to sample: tensor([[1.0000, 1.0000, 1.0000, 2.0966, 3.0000]])\n",
      "Training data shapes: torch.Size([180, 6]), torch.Size([180, 1]), torch.Size([180, 1]), torch.Size([180, 1])\n",
      "Iteration 30/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -2.001137652968503\n",
      "Next point to sample: tensor([[3.0000, 3.0000, 1.0000, 2.5480, 3.0000]])\n",
      "Training data shapes: torch.Size([181, 6]), torch.Size([181, 1]), torch.Size([181, 1]), torch.Size([181, 1])\n",
      "Iteration 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -2.005775743716141\n",
      "Next point to sample: tensor([[1.0000, 3.0000, 1.0000, 1.8540, 3.0000]])\n",
      "Training data shapes: torch.Size([182, 6]), torch.Size([182, 1]), torch.Size([182, 1]), torch.Size([182, 1])\n",
      "Iteration 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\optim\\optimize.py:367: RuntimeWarning: Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
      "[NumericalWarning('A not p.d., added jitter of 1.0e-08 to the diagonal'), OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.'), NumericalWarning('A not p.d., added jitter of 1.0e-08 to the diagonal')]\n",
      "Trying again with a new set of initial conditions.\n",
      "  warnings.warn(first_warn_msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -2.621076266165841\n",
      "Next point to sample: tensor([[1.0000, 1.0000, 2.6023, 2.8553, 3.0000]])\n",
      "Training data shapes: torch.Size([183, 6]), torch.Size([183, 1]), torch.Size([183, 1]), torch.Size([183, 1])\n",
      "Iteration 33/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -2.774658780956722\n",
      "Next point to sample: tensor([[1.0000, 1.0000, 1.0000, 1.1552, 2.1719]])\n",
      "Training data shapes: torch.Size([184, 6]), torch.Size([184, 1]), torch.Size([184, 1]), torch.Size([184, 1])\n",
      "Iteration 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -2.4798582234033435\n",
      "Next point to sample: tensor([[1.0000, 1.0000, 2.8120, 2.4390, 3.0000]])\n",
      "Training data shapes: torch.Size([185, 6]), torch.Size([185, 1]), torch.Size([185, 1]), torch.Size([185, 1])\n",
      "Iteration 35/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -2.3600864896173146\n",
      "Next point to sample: tensor([[2.0162, 1.0000, 1.0000, 1.0000, 3.0000]])\n",
      "Training data shapes: torch.Size([186, 6]), torch.Size([186, 1]), torch.Size([186, 1]), torch.Size([186, 1])\n",
      "Iteration 36/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -2.1834570156885618\n",
      "Next point to sample: tensor([[1.0000, 1.0000, 1.0000, 1.2358, 3.0000]])\n",
      "Training data shapes: torch.Size([187, 6]), torch.Size([187, 1]), torch.Size([187, 1]), torch.Size([187, 1])\n",
      "Iteration 37/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -1.3071994698148162\n",
      "Next point to sample: tensor([[1.0000, 3.0000, 3.0000, 1.0000, 2.6384]])\n",
      "Training data shapes: torch.Size([188, 6]), torch.Size([188, 1]), torch.Size([188, 1]), torch.Size([188, 1])\n",
      "Iteration 38/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -1.235942202294333\n",
      "Next point to sample: tensor([[1.0000, 1.0000, 2.2550, 2.2630, 3.0000]])\n",
      "Training data shapes: torch.Size([189, 6]), torch.Size([189, 1]), torch.Size([189, 1]), torch.Size([189, 1])\n",
      "Iteration 39/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -2.238519388971401\n",
      "Next point to sample: tensor([[1.0000, 1.0000, 1.0000, 1.7373, 1.9927]])\n",
      "Training data shapes: torch.Size([190, 6]), torch.Size([190, 1]), torch.Size([190, 1]), torch.Size([190, 1])\n",
      "Iteration 40/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -3.335358453580159\n",
      "Next point to sample: tensor([[1.0000, 1.2906, 1.0000, 1.0000, 1.8498]])\n",
      "Training data shapes: torch.Size([191, 6]), torch.Size([191, 1]), torch.Size([191, 1]), torch.Size([191, 1])\n",
      "Iteration 41/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -3.054922870617716\n",
      "Next point to sample: tensor([[1.0000, 3.0000, 1.0000, 2.8242, 3.0000]])\n",
      "Training data shapes: torch.Size([192, 6]), torch.Size([192, 1]), torch.Size([192, 1]), torch.Size([192, 1])\n",
      "Iteration 42/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -0.3421317571525835\n",
      "Next point to sample: tensor([[1.0000, 3.0000, 1.9586, 1.0000, 1.0000]])\n",
      "Training data shapes: torch.Size([193, 6]), torch.Size([193, 1]), torch.Size([193, 1]), torch.Size([193, 1])\n",
      "Iteration 43/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -2.1437000823745116\n",
      "Next point to sample: tensor([[1.0000, 1.0000, 3.0000, 2.7992, 3.0000]])\n",
      "Training data shapes: torch.Size([194, 6]), torch.Size([194, 1]), torch.Size([194, 1]), torch.Size([194, 1])\n",
      "Iteration 44/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -2.0782209551629127\n",
      "Next point to sample: tensor([[1.0000, 3.0000, 1.0000, 1.5317, 3.0000]])\n",
      "Training data shapes: torch.Size([195, 6]), torch.Size([195, 1]), torch.Size([195, 1]), torch.Size([195, 1])\n",
      "Iteration 45/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -2.681980493888398\n",
      "Next point to sample: tensor([[1.0000, 1.0000, 1.3566, 1.3811, 3.0000]])\n",
      "Training data shapes: torch.Size([196, 6]), torch.Size([196, 1]), torch.Size([196, 1]), torch.Size([196, 1])\n",
      "Iteration 46/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -1.917562255614055\n",
      "Next point to sample: tensor([[1.0000, 3.0000, 3.0000, 1.0000, 2.0881]])\n",
      "Training data shapes: torch.Size([197, 6]), torch.Size([197, 1]), torch.Size([197, 1]), torch.Size([197, 1])\n",
      "Iteration 47/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -2.108949176029746\n",
      "Next point to sample: tensor([[1.4406, 1.0000, 3.0000, 3.0000, 3.0000]])\n",
      "Training data shapes: torch.Size([198, 6]), torch.Size([198, 1]), torch.Size([198, 1]), torch.Size([198, 1])\n",
      "Iteration 48/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -2.9320285193416495\n",
      "Next point to sample: tensor([[1.8892, 3.0000, 1.0000, 1.0000, 3.0000]])\n",
      "Training data shapes: torch.Size([199, 6]), torch.Size([199, 1]), torch.Size([199, 1]), torch.Size([199, 1])\n",
      "Iteration 49/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -3.2839395437365\n",
      "Next point to sample: tensor([[1.7348, 3.0000, 1.0000, 2.2652, 1.7348]])\n",
      "Training data shapes: torch.Size([200, 6]), torch.Size([200, 1]), torch.Size([200, 1]), torch.Size([200, 1])\n",
      "Iteration 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\optim\\optimize.py:367: RuntimeWarning: Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
      "[NumericalWarning('A not p.d., added jitter of 1.0e-08 to the diagonal'), NumericalWarning('A not p.d., added jitter of 1.0e-08 to the diagonal'), OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.'), NumericalWarning('A not p.d., added jitter of 1.0e-08 to the diagonal')]\n",
      "Trying again with a new set of initial conditions.\n",
      "  warnings.warn(first_warn_msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value: -3.534681759091437\n",
      "Next point to sample: tensor([[1.0000, 1.0000, 1.0000, 1.4330, 3.0000]])\n",
      "Training data shapes: torch.Size([201, 6]), torch.Size([201, 1]), torch.Size([201, 1]), torch.Size([201, 1])\n"
     ]
    }
   ],
   "source": [
    "train_X, train_Y1, train_Y2, train_Y3 = optimize_vehicle_safety(new_modellist, train_X, train_Y1, train_Y2, train_Y3, bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([201, 1])\n"
     ]
    }
   ],
   "source": [
    "print(train_Y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y = torch.cat([train_Y1, train_Y2, train_Y3], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([201, 3])\n"
     ]
    }
   ],
   "source": [
    "print(train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.6151, 2.0840, 1.5571, 1.0127, 2.8532, 0.0000],\n",
      "        [2.5334, 2.3375, 1.9577, 2.1742, 1.3223, 0.0000],\n",
      "        [2.3148, 2.0759, 2.3564, 2.5278, 2.2090, 0.0000],\n",
      "        ...,\n",
      "        [1.8892, 3.0000, 1.0000, 1.0000, 3.0000, 2.0000],\n",
      "        [1.7348, 3.0000, 1.0000, 2.2652, 1.7348, 2.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.4330, 3.0000, 2.0000]], dtype=torch.float64)\n",
      "torch.Size([201, 6])\n"
     ]
    }
   ],
   "source": [
    "train_X\n",
    "print(train_X)\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.9513, 1.9903, 2.2015, 2.5421, 2.9619],\n",
      "        [1.0000, 3.0000, 3.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 3.0000, 1.0000, 1.0000, 1.9622],\n",
      "        [1.3201, 3.0000, 1.0000, 1.6333, 2.7671],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 3.0000, 3.0000, 1.0000, 3.0000],\n",
      "        [2.1457, 3.0000, 1.0000, 2.0286, 2.5711],\n",
      "        [1.0000, 1.0000, 1.0000, 1.3667, 2.3094],\n",
      "        [1.0000, 3.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 3.0000, 1.0000, 1.1486, 3.0000],\n",
      "        [1.0000, 1.0000, 1.6194, 1.9232, 3.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 3.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.6095, 3.0000],\n",
      "        [1.0000, 3.0000, 1.0000, 1.4059, 2.6801],\n",
      "        [2.9025, 3.0000, 1.0000, 2.2145, 3.0000],\n",
      "        [1.9486, 3.0000, 1.0000, 2.3034, 3.0000],\n",
      "        [2.3664, 3.0000, 1.0000, 1.6966, 3.0000],\n",
      "        [2.9763, 3.0000, 1.0000, 2.4595, 2.2941],\n",
      "        [1.0000, 3.0000, 1.0000, 1.0000, 3.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 2.0341],\n",
      "        [1.5270, 3.0000, 1.0000, 1.3183, 3.0000],\n",
      "        [2.0897, 3.0000, 1.0000, 1.9986, 2.3687],\n",
      "        [1.0798, 3.0000, 1.0000, 2.2423, 3.0000],\n",
      "        [2.3874, 3.0000, 1.0000, 2.5596, 2.8124],\n",
      "        [2.2150, 3.0000, 1.0000, 2.0274, 3.0000],\n",
      "        [2.8463, 3.0000, 1.0000, 1.8214, 2.7164],\n",
      "        [1.0000, 1.9972, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 3.0000, 1.0000, 1.2886, 3.0000],\n",
      "        [2.9683, 3.0000, 1.0000, 1.9149, 3.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 2.0966, 3.0000],\n",
      "        [3.0000, 3.0000, 1.0000, 2.5480, 3.0000],\n",
      "        [1.0000, 3.0000, 1.0000, 1.8540, 3.0000],\n",
      "        [1.0000, 1.0000, 2.6023, 2.8553, 3.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.1552, 2.1719],\n",
      "        [1.0000, 1.0000, 2.8120, 2.4390, 3.0000],\n",
      "        [2.0162, 1.0000, 1.0000, 1.0000, 3.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.2358, 3.0000],\n",
      "        [1.0000, 3.0000, 3.0000, 1.0000, 2.6384],\n",
      "        [1.0000, 1.0000, 2.2550, 2.2630, 3.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.7373, 1.9927],\n",
      "        [1.0000, 1.2906, 1.0000, 1.0000, 1.8498],\n",
      "        [1.0000, 3.0000, 1.0000, 2.8242, 3.0000],\n",
      "        [1.0000, 3.0000, 1.9586, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 3.0000, 2.7992, 3.0000],\n",
      "        [1.0000, 3.0000, 1.0000, 1.5317, 3.0000],\n",
      "        [1.0000, 1.0000, 1.3566, 1.3811, 3.0000],\n",
      "        [1.0000, 3.0000, 3.0000, 1.0000, 2.0881],\n",
      "        [1.4406, 1.0000, 3.0000, 3.0000, 3.0000],\n",
      "        [1.8892, 3.0000, 1.0000, 1.0000, 3.0000],\n",
      "        [1.7348, 3.0000, 1.0000, 2.2652, 1.7348],\n",
      "        [1.0000, 1.0000, 1.0000, 1.4330, 3.0000]], dtype=torch.float64)\n",
      "torch.Size([51, 5])\n",
      "tensor([[-1.6924e+03, -1.0578e+01, -1.0246e-01],\n",
      "        [-1.6755e+03, -6.1428e+00, -2.6400e-01],\n",
      "        [-1.6706e+03, -7.0276e+00, -8.4902e-02],\n",
      "        [-1.6799e+03, -8.5452e+00, -6.0086e-02],\n",
      "        [-1.6617e+03, -8.3046e+00, -7.0800e-02],\n",
      "        [-1.6844e+03, -6.3150e+00, -2.1600e-01],\n",
      "        [-1.6840e+03, -9.5432e+00, -5.2238e-02],\n",
      "        [-1.6704e+03, -8.8746e+00, -5.7977e-02],\n",
      "        [-1.6664e+03, -6.9448e+00, -9.2600e-02],\n",
      "        [-1.6764e+03, -7.4045e+00, -7.1788e-02],\n",
      "        [-1.6806e+03, -9.7644e+00, -5.6264e-02],\n",
      "        [-1.6706e+03, -8.4768e+00, -5.4800e-02],\n",
      "        [-1.6753e+03, -9.2631e+00, -5.2510e-02],\n",
      "        [-1.6770e+03, -7.8929e+00, -6.7155e-02],\n",
      "        [-1.6891e+03, -9.9960e+00, -4.4155e-02],\n",
      "        [-1.6876e+03, -1.0123e+01, -4.7197e-02],\n",
      "        [-1.6839e+03, -9.0908e+00, -5.3012e-02],\n",
      "        [-1.6880e+03, -1.0215e+01, -4.8332e-02],\n",
      "        [-1.6753e+03, -7.1170e+00, -7.6600e-02],\n",
      "        [-1.6663e+03, -8.3936e+00, -6.2527e-02],\n",
      "        [-1.6790e+03, -8.0804e+00, -6.4879e-02],\n",
      "        [-1.6827e+03, -9.4423e+00, -5.4426e-02],\n",
      "        [-1.6850e+03, -9.7876e+00, -5.0881e-02],\n",
      "        [-1.6897e+03, -1.0605e+01, -4.6315e-02],\n",
      "        [-1.6861e+03, -9.6325e+00, -4.8557e-02],\n",
      "        [-1.6847e+03, -9.3060e+00, -5.1279e-02],\n",
      "        [-1.6640e+03, -7.6266e+00, -1.0577e-01],\n",
      "        [-1.6775e+03, -7.6823e+00, -6.7696e-02],\n",
      "        [-1.6870e+03, -9.5258e+00, -4.7138e-02],\n",
      "        [-1.6791e+03, -9.9856e+00, -5.6503e-02],\n",
      "        [-1.6919e+03, -1.0542e+01, -4.2488e-02],\n",
      "        [-1.6819e+03, -8.8751e+00, -5.5514e-02],\n",
      "        [-1.6923e+03, -1.0854e+01, -4.7150e-02],\n",
      "        [-1.6681e+03, -8.5933e+00, -6.0073e-02],\n",
      "        [-1.6900e+03, -9.9343e+00, -4.8533e-02],\n",
      "        [-1.6730e+03, -9.1934e+00, -6.5775e-02],\n",
      "        [-1.6724e+03, -8.7654e+00, -5.2954e-02],\n",
      "        [-1.6828e+03, -6.2839e+00, -2.2468e-01],\n",
      "        [-1.6861e+03, -1.0070e+01, -5.3950e-02],\n",
      "        [-1.6718e+03, -9.3578e+00, -6.1116e-02],\n",
      "        [-1.6662e+03, -8.1802e+00, -7.9143e-02],\n",
      "        [-1.6893e+03, -1.1185e+01, -5.0849e-02],\n",
      "        [-1.6707e+03, -6.9035e+00, -1.7475e-01],\n",
      "        [-1.6936e+03, -1.0373e+01, -4.1365e-02],\n",
      "        [-1.6794e+03, -8.1814e+00, -6.1604e-02],\n",
      "        [-1.6752e+03, -9.0115e+00, -5.7386e-02],\n",
      "        [-1.6803e+03, -6.2365e+00, -2.3789e-01],\n",
      "        [-1.6962e+03, -1.0759e+01, -4.4158e-02],\n",
      "        [-1.6774e+03, -7.7566e+00, -7.3221e-02],\n",
      "        [-1.6811e+03, -9.8220e+00, -5.8360e-02],\n",
      "        [-1.6740e+03, -9.0219e+00, -5.2340e-02]], dtype=torch.float64)\n",
      "torch.Size([51, 3])\n"
     ]
    }
   ],
   "source": [
    "indices = train_X[:, -1]\n",
    "\n",
    "mask = indices == 2\n",
    "\n",
    "filtered_train_Y = train_Y[mask]\n",
    "\n",
    "filtered_train_X = train_X[mask]\n",
    "\n",
    "filtered_train_X_new = X_baseline_no_task = filtered_train_X[:, :-1]\n",
    "\n",
    "\n",
    "print(filtered_train_X_new)\n",
    "print(filtered_train_X_new.shape)\n",
    "print(filtered_train_Y)\n",
    "print(filtered_train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6924e+03, -1.0578e+01, -1.0246e-01],\n",
      "        [-1.6755e+03, -6.1428e+00, -2.6400e-01],\n",
      "        [-1.6706e+03, -7.0276e+00, -8.4902e-02],\n",
      "        [-1.6799e+03, -8.5452e+00, -6.0086e-02],\n",
      "        [-1.6617e+03, -8.3046e+00, -7.0800e-02],\n",
      "        [-1.6844e+03, -6.3150e+00, -2.1600e-01],\n",
      "        [-1.6840e+03, -9.5432e+00, -5.2238e-02],\n",
      "        [-1.6704e+03, -8.8746e+00, -5.7977e-02],\n",
      "        [-1.6664e+03, -6.9448e+00, -9.2600e-02],\n",
      "        [-1.6764e+03, -7.4045e+00, -7.1788e-02],\n",
      "        [-1.6806e+03, -9.7644e+00, -5.6264e-02],\n",
      "        [-1.6706e+03, -8.4768e+00, -5.4800e-02],\n",
      "        [-1.6753e+03, -9.2631e+00, -5.2510e-02],\n",
      "        [-1.6770e+03, -7.8929e+00, -6.7155e-02],\n",
      "        [-1.6891e+03, -9.9960e+00, -4.4155e-02],\n",
      "        [-1.6876e+03, -1.0123e+01, -4.7197e-02],\n",
      "        [-1.6839e+03, -9.0908e+00, -5.3012e-02],\n",
      "        [-1.6880e+03, -1.0215e+01, -4.8333e-02],\n",
      "        [-1.6753e+03, -7.1170e+00, -7.6600e-02],\n",
      "        [-1.6663e+03, -8.3936e+00, -6.2527e-02],\n",
      "        [-1.6790e+03, -8.0804e+00, -6.4879e-02],\n",
      "        [-1.6827e+03, -9.4423e+00, -5.4426e-02],\n",
      "        [-1.6850e+03, -9.7876e+00, -5.0881e-02],\n",
      "        [-1.6897e+03, -1.0605e+01, -4.6315e-02],\n",
      "        [-1.6861e+03, -9.6325e+00, -4.8557e-02],\n",
      "        [-1.6847e+03, -9.3060e+00, -5.1279e-02],\n",
      "        [-1.6640e+03, -7.6266e+00, -1.0577e-01],\n",
      "        [-1.6775e+03, -7.6823e+00, -6.7696e-02],\n",
      "        [-1.6870e+03, -9.5258e+00, -4.7138e-02],\n",
      "        [-1.6791e+03, -9.9856e+00, -5.6503e-02],\n",
      "        [-1.6919e+03, -1.0542e+01, -4.2488e-02],\n",
      "        [-1.6819e+03, -8.8751e+00, -5.5514e-02],\n",
      "        [-1.6923e+03, -1.0854e+01, -4.7150e-02],\n",
      "        [-1.6681e+03, -8.5933e+00, -6.0073e-02],\n",
      "        [-1.6900e+03, -9.9343e+00, -4.8533e-02],\n",
      "        [-1.6730e+03, -9.1934e+00, -6.5775e-02],\n",
      "        [-1.6724e+03, -8.7654e+00, -5.2954e-02],\n",
      "        [-1.6828e+03, -6.2839e+00, -2.2468e-01],\n",
      "        [-1.6861e+03, -1.0070e+01, -5.3950e-02],\n",
      "        [-1.6718e+03, -9.3578e+00, -6.1116e-02],\n",
      "        [-1.6662e+03, -8.1802e+00, -7.9143e-02],\n",
      "        [-1.6893e+03, -1.1185e+01, -5.0849e-02],\n",
      "        [-1.6707e+03, -6.9035e+00, -1.7475e-01],\n",
      "        [-1.6936e+03, -1.0373e+01, -4.1365e-02],\n",
      "        [-1.6794e+03, -8.1814e+00, -6.1604e-02],\n",
      "        [-1.6752e+03, -9.0115e+00, -5.7386e-02],\n",
      "        [-1.6803e+03, -6.2365e+00, -2.3789e-01],\n",
      "        [-1.6962e+03, -1.0759e+01, -4.4158e-02],\n",
      "        [-1.6774e+03, -7.7566e+00, -7.3221e-02],\n",
      "        [-1.6811e+03, -9.8220e+00, -5.8360e-02],\n",
      "        [-1.6740e+03, -9.0219e+00, -5.2340e-02]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "test_XX, exp = generate_car_crash_synthetic_data(filtered_train_X_new, 0.0)\n",
    "\n",
    "print(test_XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non_dominated points: tensor([[-1.6755e+03, -6.1428e+00, -2.6400e-01],\n",
      "        [-1.6706e+03, -7.0276e+00, -8.4902e-02],\n",
      "        [-1.6617e+03, -8.3046e+00, -7.0800e-02],\n",
      "        [-1.6844e+03, -6.3150e+00, -2.1600e-01],\n",
      "        [-1.6840e+03, -9.5432e+00, -5.2238e-02],\n",
      "        [-1.6704e+03, -8.8746e+00, -5.7977e-02],\n",
      "        [-1.6664e+03, -6.9448e+00, -9.2600e-02],\n",
      "        [-1.6764e+03, -7.4045e+00, -7.1788e-02],\n",
      "        [-1.6706e+03, -8.4768e+00, -5.4800e-02],\n",
      "        [-1.6770e+03, -7.8929e+00, -6.7155e-02],\n",
      "        [-1.6891e+03, -9.9960e+00, -4.4155e-02],\n",
      "        [-1.6753e+03, -7.1170e+00, -7.6600e-02],\n",
      "        [-1.6663e+03, -8.3936e+00, -6.2527e-02],\n",
      "        [-1.6790e+03, -8.0804e+00, -6.4879e-02],\n",
      "        [-1.6850e+03, -9.7876e+00, -5.0881e-02],\n",
      "        [-1.6861e+03, -9.6325e+00, -4.8557e-02],\n",
      "        [-1.6847e+03, -9.3060e+00, -5.1279e-02],\n",
      "        [-1.6640e+03, -7.6266e+00, -1.0577e-01],\n",
      "        [-1.6775e+03, -7.6823e+00, -6.7696e-02],\n",
      "        [-1.6870e+03, -9.5258e+00, -4.7138e-02],\n",
      "        [-1.6919e+03, -1.0542e+01, -4.2488e-02],\n",
      "        [-1.6681e+03, -8.5933e+00, -6.0073e-02],\n",
      "        [-1.6724e+03, -8.7654e+00, -5.2954e-02],\n",
      "        [-1.6828e+03, -6.2839e+00, -2.2468e-01],\n",
      "        [-1.6662e+03, -8.1802e+00, -7.9143e-02],\n",
      "        [-1.6707e+03, -6.9035e+00, -1.7475e-01],\n",
      "        [-1.6936e+03, -1.0373e+01, -4.1365e-02],\n",
      "        [-1.6794e+03, -8.1814e+00, -6.1604e-02],\n",
      "        [-1.6803e+03, -6.2365e+00, -2.3789e-01],\n",
      "        [-1.6740e+03, -9.0219e+00, -5.2340e-02]], dtype=torch.float64)\n",
      "tensor([-1.8647e+03, -1.1820e+01, -2.9040e-01], dtype=torch.float64)\n",
      "Final Hypervolume: 242.06782513945595\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from botorch.utils.multi_objective.box_decompositions.dominated import DominatedPartitioning\n",
    "from botorch.utils.multi_objective.pareto import is_non_dominated\n",
    "\n",
    "def calculate_final_hypervolume(train_Y_points, ref_point):\n",
    "    # Ensure train_Y is a 2D tensor and convert to float64 type\n",
    "    if train_Y_points.dim() == 1:\n",
    "        train_Y_points = train_Y_points.unsqueeze(0)\n",
    "    \n",
    "    train_Y_points = train_Y_points.to(torch.float64)\n",
    "    ref_point = ref_point.to(torch.float64)\n",
    "\n",
    "    # Filter out the non-dominated points\n",
    "    is_non_dominated_mask = is_non_dominated(train_Y_points)\n",
    "    non_dominated_points = train_Y_points[is_non_dominated_mask]\n",
    "\n",
    "    print(f\"non_dominated points: {non_dominated_points}\")\n",
    "    print(ref_point)\n",
    "    \n",
    "    # Compute the hypervolume\n",
    "    bd = DominatedPartitioning(ref_point=ref_point, Y=non_dominated_points)\n",
    "    hypervolume = bd.compute_hypervolume().item()\n",
    "    \n",
    "    return hypervolume, non_dominated_points\n",
    "\n",
    "# Example usage:\n",
    "ref_point = torch.tensor([-1864.72022, -11.81993945, -0.2903999384], dtype=torch.float64)\n",
    "\n",
    "\n",
    "final_hypervolume, non_dom_points = calculate_final_hypervolume(filtered_train_Y, ref_point)\n",
    "print(f\"Final Hypervolume: {final_hypervolume}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def create_pairplots(tensor):\n",
    "    \"\"\"\n",
    "    Creates pair plots for the three dimensions of the input tensor.\n",
    "\n",
    "    Args:\n",
    "    tensor (torch.Tensor): A tensor of shape [n, 3]\n",
    "\n",
    "    Returns:\n",
    "    None: Displays the pair plots.\n",
    "    \"\"\"\n",
    "    # Convert the tensor to a Pandas DataFrame for easier plotting with Seaborn\n",
    "    df = pd.DataFrame(tensor.numpy(), columns=['Dim1', 'Dim2', 'Dim3'])\n",
    "    \n",
    "    # Create pair plots for each pair of dimensions\n",
    "    sns.pairplot(df)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 750x750 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "non_dom_points = -non_dom_points\n",
    "create_pairplots(non_dom_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.9247, 0.6232, 2.7569, 1.7187, 2.3613, 0.0000],\n",
      "        [2.1386, 1.0810, 2.0433, 1.0326, 2.8096, 0.0000],\n",
      "        [1.9198, 0.0873, 2.3361, 1.2222, 2.4713, 0.0000],\n",
      "        [2.5457, 1.6820, 0.3760, 0.3295, 2.3937, 0.0000],\n",
      "        [1.0364, 2.2293, 1.4836, 0.9493, 1.9669, 0.0000],\n",
      "        [1.7101, 0.6485, 2.4573, 2.2737, 0.0276, 0.0000],\n",
      "        [1.1502, 2.9806, 1.9923, 1.0980, 1.0318, 0.0000],\n",
      "        [2.2174, 2.8534, 2.4883, 1.2107, 0.9697, 0.0000],\n",
      "        [0.4827, 2.4407, 1.6537, 0.1218, 2.8277, 0.0000],\n",
      "        [2.3530, 1.6258, 1.7168, 2.1694, 0.9787, 0.0000],\n",
      "        [2.4652, 0.2077, 2.8203, 1.6549, 2.4798, 0.0000],\n",
      "        [2.6177, 1.0288, 2.8193, 0.5612, 1.6197, 0.0000],\n",
      "        [2.4013, 0.7797, 0.4519, 2.5350, 2.0968, 0.0000],\n",
      "        [2.7104, 2.7646, 2.3751, 0.0652, 0.5833, 0.0000],\n",
      "        [2.5060, 0.5138, 2.4884, 2.6837, 1.8664, 0.0000],\n",
      "        [1.3624, 0.3832, 1.2960, 1.3035, 1.6263, 0.0000],\n",
      "        [1.7419, 2.5283, 0.7952, 1.6990, 2.6775, 0.0000],\n",
      "        [1.2433, 0.7719, 2.5990, 0.0054, 2.1716, 0.0000],\n",
      "        [2.2666, 1.4192, 0.2921, 1.9433, 2.4494, 0.0000],\n",
      "        [2.6712, 1.2617, 0.2701, 2.2349, 1.6257, 0.0000],\n",
      "        [0.2888, 2.4603, 2.2945, 1.7029, 1.8512, 0.0000],\n",
      "        [2.2564, 1.3512, 1.5010, 1.3993, 0.6689, 0.0000],\n",
      "        [1.5567, 0.2841, 0.6933, 0.4740, 2.8847, 0.0000],\n",
      "        [0.6666, 0.6410, 1.5768, 2.8422, 2.1764, 0.0000],\n",
      "        [2.5082, 0.9160, 2.0756, 1.8821, 2.1094, 0.0000],\n",
      "        [1.6948, 1.9519, 0.6984, 1.9703, 0.0926, 0.0000],\n",
      "        [1.6491, 2.6673, 2.3911, 0.2964, 1.9873, 0.0000],\n",
      "        [0.8714, 1.9122, 0.0331, 1.9111, 2.6276, 0.0000],\n",
      "        [0.2598, 0.3851, 0.8277, 1.7129, 2.0364, 0.0000],\n",
      "        [0.7719, 2.3460, 1.7379, 1.3322, 2.8577, 0.0000],\n",
      "        [1.4134, 1.5322, 2.9828, 2.7446, 2.5307, 0.0000],\n",
      "        [0.6010, 0.0861, 2.0216, 2.3900, 0.6593, 0.0000],\n",
      "        [2.8942, 1.9641, 2.7865, 2.8148, 0.4511, 0.0000],\n",
      "        [1.8141, 0.0810, 0.5746, 0.8852, 2.7956, 0.0000],\n",
      "        [0.5536, 2.9582, 2.1394, 1.8497, 1.8321, 0.0000],\n",
      "        [0.7637, 2.0073, 0.7717, 1.9103, 2.2529, 0.0000],\n",
      "        [0.1199, 1.2493, 2.7325, 2.8775, 0.7080, 0.0000],\n",
      "        [0.7183, 1.5011, 2.1317, 2.6998, 1.7263, 0.0000],\n",
      "        [2.0639, 0.1107, 1.7923, 0.3758, 1.4931, 0.0000],\n",
      "        [2.7457, 2.8356, 0.8523, 0.1634, 0.5242, 0.0000],\n",
      "        [0.9041, 0.1727, 0.5628, 1.3509, 0.6867, 0.0000],\n",
      "        [2.0709, 1.1288, 0.2245, 0.1308, 2.0299, 0.0000],\n",
      "        [1.8521, 0.6389, 0.9581, 1.0810, 2.2581, 0.0000],\n",
      "        [1.1080, 2.1728, 1.5665, 1.3340, 2.2248, 0.0000],\n",
      "        [2.7137, 0.4441, 1.7086, 2.9272, 1.5145, 0.0000],\n",
      "        [1.0317, 0.8633, 0.8518, 1.9410, 2.0843, 0.0000],\n",
      "        [0.7044, 1.1861, 2.8456, 2.6602, 2.8009, 0.0000],\n",
      "        [2.6683, 1.7955, 2.4007, 1.4944, 1.1793, 0.0000],\n",
      "        [0.8782, 0.9222, 2.3675, 2.5441, 2.9553, 0.0000],\n",
      "        [2.9709, 2.8388, 1.3147, 2.2251, 1.2911, 0.0000],\n",
      "        [2.9387, 2.2457, 2.1179, 2.4674, 1.9834, 1.0000],\n",
      "        [1.2853, 1.8067, 1.7360, 0.2942, 0.1926, 1.0000],\n",
      "        [1.6443, 0.9954, 1.5407, 1.6713, 2.3505, 1.0000],\n",
      "        [1.8001, 1.7733, 1.9449, 0.4176, 2.0102, 1.0000],\n",
      "        [0.9233, 0.4677, 2.1473, 1.6056, 0.6799, 1.0000],\n",
      "        [2.8221, 0.2918, 2.2495, 1.7590, 0.6282, 1.0000],\n",
      "        [1.7075, 0.8019, 0.1019, 1.3023, 0.1969, 1.0000],\n",
      "        [0.4592, 0.0756, 0.1332, 0.8099, 0.8521, 1.0000],\n",
      "        [2.9699, 1.1820, 2.4070, 1.2192, 0.5742, 1.0000],\n",
      "        [2.7338, 1.3998, 2.3278, 2.1584, 1.7991, 1.0000],\n",
      "        [2.9767, 0.0253, 0.1726, 2.5013, 2.8127, 1.0000],\n",
      "        [0.4579, 0.2419, 0.5252, 1.9721, 1.0639, 1.0000],\n",
      "        [1.9879, 0.2678, 0.5983, 2.1829, 0.3294, 1.0000],\n",
      "        [1.2297, 1.7528, 2.6919, 2.9543, 0.8810, 1.0000],\n",
      "        [1.9174, 1.9398, 2.2125, 1.0109, 0.4855, 1.0000],\n",
      "        [0.8197, 0.9423, 0.7988, 1.7639, 1.3018, 1.0000],\n",
      "        [2.3352, 2.8943, 0.0232, 1.4688, 2.2367, 1.0000],\n",
      "        [2.2334, 2.9740, 1.7463, 2.8093, 2.9897, 1.0000],\n",
      "        [1.4371, 0.0923, 2.2157, 0.9469, 0.7705, 1.0000],\n",
      "        [1.6771, 0.0825, 0.5703, 1.0250, 2.2397, 1.0000],\n",
      "        [0.3235, 1.1626, 0.7955, 2.0866, 1.0704, 1.0000],\n",
      "        [2.2055, 0.5756, 0.2549, 1.2424, 1.5187, 1.0000],\n",
      "        [1.4550, 0.0930, 0.4994, 2.7069, 1.1638, 1.0000],\n",
      "        [1.9551, 1.5078, 1.7606, 0.9486, 1.1513, 1.0000],\n",
      "        [2.6115, 0.4206, 1.9410, 0.2945, 1.3302, 1.0000],\n",
      "        [2.4844, 1.0416, 2.9865, 0.1955, 1.9167, 1.0000],\n",
      "        [2.4511, 2.2616, 1.0593, 2.4018, 2.4142, 1.0000],\n",
      "        [2.8952, 1.7362, 0.8639, 0.2605, 0.1852, 1.0000],\n",
      "        [1.0619, 0.4211, 2.7687, 2.3809, 1.2063, 1.0000],\n",
      "        [0.9537, 2.2423, 2.3674, 2.4737, 1.9903, 1.0000],\n",
      "        [1.7004, 1.7222, 0.7595, 1.0605, 0.4342, 1.0000],\n",
      "        [0.5750, 2.6975, 2.4301, 0.9348, 1.9815, 1.0000],\n",
      "        [1.5844, 2.8226, 1.7904, 0.4380, 2.8464, 1.0000],\n",
      "        [2.9414, 2.8440, 2.6082, 2.4075, 2.4714, 1.0000],\n",
      "        [1.8562, 1.7602, 2.1291, 1.2327, 0.8284, 1.0000],\n",
      "        [0.4599, 2.4306, 1.9476, 1.6520, 1.5975, 1.0000],\n",
      "        [0.0151, 1.0882, 0.3513, 2.2656, 2.5461, 1.0000],\n",
      "        [0.0175, 1.1173, 1.5152, 0.8470, 0.5992, 1.0000],\n",
      "        [1.0635, 1.6566, 0.2858, 2.7093, 0.1242, 1.0000],\n",
      "        [0.0375, 1.8399, 0.9602, 1.1943, 2.7061, 1.0000],\n",
      "        [1.7015, 0.1309, 0.5498, 2.0332, 2.3989, 1.0000],\n",
      "        [0.0092, 1.6105, 1.2784, 0.1634, 2.0131, 1.0000],\n",
      "        [0.4677, 1.1459, 2.2658, 0.7614, 2.5971, 1.0000],\n",
      "        [0.3968, 0.6651, 0.8267, 0.1729, 2.8869, 1.0000],\n",
      "        [2.3386, 2.9320, 1.7193, 2.2269, 1.8073, 1.0000],\n",
      "        [2.6459, 0.0437, 1.0168, 2.6461, 2.5211, 1.0000],\n",
      "        [0.9757, 0.2520, 1.8953, 0.7888, 0.4404, 1.0000],\n",
      "        [0.6936, 1.4429, 0.8114, 1.8530, 2.7106, 1.0000],\n",
      "        [0.1017, 2.7425, 1.2163, 0.3269, 0.0949, 1.0000],\n",
      "        [1.9714, 1.6501, 1.7658, 2.0419, 0.4935, 1.0000],\n",
      "        [1.7312, 2.5138, 2.8308, 2.1087, 0.2277, 1.0000],\n",
      "        [2.8044, 2.6459, 0.4620, 0.5275, 2.9940, 1.0000],\n",
      "        [0.9938, 0.0245, 1.6207, 0.9531, 2.6762, 1.0000],\n",
      "        [0.4955, 0.3402, 2.5529, 0.8788, 0.5644, 1.0000],\n",
      "        [2.2905, 0.4135, 1.9345, 2.6202, 0.7305, 1.0000],\n",
      "        [0.9332, 1.6881, 1.9629, 0.3182, 2.2449, 1.0000],\n",
      "        [0.5793, 2.6090, 2.2068, 0.1924, 0.7752, 1.0000],\n",
      "        [0.0322, 1.0451, 1.2725, 0.7784, 2.5218, 1.0000],\n",
      "        [0.1538, 1.0091, 0.7481, 2.1707, 0.8702, 1.0000],\n",
      "        [2.7746, 2.4861, 1.7910, 2.9528, 0.1673, 1.0000],\n",
      "        [2.6679, 1.8812, 0.3546, 0.6309, 1.7196, 1.0000],\n",
      "        [0.5442, 2.6016, 0.6929, 0.4916, 0.6875, 1.0000],\n",
      "        [1.5665, 1.8155, 1.2266, 1.0462, 1.4898, 1.0000],\n",
      "        [0.6867, 0.8301, 1.8949, 2.9810, 0.0219, 1.0000],\n",
      "        [1.3946, 2.0308, 1.9502, 1.7097, 0.2969, 1.0000],\n",
      "        [0.6090, 0.4912, 0.8665, 0.5652, 1.7059, 1.0000],\n",
      "        [1.2207, 2.2789, 0.5593, 2.8241, 1.9948, 1.0000],\n",
      "        [1.3083, 1.1933, 2.9793, 0.6332, 0.6446, 1.0000],\n",
      "        [1.9686, 2.3358, 0.8889, 2.5790, 2.3153, 1.0000],\n",
      "        [1.9711, 0.2781, 0.0460, 1.3715, 2.9204, 1.0000],\n",
      "        [1.0687, 2.7778, 0.2024, 0.0626, 1.1215, 1.0000],\n",
      "        [0.9689, 1.2458, 2.3249, 1.7954, 2.8959, 1.0000],\n",
      "        [0.0925, 2.8916, 0.6687, 0.4161, 1.0138, 1.0000],\n",
      "        [1.7268, 0.9484, 1.3941, 2.7720, 1.4776, 1.0000],\n",
      "        [0.2802, 2.9088, 1.7159, 0.9686, 1.3208, 1.0000],\n",
      "        [1.2215, 2.1254, 2.4236, 2.0474, 1.8693, 1.0000],\n",
      "        [1.7910, 2.7467, 1.8605, 1.8200, 1.0038, 1.0000],\n",
      "        [2.7707, 0.7464, 0.3956, 2.9604, 0.4831, 1.0000],\n",
      "        [2.0361, 0.7660, 1.2692, 2.7397, 1.4511, 1.0000],\n",
      "        [0.7705, 0.9290, 0.8114, 0.4994, 1.0531, 1.0000],\n",
      "        [2.4648, 0.9108, 1.6459, 0.6873, 1.5663, 1.0000],\n",
      "        [1.5492, 1.3044, 1.5675, 2.7918, 1.7924, 1.0000],\n",
      "        [1.3554, 1.4428, 1.3718, 0.3499, 1.6733, 1.0000],\n",
      "        [2.1745, 0.8824, 1.6612, 1.7742, 0.2032, 1.0000],\n",
      "        [2.6483, 2.3873, 2.4791, 2.3647, 0.9152, 1.0000],\n",
      "        [1.1956, 2.6673, 0.5074, 0.0197, 0.8022, 1.0000],\n",
      "        [0.1973, 0.6510, 2.1544, 1.5274, 0.7199, 1.0000],\n",
      "        [0.1919, 2.7801, 0.6494, 0.6937, 2.6265, 1.0000],\n",
      "        [1.7708, 0.5007, 2.1753, 1.6965, 1.4043, 1.0000],\n",
      "        [0.3417, 1.9181, 1.2739, 1.7742, 0.8458, 1.0000],\n",
      "        [1.5731, 2.8811, 0.2149, 2.9478, 1.2221, 1.0000],\n",
      "        [2.5527, 0.1605, 0.5596, 0.9591, 0.2893, 1.0000],\n",
      "        [1.8434, 0.5505, 2.8127, 2.2330, 2.8284, 1.0000],\n",
      "        [1.4384, 0.1221, 1.0275, 1.7847, 1.6332, 1.0000],\n",
      "        [2.9393, 1.3699, 0.6195, 2.4514, 0.3009, 1.0000],\n",
      "        [0.1272, 0.2933, 2.4958, 0.4260, 2.8990, 1.0000],\n",
      "        [0.0667, 2.8030, 2.7474, 2.1415, 0.6911, 1.0000],\n",
      "        [2.4032, 0.5506, 2.4817, 1.5117, 0.8227, 1.0000],\n",
      "        [2.8090, 0.9623, 2.8930, 2.0974, 1.6554, 1.0000],\n",
      "        [1.4280, 1.6841, 2.9880, 0.0534, 1.3107, 1.0000],\n",
      "        [0.4497, 1.4697, 0.6582, 2.1464, 1.0634, 2.0000],\n",
      "        [0.0000, 3.0000, 0.0000, 0.0000, 2.0111, 2.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4919, 1.5264, 2.0000],\n",
      "        [0.0000, 3.0000, 0.0000, 0.0000, 0.0000, 2.0000],\n",
      "        [0.0000, 0.6852, 0.0000, 0.0000, 0.0000, 2.0000],\n",
      "        [0.0000, 0.0000, 2.1814, 1.5390, 3.0000, 2.0000],\n",
      "        [0.0000, 3.0000, 0.0000, 0.6087, 1.3285, 2.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.6452, 0.2243, 2.0000],\n",
      "        [0.0000, 3.0000, 0.0000, 0.0000, 1.0122, 2.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 1.0459, 2.0000]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.8535e+03, -1.0461e+01, -7.3818e-02],\n",
      "        [-1.8454e+03, -1.0037e+01, -1.0756e-01],\n",
      "        [-1.8437e+03, -1.0516e+01, -1.1253e-03],\n",
      "        [-1.8316e+03, -8.8778e+00, -8.7670e-02],\n",
      "        [-1.8379e+03, -8.3106e+00, -1.4290e-01],\n",
      "        [-1.8422e+03, -1.0765e+01, -9.9174e-02],\n",
      "        [-1.8393e+03, -7.9024e+00, -1.8882e-01],\n",
      "        [-1.8449e+03, -8.3922e+00, -2.2488e-01],\n",
      "        [-1.8350e+03, -6.1035e+00, -1.9033e-01],\n",
      "        [-1.8464e+03, -1.0867e+01, -1.3405e-01],\n",
      "        [-1.8516e+03, -1.0511e+01, -1.4777e-02],\n",
      "        [-1.8406e+03, -9.1690e+00, -1.8544e-01],\n",
      "        [-1.8466e+03, -1.1464e+01, -9.1454e-02],\n",
      "        [-1.8337e+03, -7.2303e+00, -3.0736e-01],\n",
      "        [-1.8566e+03, -1.1512e+01, -5.6539e-02],\n",
      "        [-1.8344e+03, -1.0272e+01, -3.2158e-02],\n",
      "        [-1.8468e+03, -9.8677e+00, -7.3741e-02],\n",
      "        [-1.8333e+03, -8.2333e+00, -1.5087e-01],\n",
      "        [-1.8438e+03, -1.0496e+01, -8.0070e-02],\n",
      "        [-1.8428e+03, -1.0705e+01, -9.2809e-02],\n",
      "        [-1.8464e+03, -8.8970e+00, -1.6671e-01],\n",
      "        [-1.8363e+03, -9.9669e+00, -1.2965e-01],\n",
      "        [-1.8307e+03, -9.8124e+00, -9.9684e-03],\n",
      "        [-1.8504e+03, -1.2324e+01, -5.2687e-02],\n",
      "        [-1.8499e+03, -1.0885e+01, -9.2035e-02],\n",
      "        [-1.8344e+03, -1.0122e+01, -9.8943e-02],\n",
      "        [-1.8397e+03, -7.0568e+00, -2.6092e-01],\n",
      "        [-1.8407e+03, -9.5613e+00, -5.9192e-02],\n",
      "        [-1.8347e+03, -1.0028e+01, -9.9211e-03],\n",
      "        [-1.8464e+03, -8.7852e+00, -1.3174e-01],\n",
      "        [-1.8626e+03, -1.1290e+01, -1.0488e-01],\n",
      "        [-1.8398e+03, -1.1325e+01, -4.3252e-03],\n",
      "        [-1.8570e+03, -1.0829e+01, -1.8003e-01],\n",
      "        [-1.8333e+03, -1.0359e+01,  5.9689e-03],\n",
      "        [-1.8487e+03, -9.3047e+00, -1.5135e-01],\n",
      "        [-1.8426e+03, -1.0004e+01, -8.3808e-02],\n",
      "        [-1.8495e+03, -1.1622e+01, -1.1574e-01],\n",
      "        [-1.8521e+03, -1.1779e+01, -1.1084e-01],\n",
      "        [-1.8295e+03, -1.0282e+01, -4.1524e-02],\n",
      "        [-1.8269e+03, -7.4807e+00, -1.2831e-01],\n",
      "        [-1.8248e+03, -9.8259e+00, -1.8185e-03],\n",
      "        [-1.8248e+03, -8.7394e+00, -6.5922e-02],\n",
      "        [-1.8358e+03, -1.0196e+01, -5.1204e-02],\n",
      "        [-1.8428e+03, -9.1167e+00, -1.3026e-01],\n",
      "        [-1.8534e+03, -1.2033e+01, -7.8549e-02],\n",
      "        [-1.8402e+03, -1.0643e+01, -5.9823e-02],\n",
      "        [-1.8598e+03, -1.1206e+01, -6.7785e-02],\n",
      "        [-1.8464e+03, -9.6430e+00, -1.8232e-01],\n",
      "        [-1.8569e+03, -1.1491e+01, -4.9404e-02],\n",
      "        [-1.8511e+03, -1.0632e+01, -9.3148e-02],\n",
      "        [-2.0280e+03, -1.2192e+01, -1.4689e-01],\n",
      "        [-1.9903e+03, -8.3851e+00, -2.2499e-01],\n",
      "        [-2.0123e+03, -1.1563e+01, -8.6099e-02],\n",
      "        [-2.0037e+03, -9.2696e+00, -2.0395e-01],\n",
      "        [-2.0025e+03, -1.0978e+01, -6.3375e-02],\n",
      "        [-2.0091e+03, -1.1543e+01, -7.6676e-02],\n",
      "        [-1.9891e+03, -1.0153e+01, -5.0366e-02],\n",
      "        [-1.9826e+03, -9.4162e+00,  3.6325e-02],\n",
      "        [-2.0076e+03, -1.0511e+01, -1.8994e-01],\n",
      "        [-2.0224e+03, -1.1777e+01, -1.4147e-01],\n",
      "        [-2.0160e+03, -1.2418e+01, -7.5519e-02],\n",
      "        [-1.9971e+03, -1.1364e+01, -1.4475e-02],\n",
      "        [-2.0000e+03, -1.1936e+01, -5.8256e-02],\n",
      "        [-2.0235e+03, -1.2931e+01, -1.6351e-01],\n",
      "        [-2.0033e+03, -9.5215e+00, -2.2840e-01],\n",
      "        [-2.0010e+03, -1.1058e+01, -6.9744e-02],\n",
      "        [-2.0087e+03, -9.6076e+00, -8.5833e-03],\n",
      "        [-2.0345e+03, -1.3420e+01, -8.6365e-02],\n",
      "        [-1.9977e+03, -1.0750e+01, -3.5602e-02],\n",
      "        [-1.9979e+03, -1.1187e+01,  4.8253e-03],\n",
      "        [-2.0019e+03, -1.1358e+01, -8.1994e-02],\n",
      "        [-1.9972e+03, -1.0868e+01, -4.7506e-02],\n",
      "        [-2.0068e+03, -1.2800e+01, -5.5650e-02],\n",
      "        [-2.0027e+03, -1.0161e+01, -1.6662e-01],\n",
      "        [-1.9974e+03, -1.1175e+01, -1.0972e-01],\n",
      "        [-2.0067e+03, -9.5896e+00, -2.3063e-01],\n",
      "        [-2.0225e+03, -1.2431e+01, -1.0276e-01],\n",
      "        [-1.9895e+03, -9.5086e+00, -1.5318e-01],\n",
      "        [-2.0162e+03, -1.1803e+01, -3.9610e-02],\n",
      "        [-2.0238e+03, -1.2090e+01, -1.5137e-01],\n",
      "        [-1.9943e+03, -9.7346e+00, -1.1301e-01],\n",
      "        [-2.0101e+03, -7.7815e+00, -2.3926e-01],\n",
      "        [-2.0098e+03, -8.1712e+00, -1.9842e-01],\n",
      "        [-2.0344e+03, -1.1732e+01, -1.4870e-01],\n",
      "        [-2.0060e+03, -1.0071e+01, -1.9573e-01],\n",
      "        [-2.0109e+03, -9.9024e+00, -1.6683e-01],\n",
      "        [-2.0079e+03, -1.1344e+01, -6.6452e-02],\n",
      "        [-1.9909e+03, -8.7611e+00, -1.1643e-01],\n",
      "        [-2.0033e+03, -1.2411e+01, -1.0698e-01],\n",
      "        [-2.0044e+03, -8.8418e+00, -9.6187e-02],\n",
      "        [-2.0082e+03, -1.2140e+01, -2.4596e-02],\n",
      "        [-1.9921e+03, -7.0056e+00, -1.4752e-01],\n",
      "        [-2.0062e+03, -8.8499e+00, -1.2793e-01],\n",
      "        [-1.9929e+03, -8.5993e+00, -3.9070e-02],\n",
      "        [-2.0228e+03, -1.1780e+01, -1.1717e-01],\n",
      "        [-2.0195e+03, -1.3105e+01, -4.7772e-02],\n",
      "        [-1.9919e+03, -1.0254e+01, -5.2270e-02],\n",
      "        [-2.0104e+03, -1.1042e+01, -8.1114e-02],\n",
      "        [-1.9865e+03, -6.1487e+00, -1.8850e-01],\n",
      "        [-2.0098e+03, -1.1535e+01, -1.5554e-01],\n",
      "        [-2.0165e+03, -1.0539e+01, -2.3824e-01],\n",
      "        [-2.0071e+03, -9.2777e+00, -7.5629e-02],\n",
      "        [-2.0032e+03, -1.0937e+01,  2.6638e-02],\n",
      "        [-1.9958e+03, -9.4351e+00, -7.2716e-02],\n",
      "        [-2.0148e+03, -1.2634e+01, -7.8776e-02],\n",
      "        [-2.0014e+03, -8.3267e+00, -1.9610e-01],\n",
      "        [-1.9953e+03, -6.3799e+00, -3.0082e-01],\n",
      "        [-1.9990e+03, -8.7194e+00, -7.5065e-02],\n",
      "        [-2.0005e+03, -1.1488e+01, -7.4559e-02],\n",
      "        [-2.0212e+03, -1.2790e+01, -1.5694e-01],\n",
      "        [-1.9981e+03, -9.6104e+00, -9.0878e-02],\n",
      "        [-1.9892e+03, -6.9924e+00, -1.1630e-01],\n",
      "        [-2.0022e+03, -9.9030e+00, -1.3532e-01],\n",
      "        [-2.0107e+03, -1.3527e+01, -1.0942e-01],\n",
      "        [-2.0061e+03, -1.0570e+01, -1.8411e-01],\n",
      "        [-1.9905e+03, -9.4927e+00, -2.7973e-02],\n",
      "        [-2.0180e+03, -1.3110e+01, -9.4636e-02],\n",
      "        [-2.0010e+03, -8.5776e+00, -2.3690e-01],\n",
      "        [-2.0216e+03, -1.2734e+01, -9.6122e-02],\n",
      "        [-2.0033e+03, -1.1149e+01, -2.2885e-02],\n",
      "        [-1.9868e+03, -6.2034e+00, -7.0791e-02],\n",
      "        [-2.0194e+03, -1.1021e+01, -9.7096e-02],\n",
      "        [-1.9896e+03, -5.9788e+00, -1.0844e-01],\n",
      "        [-2.0171e+03, -1.3225e+01, -1.0498e-01],\n",
      "        [-2.0027e+03, -7.7454e+00, -1.8594e-01],\n",
      "        [-2.0200e+03, -1.1104e+01, -1.6724e-01],\n",
      "        [-2.0135e+03, -1.0703e+01, -1.6191e-01],\n",
      "        [-2.0104e+03, -1.2461e+01, -1.3288e-01],\n",
      "        [-2.0163e+03, -1.3107e+01, -9.9379e-02],\n",
      "        [-1.9878e+03, -9.0708e+00, -7.4810e-02],\n",
      "        [-2.0016e+03, -1.0874e+01, -1.2688e-01],\n",
      "        [-2.0204e+03, -1.3315e+01, -1.1526e-01],\n",
      "        [-1.9959e+03, -9.1718e+00, -1.5025e-01],\n",
      "        [-2.0036e+03, -1.1439e+01, -1.1997e-01],\n",
      "        [-2.0229e+03, -1.1490e+01, -1.8815e-01],\n",
      "        [-1.9864e+03, -6.6436e+00, -1.1364e-01],\n",
      "        [-2.0005e+03, -1.0299e+01, -7.5001e-02],\n",
      "        [-2.0007e+03, -6.8998e+00, -8.7863e-02],\n",
      "        [-2.0099e+03, -1.1501e+01, -6.6069e-02],\n",
      "        [-2.0026e+03, -1.0468e+01, -1.2690e-01],\n",
      "        [-2.0158e+03, -1.3010e+01, -4.6380e-02],\n",
      "        [-1.9895e+03, -1.1100e+01, -3.0731e-02],\n",
      "        [-2.0263e+03, -1.1876e+01, -2.8289e-02],\n",
      "        [-2.0037e+03, -1.1890e+01, -1.1252e-02],\n",
      "        [-2.0082e+03, -1.1755e+01, -1.2433e-01],\n",
      "        [-2.0026e+03, -8.5909e+00, -2.2162e-02],\n",
      "        [-2.0149e+03, -1.0259e+01, -2.2422e-01],\n",
      "        [-2.0087e+03, -1.1080e+01, -1.0477e-01],\n",
      "        [-2.0231e+03, -1.1240e+01, -1.2346e-01],\n",
      "        [-2.0010e+03, -7.5577e+00, -3.2189e-01],\n",
      "        [-1.6691e+03, -9.4769e+00, -7.6155e-02],\n",
      "        [-1.6562e+03, -3.4575e+00, -3.5200e-02],\n",
      "        [-1.6403e+03, -6.5856e+00,  5.5100e-02],\n",
      "        [-1.6509e+03, -7.0397e+00,  5.2462e-02],\n",
      "        [-1.6472e+03, -3.4575e+00, -3.5200e-02],\n",
      "        [-1.6419e+03, -5.8711e+00, -3.7522e-03],\n",
      "        [-1.6755e+03, -8.7794e+00,  5.8287e-02],\n",
      "        [-1.6579e+03, -4.6946e+00, -1.7690e-02],\n",
      "        [-1.6463e+03, -7.1987e+00,  5.0562e-02],\n",
      "        [-1.6518e+03, -3.4575e+00, -3.5200e-02],\n",
      "        [-1.6449e+03, -6.5856e+00,  5.5100e-02]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\cached_cholesky.py:89: RuntimeWarning: `cache_root` is only supported for GPyTorchModels that are not MultiTask models and don't produce a TransformedPosterior. Got a model of type <class 'botorch.models.model.ModelList'>. Setting `cache_root = False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create the qNEHVI acquisition function using the modified X_baseline\n",
    "qNEHVI = qLogNoisyExpectedHypervolumeImprovement(\n",
    "    model=new_modellist,\n",
    "    X_baseline=X_baseline_no_task,\n",
    "    ref_point=torch.tensor([-1864.72022, -11.81993945, -0.2903999384]),\n",
    "    prune_baseline=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "new_X, acq_func_value = optimize_acqf(\n",
    "        acq_function=qNEHVI,\n",
    "        bounds=bounds,\n",
    "        q=1,\n",
    "        num_restarts=10,\n",
    "        raw_samples=512,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_Y , exp_ = generate_car_crash_synthetic_data(new_X, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "print(new_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0428, 2.7625, 3.0000, 0.0000, 0.6162]])\n"
     ]
    }
   ],
   "source": [
    "print(new_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.1095e+00, 4.7438e-01, 1.1849e+00, 1.1346e+00, 9.2231e-01, 0.0000e+00],\n",
      "        [1.9544e+00, 8.8923e-01, 2.9239e+00, 1.2207e+00, 2.3603e+00, 0.0000e+00],\n",
      "        [1.1821e+00, 1.4144e+00, 1.9060e+00, 1.4549e+00, 2.1148e+00, 0.0000e+00],\n",
      "        [2.4778e+00, 1.6518e+00, 2.9498e-01, 2.0014e+00, 1.8411e+00, 0.0000e+00],\n",
      "        [2.7775e+00, 1.4986e+00, 1.2764e+00, 2.2276e+00, 1.9990e+00, 0.0000e+00],\n",
      "        [6.7216e-01, 2.0316e+00, 7.6085e-01, 5.1144e-01, 1.7983e+00, 0.0000e+00],\n",
      "        [2.9586e-02, 2.6612e-01, 1.1861e+00, 7.8961e-01, 2.5484e+00, 0.0000e+00],\n",
      "        [7.9050e-01, 1.7441e+00, 2.8862e+00, 2.0452e+00, 3.4542e-01, 0.0000e+00],\n",
      "        [2.9570e+00, 4.5597e-01, 2.9142e+00, 1.1441e+00, 2.7106e+00, 0.0000e+00],\n",
      "        [2.1601e-01, 2.2784e+00, 2.1023e+00, 2.1226e+00, 1.6035e+00, 0.0000e+00],\n",
      "        [1.4925e+00, 2.3871e+00, 5.6532e-01, 1.6936e+00, 2.6634e+00, 0.0000e+00],\n",
      "        [2.9840e+00, 1.4505e+00, 1.1742e+00, 2.2280e+00, 6.9904e-01, 0.0000e+00],\n",
      "        [2.2886e+00, 8.7753e-01, 1.2161e+00, 4.8886e-01, 1.5046e+00, 0.0000e+00],\n",
      "        [1.6843e+00, 6.9007e-01, 7.9141e-01, 2.3125e+00, 2.0217e+00, 0.0000e+00],\n",
      "        [5.1184e-01, 2.2573e-01, 9.1774e-02, 2.3004e+00, 1.1208e+00, 0.0000e+00],\n",
      "        [1.9600e+00, 9.9001e-01, 1.7316e+00, 2.4745e+00, 6.8754e-01, 0.0000e+00],\n",
      "        [2.9388e+00, 1.4816e+00, 3.3935e-01, 2.2718e+00, 2.8387e+00, 0.0000e+00],\n",
      "        [8.8817e-01, 5.9732e-01, 3.4796e-01, 8.7895e-02, 1.7491e+00, 0.0000e+00],\n",
      "        [5.4953e-01, 2.9201e+00, 1.5113e+00, 8.4104e-01, 1.3392e+00, 0.0000e+00],\n",
      "        [1.5407e+00, 2.3158e+00, 2.2233e+00, 1.1216e+00, 2.5921e+00, 0.0000e+00],\n",
      "        [2.0046e+00, 1.2412e+00, 2.6696e+00, 2.0846e+00, 1.9934e+00, 0.0000e+00],\n",
      "        [1.0821e+00, 8.8893e-01, 2.1580e-01, 1.4219e+00, 2.6992e+00, 0.0000e+00],\n",
      "        [7.9075e-02, 1.5490e+00, 2.9323e-01, 2.0884e+00, 2.2668e-01, 0.0000e+00],\n",
      "        [6.8464e-01, 2.3550e+00, 2.4933e+00, 1.3518e-01, 1.0620e+00, 0.0000e+00],\n",
      "        [1.4140e-01, 2.4172e+00, 2.4231e+00, 1.4839e+00, 2.3298e+00, 0.0000e+00],\n",
      "        [6.7668e-01, 7.6215e-01, 1.2966e+00, 6.6012e-01, 7.5970e-01, 0.0000e+00],\n",
      "        [1.3927e+00, 1.0236e+00, 9.3459e-02, 5.0839e-01, 2.7074e-01, 0.0000e+00],\n",
      "        [1.4904e+00, 2.3760e+00, 1.8303e+00, 4.1294e-01, 1.6843e-01, 0.0000e+00],\n",
      "        [7.7866e-01, 2.0538e+00, 1.0149e+00, 6.3521e-01, 1.6430e+00, 0.0000e+00],\n",
      "        [2.9510e+00, 2.6702e+00, 7.5484e-01, 2.2540e+00, 2.2297e+00, 0.0000e+00],\n",
      "        [6.7048e-01, 2.1557e+00, 1.9471e+00, 6.0638e-01, 2.4355e+00, 0.0000e+00],\n",
      "        [2.4621e+00, 1.1999e+00, 2.1375e+00, 2.9831e+00, 1.1498e+00, 0.0000e+00],\n",
      "        [1.4482e+00, 4.7126e-01, 1.0248e+00, 1.4815e+00, 1.1080e+00, 0.0000e+00],\n",
      "        [6.7375e-01, 5.1623e-01, 1.3648e+00, 6.4599e-01, 3.7723e-01, 0.0000e+00],\n",
      "        [1.5195e+00, 1.0121e+00, 1.1112e+00, 6.7759e-01, 1.4099e+00, 0.0000e+00],\n",
      "        [2.2523e+00, 1.0457e+00, 2.5606e+00, 1.8573e+00, 1.8587e+00, 0.0000e+00],\n",
      "        [4.1105e-01, 1.5344e+00, 2.7060e+00, 2.7352e+00, 2.0126e+00, 0.0000e+00],\n",
      "        [1.4704e+00, 1.5549e+00, 2.6425e+00, 2.6170e+00, 2.7361e+00, 0.0000e+00],\n",
      "        [2.3730e+00, 1.8845e-01, 4.3406e-01, 2.5862e+00, 7.7442e-01, 0.0000e+00],\n",
      "        [1.3322e+00, 2.0385e+00, 3.3474e-04, 1.9608e+00, 1.0268e+00, 0.0000e+00],\n",
      "        [2.3399e+00, 2.3606e+00, 8.7402e-01, 1.3272e+00, 2.4534e+00, 0.0000e+00],\n",
      "        [4.0843e-01, 7.7788e-01, 1.3403e+00, 2.4814e-03, 2.1503e+00, 0.0000e+00],\n",
      "        [1.5974e+00, 2.5476e+00, 1.7845e+00, 2.5581e+00, 1.1577e+00, 0.0000e+00],\n",
      "        [2.3930e+00, 3.7347e-01, 1.6669e+00, 2.1516e+00, 1.3323e+00, 0.0000e+00],\n",
      "        [1.8997e+00, 1.0976e+00, 1.3622e+00, 7.5407e-01, 2.0034e+00, 0.0000e+00],\n",
      "        [2.6343e-01, 1.6843e+00, 2.3582e+00, 1.8659e+00, 5.1078e-01, 0.0000e+00],\n",
      "        [2.0311e-01, 1.8899e+00, 2.0633e+00, 6.5203e-01, 1.1316e+00, 0.0000e+00],\n",
      "        [1.3192e+00, 1.1821e+00, 3.3569e-01, 1.1726e+00, 7.2604e-01, 0.0000e+00],\n",
      "        [9.3907e-01, 4.8929e-01, 1.8089e+00, 1.5896e+00, 2.7438e+00, 0.0000e+00],\n",
      "        [1.1180e+00, 8.0039e-01, 1.1121e+00, 1.2126e+00, 2.0456e+00, 0.0000e+00],\n",
      "        [1.7371e+00, 2.1816e+00, 1.4036e+00, 2.1417e+00, 1.0930e+00, 1.0000e+00],\n",
      "        [7.2343e-01, 1.7432e+00, 2.4930e+00, 2.6765e+00, 1.6683e-01, 1.0000e+00],\n",
      "        [7.2778e-01, 9.3275e-01, 1.9012e+00, 1.8060e-02, 1.2720e+00, 1.0000e+00],\n",
      "        [2.5371e+00, 1.4752e+00, 8.0985e-01, 2.7472e+00, 2.2741e+00, 1.0000e+00],\n",
      "        [2.3149e+00, 1.7756e+00, 3.4527e-01, 2.4354e-01, 2.1119e+00, 1.0000e+00],\n",
      "        [2.0229e+00, 2.1903e+00, 2.7554e+00, 1.7451e+00, 2.2070e+00, 1.0000e+00],\n",
      "        [1.7497e+00, 1.3751e+00, 1.9027e-01, 2.8235e+00, 8.3824e-01, 1.0000e+00],\n",
      "        [2.2147e-01, 5.2363e-01, 1.2312e+00, 1.8664e+00, 1.1926e-01, 1.0000e+00],\n",
      "        [6.6818e-01, 1.0227e+00, 3.6907e-01, 9.5468e-01, 1.6347e+00, 1.0000e+00],\n",
      "        [2.9150e+00, 2.0728e+00, 1.1627e-01, 2.0893e+00, 1.8006e+00, 1.0000e+00],\n",
      "        [1.5446e+00, 1.2252e+00, 5.7008e-01, 1.7337e+00, 2.7282e+00, 1.0000e+00],\n",
      "        [2.6337e+00, 2.9522e+00, 2.6929e+00, 1.2091e-01, 6.5446e-01, 1.0000e+00],\n",
      "        [2.4618e-01, 1.5306e+00, 9.2099e-01, 1.0494e+00, 1.3195e-01, 1.0000e+00],\n",
      "        [5.0541e-01, 7.1441e-01, 2.1399e+00, 1.1461e+00, 1.9115e+00, 1.0000e+00],\n",
      "        [2.2830e+00, 2.6434e+00, 9.7919e-01, 2.7777e+00, 1.4599e+00, 1.0000e+00],\n",
      "        [2.0730e+00, 2.9947e+00, 2.4353e+00, 2.8934e+00, 1.2480e+00, 1.0000e+00],\n",
      "        [1.9241e+00, 1.1053e+00, 7.5941e-01, 1.4742e+00, 2.8364e+00, 1.0000e+00],\n",
      "        [1.2317e+00, 1.9205e+00, 7.6503e-01, 4.3472e-01, 1.8933e+00, 1.0000e+00],\n",
      "        [6.5522e-01, 2.5844e+00, 2.3094e+00, 1.2115e+00, 2.6259e+00, 1.0000e+00],\n",
      "        [1.6321e+00, 2.4340e+00, 1.0529e+00, 4.0903e-01, 1.0078e+00, 1.0000e+00],\n",
      "        [1.1687e+00, 2.8802e+00, 6.5431e-01, 2.4759e+00, 8.7257e-01, 1.0000e+00],\n",
      "        [2.4314e+00, 8.0831e-01, 5.6305e-01, 9.2399e-01, 9.6092e-01, 1.0000e+00],\n",
      "        [1.4884e+00, 1.6454e+00, 7.2084e-01, 6.6568e-01, 1.9992e+00, 1.0000e+00],\n",
      "        [2.5202e+00, 2.9421e+00, 2.5442e+00, 1.4537e+00, 2.9334e+00, 1.0000e+00],\n",
      "        [2.7165e+00, 1.1037e+00, 1.9406e-01, 2.7872e+00, 1.3867e+00, 1.0000e+00],\n",
      "        [2.4742e+00, 1.7420e+00, 2.3043e+00, 1.8954e+00, 2.1625e+00, 1.0000e+00],\n",
      "        [1.9920e-01, 1.6025e+00, 5.0787e-01, 1.4836e+00, 2.9079e+00, 1.0000e+00],\n",
      "        [2.7594e+00, 1.2526e+00, 1.3351e+00, 1.0908e+00, 2.9177e+00, 1.0000e+00],\n",
      "        [3.7702e-01, 1.0594e+00, 1.8422e+00, 2.7977e+00, 6.5636e-01, 1.0000e+00],\n",
      "        [9.8652e-01, 1.7806e+00, 6.0428e-01, 2.8535e-01, 4.7529e-01, 1.0000e+00],\n",
      "        [2.6991e+00, 3.5814e-01, 1.4579e+00, 4.7755e-01, 1.2927e+00, 1.0000e+00],\n",
      "        [9.4537e-01, 1.0528e+00, 8.8569e-01, 5.1367e-01, 1.2763e+00, 1.0000e+00],\n",
      "        [6.2218e-01, 1.0194e+00, 5.0725e-02, 5.2751e-01, 1.6326e+00, 1.0000e+00],\n",
      "        [1.6782e+00, 2.4933e+00, 8.9725e-01, 1.0262e+00, 2.7166e+00, 1.0000e+00],\n",
      "        [2.7913e+00, 2.4538e+00, 8.3240e-01, 2.1202e+00, 1.3464e+00, 1.0000e+00],\n",
      "        [1.1147e+00, 4.7743e-01, 1.6375e+00, 5.7504e-01, 2.3773e+00, 1.0000e+00],\n",
      "        [2.2530e-01, 2.3843e+00, 5.8252e-01, 1.3843e+00, 1.0363e+00, 1.0000e+00],\n",
      "        [2.5734e+00, 2.7322e+00, 1.1164e+00, 1.3684e+00, 2.1031e-01, 1.0000e+00],\n",
      "        [3.1096e-01, 3.6204e-01, 9.6047e-01, 2.6251e-02, 1.0320e+00, 1.0000e+00],\n",
      "        [8.9296e-01, 1.2575e-01, 9.1309e-01, 2.2314e+00, 2.7652e+00, 1.0000e+00],\n",
      "        [1.9922e-01, 1.7069e+00, 1.4556e+00, 2.8672e+00, 9.6861e-01, 1.0000e+00],\n",
      "        [1.5800e+00, 1.1480e-01, 5.4661e-01, 1.2437e+00, 1.3102e+00, 1.0000e+00],\n",
      "        [2.3264e+00, 2.7639e+00, 1.7689e+00, 2.3803e+00, 2.8699e+00, 1.0000e+00],\n",
      "        [2.5107e+00, 2.5364e+00, 2.8883e+00, 9.7850e-01, 6.5246e-01, 1.0000e+00],\n",
      "        [1.4799e-03, 1.1656e+00, 2.7512e+00, 2.3877e+00, 2.1247e+00, 1.0000e+00],\n",
      "        [1.7224e+00, 1.8691e+00, 1.8407e+00, 1.1706e+00, 2.7444e+00, 1.0000e+00],\n",
      "        [1.1240e+00, 1.8312e+00, 1.1199e+00, 2.0186e+00, 2.6656e+00, 1.0000e+00],\n",
      "        [2.2166e+00, 1.3216e+00, 2.1943e+00, 1.7915e+00, 4.5079e-01, 1.0000e+00],\n",
      "        [1.6891e+00, 2.7075e+00, 2.2014e+00, 5.7290e-01, 1.0821e+00, 1.0000e+00],\n",
      "        [2.4456e-01, 1.9768e+00, 1.7879e+00, 7.7462e-02, 1.0145e+00, 1.0000e+00],\n",
      "        [1.6069e+00, 2.2776e+00, 6.9906e-01, 2.9194e+00, 2.4635e+00, 1.0000e+00],\n",
      "        [2.0675e+00, 5.9270e-01, 4.5986e-01, 2.3539e+00, 1.9606e+00, 1.0000e+00],\n",
      "        [1.5347e+00, 2.9477e+00, 1.9736e+00, 1.9263e+00, 1.8765e+00, 1.0000e+00],\n",
      "        [1.9510e+00, 4.5297e-01, 1.1450e+00, 1.2498e+00, 2.3232e+00, 1.0000e+00],\n",
      "        [1.3733e+00, 7.7238e-01, 1.5250e+00, 1.0630e+00, 2.9335e+00, 1.0000e+00],\n",
      "        [2.6407e+00, 3.4660e-01, 2.1953e+00, 1.0950e+00, 2.3728e+00, 1.0000e+00],\n",
      "        [2.6483e+00, 4.7349e-01, 1.3407e+00, 1.5866e+00, 1.7220e+00, 1.0000e+00],\n",
      "        [8.3921e-01, 1.0887e+00, 2.0260e+00, 8.2913e-01, 2.3550e+00, 1.0000e+00],\n",
      "        [8.5527e-01, 1.4275e-01, 1.9713e+00, 2.7941e+00, 2.9941e+00, 1.0000e+00],\n",
      "        [7.8421e-01, 1.0655e+00, 2.8525e+00, 2.6525e+00, 8.4611e-01, 1.0000e+00],\n",
      "        [1.6769e+00, 1.5892e+00, 1.2064e+00, 1.0887e-01, 6.1976e-01, 1.0000e+00],\n",
      "        [1.2102e+00, 5.9493e-01, 9.0377e-01, 1.2043e+00, 1.4528e+00, 1.0000e+00],\n",
      "        [2.2659e+00, 1.1219e+00, 2.9973e-01, 7.1424e-01, 8.1304e-01, 1.0000e+00],\n",
      "        [5.3694e-01, 1.8897e+00, 3.6001e-01, 9.7145e-01, 2.5285e-01, 1.0000e+00],\n",
      "        [8.0275e-01, 1.0154e+00, 2.2179e+00, 1.8410e+00, 2.7611e+00, 1.0000e+00],\n",
      "        [1.3869e+00, 2.3544e+00, 1.6736e+00, 2.2131e+00, 1.9660e+00, 1.0000e+00],\n",
      "        [1.1523e+00, 2.9404e-01, 6.6261e-01, 2.6023e+00, 1.8618e+00, 1.0000e+00],\n",
      "        [5.0062e-01, 3.6599e-02, 2.7008e+00, 2.4632e+00, 1.0260e+00, 1.0000e+00],\n",
      "        [2.7031e+00, 2.5823e+00, 8.1651e-01, 2.3708e-02, 1.5901e+00, 1.0000e+00],\n",
      "        [7.2440e-01, 1.7925e+00, 1.0907e+00, 1.3922e+00, 2.8885e+00, 1.0000e+00],\n",
      "        [2.5889e+00, 1.5687e+00, 1.2595e+00, 3.9236e-01, 2.3423e+00, 1.0000e+00],\n",
      "        [5.9518e-01, 1.4913e+00, 9.5298e-01, 7.3678e-01, 1.5113e+00, 1.0000e+00],\n",
      "        [2.3455e-01, 2.5704e+00, 2.7571e+00, 3.6704e-01, 2.8797e+00, 1.0000e+00],\n",
      "        [5.4168e-01, 9.5958e-01, 2.0712e+00, 2.4199e+00, 2.8881e+00, 1.0000e+00],\n",
      "        [9.0561e-01, 1.2511e+00, 5.9562e-01, 1.9656e-02, 1.9944e+00, 1.0000e+00],\n",
      "        [2.6232e+00, 1.3485e+00, 2.3257e+00, 1.1255e+00, 2.3785e+00, 1.0000e+00],\n",
      "        [2.4580e+00, 6.0705e-01, 6.0524e-01, 2.9745e+00, 1.3674e+00, 1.0000e+00],\n",
      "        [2.3027e+00, 2.8116e+00, 1.1106e-01, 1.7462e-01, 1.5586e+00, 1.0000e+00],\n",
      "        [2.5260e+00, 1.7956e+00, 1.4556e+00, 1.0243e+00, 2.9286e+00, 1.0000e+00],\n",
      "        [2.6615e+00, 1.5526e+00, 2.4367e-01, 2.1188e+00, 2.8461e+00, 1.0000e+00],\n",
      "        [2.5980e+00, 4.9608e-01, 1.3966e+00, 1.2458e+00, 2.1387e+00, 1.0000e+00],\n",
      "        [1.8435e+00, 1.9494e+00, 1.4865e-01, 2.6765e+00, 2.1067e-01, 1.0000e+00],\n",
      "        [2.7325e+00, 7.0206e-02, 1.2652e+00, 2.1662e+00, 1.3290e+00, 1.0000e+00],\n",
      "        [3.2076e-01, 1.9430e-02, 1.3884e+00, 2.0140e+00, 6.6447e-01, 1.0000e+00],\n",
      "        [1.7707e+00, 1.4620e-01, 2.6354e+00, 7.4466e-01, 2.8126e+00, 1.0000e+00],\n",
      "        [1.1099e+00, 4.5251e-01, 1.7716e+00, 2.2710e+00, 1.2096e+00, 1.0000e+00],\n",
      "        [2.5341e+00, 1.6510e+00, 1.4159e+00, 2.7051e+00, 9.7369e-01, 1.0000e+00],\n",
      "        [1.9388e+00, 4.8090e-01, 5.5759e-02, 6.0301e-01, 2.2740e+00, 1.0000e+00],\n",
      "        [1.6786e+00, 3.4804e-01, 5.7173e-01, 2.3067e+00, 4.5683e-01, 1.0000e+00],\n",
      "        [1.7835e+00, 1.2635e+00, 9.6761e-01, 6.1024e-01, 7.3255e-01, 1.0000e+00],\n",
      "        [1.6259e+00, 9.4117e-01, 8.7737e-01, 2.8549e+00, 4.5742e-01, 1.0000e+00],\n",
      "        [2.9726e+00, 2.4945e+00, 8.0483e-01, 1.3876e+00, 1.1474e+00, 1.0000e+00],\n",
      "        [6.7524e-01, 1.9940e+00, 1.5134e+00, 6.4185e-01, 2.0775e+00, 1.0000e+00],\n",
      "        [1.2910e+00, 2.6350e+00, 2.5383e+00, 2.6227e+00, 1.8079e+00, 1.0000e+00],\n",
      "        [2.0436e+00, 3.0367e-01, 1.7168e+00, 2.9225e+00, 1.2775e+00, 1.0000e+00],\n",
      "        [2.9817e+00, 9.6190e-01, 5.7945e-01, 1.6836e+00, 3.3916e-01, 1.0000e+00],\n",
      "        [1.8654e+00, 2.7972e+00, 1.0140e+00, 2.5209e+00, 2.1490e+00, 1.0000e+00],\n",
      "        [5.2776e-01, 7.6593e-01, 2.1458e+00, 2.7365e+00, 1.3080e+00, 1.0000e+00],\n",
      "        [2.9562e+00, 1.3421e+00, 1.8065e+00, 4.9768e-01, 1.0501e+00, 1.0000e+00],\n",
      "        [1.3414e-01, 2.0209e+00, 2.9772e+00, 9.5065e-01, 2.8751e+00, 1.0000e+00],\n",
      "        [2.2277e-01, 2.0879e+00, 2.2132e+00, 2.0463e+00, 1.3238e+00, 2.0000e+00]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([151, 6])\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "print(new_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated train_X shape: torch.Size([152, 6])\n"
     ]
    }
   ],
   "source": [
    "task_feature = torch.tensor([[2.0]], dtype=torch.float64)  # Creating a tensor with value 2.0 and dtype float64\n",
    "new_X_with_task = torch.cat([new_X, task_feature], dim=-1)  # Concatenating along the last dimension\n",
    "\n",
    "# Concatenating new_X_with_task to train_X\n",
    "train_X = torch.cat([train_X, new_X_with_task], dim=0)  # Concatenating along the first dimension\n",
    "\n",
    "# Verify the shapes\n",
    "print(\"Updated train_X shape:\", train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.1095e+00, 4.7438e-01, 1.1849e+00, 1.1346e+00, 9.2231e-01, 0.0000e+00],\n",
      "        [1.9544e+00, 8.8923e-01, 2.9239e+00, 1.2207e+00, 2.3603e+00, 0.0000e+00],\n",
      "        [1.1821e+00, 1.4144e+00, 1.9060e+00, 1.4549e+00, 2.1148e+00, 0.0000e+00],\n",
      "        [2.4778e+00, 1.6518e+00, 2.9498e-01, 2.0014e+00, 1.8411e+00, 0.0000e+00],\n",
      "        [2.7775e+00, 1.4986e+00, 1.2764e+00, 2.2276e+00, 1.9990e+00, 0.0000e+00],\n",
      "        [6.7216e-01, 2.0316e+00, 7.6085e-01, 5.1144e-01, 1.7983e+00, 0.0000e+00],\n",
      "        [2.9586e-02, 2.6612e-01, 1.1861e+00, 7.8961e-01, 2.5484e+00, 0.0000e+00],\n",
      "        [7.9050e-01, 1.7441e+00, 2.8862e+00, 2.0452e+00, 3.4542e-01, 0.0000e+00],\n",
      "        [2.9570e+00, 4.5597e-01, 2.9142e+00, 1.1441e+00, 2.7106e+00, 0.0000e+00],\n",
      "        [2.1601e-01, 2.2784e+00, 2.1023e+00, 2.1226e+00, 1.6035e+00, 0.0000e+00],\n",
      "        [1.4925e+00, 2.3871e+00, 5.6532e-01, 1.6936e+00, 2.6634e+00, 0.0000e+00],\n",
      "        [2.9840e+00, 1.4505e+00, 1.1742e+00, 2.2280e+00, 6.9904e-01, 0.0000e+00],\n",
      "        [2.2886e+00, 8.7753e-01, 1.2161e+00, 4.8886e-01, 1.5046e+00, 0.0000e+00],\n",
      "        [1.6843e+00, 6.9007e-01, 7.9141e-01, 2.3125e+00, 2.0217e+00, 0.0000e+00],\n",
      "        [5.1184e-01, 2.2573e-01, 9.1774e-02, 2.3004e+00, 1.1208e+00, 0.0000e+00],\n",
      "        [1.9600e+00, 9.9001e-01, 1.7316e+00, 2.4745e+00, 6.8754e-01, 0.0000e+00],\n",
      "        [2.9388e+00, 1.4816e+00, 3.3935e-01, 2.2718e+00, 2.8387e+00, 0.0000e+00],\n",
      "        [8.8817e-01, 5.9732e-01, 3.4796e-01, 8.7895e-02, 1.7491e+00, 0.0000e+00],\n",
      "        [5.4953e-01, 2.9201e+00, 1.5113e+00, 8.4104e-01, 1.3392e+00, 0.0000e+00],\n",
      "        [1.5407e+00, 2.3158e+00, 2.2233e+00, 1.1216e+00, 2.5921e+00, 0.0000e+00],\n",
      "        [2.0046e+00, 1.2412e+00, 2.6696e+00, 2.0846e+00, 1.9934e+00, 0.0000e+00],\n",
      "        [1.0821e+00, 8.8893e-01, 2.1580e-01, 1.4219e+00, 2.6992e+00, 0.0000e+00],\n",
      "        [7.9075e-02, 1.5490e+00, 2.9323e-01, 2.0884e+00, 2.2668e-01, 0.0000e+00],\n",
      "        [6.8464e-01, 2.3550e+00, 2.4933e+00, 1.3518e-01, 1.0620e+00, 0.0000e+00],\n",
      "        [1.4140e-01, 2.4172e+00, 2.4231e+00, 1.4839e+00, 2.3298e+00, 0.0000e+00],\n",
      "        [6.7668e-01, 7.6215e-01, 1.2966e+00, 6.6012e-01, 7.5970e-01, 0.0000e+00],\n",
      "        [1.3927e+00, 1.0236e+00, 9.3459e-02, 5.0839e-01, 2.7074e-01, 0.0000e+00],\n",
      "        [1.4904e+00, 2.3760e+00, 1.8303e+00, 4.1294e-01, 1.6843e-01, 0.0000e+00],\n",
      "        [7.7866e-01, 2.0538e+00, 1.0149e+00, 6.3521e-01, 1.6430e+00, 0.0000e+00],\n",
      "        [2.9510e+00, 2.6702e+00, 7.5484e-01, 2.2540e+00, 2.2297e+00, 0.0000e+00],\n",
      "        [6.7048e-01, 2.1557e+00, 1.9471e+00, 6.0638e-01, 2.4355e+00, 0.0000e+00],\n",
      "        [2.4621e+00, 1.1999e+00, 2.1375e+00, 2.9831e+00, 1.1498e+00, 0.0000e+00],\n",
      "        [1.4482e+00, 4.7126e-01, 1.0248e+00, 1.4815e+00, 1.1080e+00, 0.0000e+00],\n",
      "        [6.7375e-01, 5.1623e-01, 1.3648e+00, 6.4599e-01, 3.7723e-01, 0.0000e+00],\n",
      "        [1.5195e+00, 1.0121e+00, 1.1112e+00, 6.7759e-01, 1.4099e+00, 0.0000e+00],\n",
      "        [2.2523e+00, 1.0457e+00, 2.5606e+00, 1.8573e+00, 1.8587e+00, 0.0000e+00],\n",
      "        [4.1105e-01, 1.5344e+00, 2.7060e+00, 2.7352e+00, 2.0126e+00, 0.0000e+00],\n",
      "        [1.4704e+00, 1.5549e+00, 2.6425e+00, 2.6170e+00, 2.7361e+00, 0.0000e+00],\n",
      "        [2.3730e+00, 1.8845e-01, 4.3406e-01, 2.5862e+00, 7.7442e-01, 0.0000e+00],\n",
      "        [1.3322e+00, 2.0385e+00, 3.3474e-04, 1.9608e+00, 1.0268e+00, 0.0000e+00],\n",
      "        [2.3399e+00, 2.3606e+00, 8.7402e-01, 1.3272e+00, 2.4534e+00, 0.0000e+00],\n",
      "        [4.0843e-01, 7.7788e-01, 1.3403e+00, 2.4814e-03, 2.1503e+00, 0.0000e+00],\n",
      "        [1.5974e+00, 2.5476e+00, 1.7845e+00, 2.5581e+00, 1.1577e+00, 0.0000e+00],\n",
      "        [2.3930e+00, 3.7347e-01, 1.6669e+00, 2.1516e+00, 1.3323e+00, 0.0000e+00],\n",
      "        [1.8997e+00, 1.0976e+00, 1.3622e+00, 7.5407e-01, 2.0034e+00, 0.0000e+00],\n",
      "        [2.6343e-01, 1.6843e+00, 2.3582e+00, 1.8659e+00, 5.1078e-01, 0.0000e+00],\n",
      "        [2.0311e-01, 1.8899e+00, 2.0633e+00, 6.5203e-01, 1.1316e+00, 0.0000e+00],\n",
      "        [1.3192e+00, 1.1821e+00, 3.3569e-01, 1.1726e+00, 7.2604e-01, 0.0000e+00],\n",
      "        [9.3907e-01, 4.8929e-01, 1.8089e+00, 1.5896e+00, 2.7438e+00, 0.0000e+00],\n",
      "        [1.1180e+00, 8.0039e-01, 1.1121e+00, 1.2126e+00, 2.0456e+00, 0.0000e+00],\n",
      "        [1.7371e+00, 2.1816e+00, 1.4036e+00, 2.1417e+00, 1.0930e+00, 1.0000e+00],\n",
      "        [7.2343e-01, 1.7432e+00, 2.4930e+00, 2.6765e+00, 1.6683e-01, 1.0000e+00],\n",
      "        [7.2778e-01, 9.3275e-01, 1.9012e+00, 1.8060e-02, 1.2720e+00, 1.0000e+00],\n",
      "        [2.5371e+00, 1.4752e+00, 8.0985e-01, 2.7472e+00, 2.2741e+00, 1.0000e+00],\n",
      "        [2.3149e+00, 1.7756e+00, 3.4527e-01, 2.4354e-01, 2.1119e+00, 1.0000e+00],\n",
      "        [2.0229e+00, 2.1903e+00, 2.7554e+00, 1.7451e+00, 2.2070e+00, 1.0000e+00],\n",
      "        [1.7497e+00, 1.3751e+00, 1.9027e-01, 2.8235e+00, 8.3824e-01, 1.0000e+00],\n",
      "        [2.2147e-01, 5.2363e-01, 1.2312e+00, 1.8664e+00, 1.1926e-01, 1.0000e+00],\n",
      "        [6.6818e-01, 1.0227e+00, 3.6907e-01, 9.5468e-01, 1.6347e+00, 1.0000e+00],\n",
      "        [2.9150e+00, 2.0728e+00, 1.1627e-01, 2.0893e+00, 1.8006e+00, 1.0000e+00],\n",
      "        [1.5446e+00, 1.2252e+00, 5.7008e-01, 1.7337e+00, 2.7282e+00, 1.0000e+00],\n",
      "        [2.6337e+00, 2.9522e+00, 2.6929e+00, 1.2091e-01, 6.5446e-01, 1.0000e+00],\n",
      "        [2.4618e-01, 1.5306e+00, 9.2099e-01, 1.0494e+00, 1.3195e-01, 1.0000e+00],\n",
      "        [5.0541e-01, 7.1441e-01, 2.1399e+00, 1.1461e+00, 1.9115e+00, 1.0000e+00],\n",
      "        [2.2830e+00, 2.6434e+00, 9.7919e-01, 2.7777e+00, 1.4599e+00, 1.0000e+00],\n",
      "        [2.0730e+00, 2.9947e+00, 2.4353e+00, 2.8934e+00, 1.2480e+00, 1.0000e+00],\n",
      "        [1.9241e+00, 1.1053e+00, 7.5941e-01, 1.4742e+00, 2.8364e+00, 1.0000e+00],\n",
      "        [1.2317e+00, 1.9205e+00, 7.6503e-01, 4.3472e-01, 1.8933e+00, 1.0000e+00],\n",
      "        [6.5522e-01, 2.5844e+00, 2.3094e+00, 1.2115e+00, 2.6259e+00, 1.0000e+00],\n",
      "        [1.6321e+00, 2.4340e+00, 1.0529e+00, 4.0903e-01, 1.0078e+00, 1.0000e+00],\n",
      "        [1.1687e+00, 2.8802e+00, 6.5431e-01, 2.4759e+00, 8.7257e-01, 1.0000e+00],\n",
      "        [2.4314e+00, 8.0831e-01, 5.6305e-01, 9.2399e-01, 9.6092e-01, 1.0000e+00],\n",
      "        [1.4884e+00, 1.6454e+00, 7.2084e-01, 6.6568e-01, 1.9992e+00, 1.0000e+00],\n",
      "        [2.5202e+00, 2.9421e+00, 2.5442e+00, 1.4537e+00, 2.9334e+00, 1.0000e+00],\n",
      "        [2.7165e+00, 1.1037e+00, 1.9406e-01, 2.7872e+00, 1.3867e+00, 1.0000e+00],\n",
      "        [2.4742e+00, 1.7420e+00, 2.3043e+00, 1.8954e+00, 2.1625e+00, 1.0000e+00],\n",
      "        [1.9920e-01, 1.6025e+00, 5.0787e-01, 1.4836e+00, 2.9079e+00, 1.0000e+00],\n",
      "        [2.7594e+00, 1.2526e+00, 1.3351e+00, 1.0908e+00, 2.9177e+00, 1.0000e+00],\n",
      "        [3.7702e-01, 1.0594e+00, 1.8422e+00, 2.7977e+00, 6.5636e-01, 1.0000e+00],\n",
      "        [9.8652e-01, 1.7806e+00, 6.0428e-01, 2.8535e-01, 4.7529e-01, 1.0000e+00],\n",
      "        [2.6991e+00, 3.5814e-01, 1.4579e+00, 4.7755e-01, 1.2927e+00, 1.0000e+00],\n",
      "        [9.4537e-01, 1.0528e+00, 8.8569e-01, 5.1367e-01, 1.2763e+00, 1.0000e+00],\n",
      "        [6.2218e-01, 1.0194e+00, 5.0725e-02, 5.2751e-01, 1.6326e+00, 1.0000e+00],\n",
      "        [1.6782e+00, 2.4933e+00, 8.9725e-01, 1.0262e+00, 2.7166e+00, 1.0000e+00],\n",
      "        [2.7913e+00, 2.4538e+00, 8.3240e-01, 2.1202e+00, 1.3464e+00, 1.0000e+00],\n",
      "        [1.1147e+00, 4.7743e-01, 1.6375e+00, 5.7504e-01, 2.3773e+00, 1.0000e+00],\n",
      "        [2.2530e-01, 2.3843e+00, 5.8252e-01, 1.3843e+00, 1.0363e+00, 1.0000e+00],\n",
      "        [2.5734e+00, 2.7322e+00, 1.1164e+00, 1.3684e+00, 2.1031e-01, 1.0000e+00],\n",
      "        [3.1096e-01, 3.6204e-01, 9.6047e-01, 2.6251e-02, 1.0320e+00, 1.0000e+00],\n",
      "        [8.9296e-01, 1.2575e-01, 9.1309e-01, 2.2314e+00, 2.7652e+00, 1.0000e+00],\n",
      "        [1.9922e-01, 1.7069e+00, 1.4556e+00, 2.8672e+00, 9.6861e-01, 1.0000e+00],\n",
      "        [1.5800e+00, 1.1480e-01, 5.4661e-01, 1.2437e+00, 1.3102e+00, 1.0000e+00],\n",
      "        [2.3264e+00, 2.7639e+00, 1.7689e+00, 2.3803e+00, 2.8699e+00, 1.0000e+00],\n",
      "        [2.5107e+00, 2.5364e+00, 2.8883e+00, 9.7850e-01, 6.5246e-01, 1.0000e+00],\n",
      "        [1.4799e-03, 1.1656e+00, 2.7512e+00, 2.3877e+00, 2.1247e+00, 1.0000e+00],\n",
      "        [1.7224e+00, 1.8691e+00, 1.8407e+00, 1.1706e+00, 2.7444e+00, 1.0000e+00],\n",
      "        [1.1240e+00, 1.8312e+00, 1.1199e+00, 2.0186e+00, 2.6656e+00, 1.0000e+00],\n",
      "        [2.2166e+00, 1.3216e+00, 2.1943e+00, 1.7915e+00, 4.5079e-01, 1.0000e+00],\n",
      "        [1.6891e+00, 2.7075e+00, 2.2014e+00, 5.7290e-01, 1.0821e+00, 1.0000e+00],\n",
      "        [2.4456e-01, 1.9768e+00, 1.7879e+00, 7.7462e-02, 1.0145e+00, 1.0000e+00],\n",
      "        [1.6069e+00, 2.2776e+00, 6.9906e-01, 2.9194e+00, 2.4635e+00, 1.0000e+00],\n",
      "        [2.0675e+00, 5.9270e-01, 4.5986e-01, 2.3539e+00, 1.9606e+00, 1.0000e+00],\n",
      "        [1.5347e+00, 2.9477e+00, 1.9736e+00, 1.9263e+00, 1.8765e+00, 1.0000e+00],\n",
      "        [1.9510e+00, 4.5297e-01, 1.1450e+00, 1.2498e+00, 2.3232e+00, 1.0000e+00],\n",
      "        [1.3733e+00, 7.7238e-01, 1.5250e+00, 1.0630e+00, 2.9335e+00, 1.0000e+00],\n",
      "        [2.6407e+00, 3.4660e-01, 2.1953e+00, 1.0950e+00, 2.3728e+00, 1.0000e+00],\n",
      "        [2.6483e+00, 4.7349e-01, 1.3407e+00, 1.5866e+00, 1.7220e+00, 1.0000e+00],\n",
      "        [8.3921e-01, 1.0887e+00, 2.0260e+00, 8.2913e-01, 2.3550e+00, 1.0000e+00],\n",
      "        [8.5527e-01, 1.4275e-01, 1.9713e+00, 2.7941e+00, 2.9941e+00, 1.0000e+00],\n",
      "        [7.8421e-01, 1.0655e+00, 2.8525e+00, 2.6525e+00, 8.4611e-01, 1.0000e+00],\n",
      "        [1.6769e+00, 1.5892e+00, 1.2064e+00, 1.0887e-01, 6.1976e-01, 1.0000e+00],\n",
      "        [1.2102e+00, 5.9493e-01, 9.0377e-01, 1.2043e+00, 1.4528e+00, 1.0000e+00],\n",
      "        [2.2659e+00, 1.1219e+00, 2.9973e-01, 7.1424e-01, 8.1304e-01, 1.0000e+00],\n",
      "        [5.3694e-01, 1.8897e+00, 3.6001e-01, 9.7145e-01, 2.5285e-01, 1.0000e+00],\n",
      "        [8.0275e-01, 1.0154e+00, 2.2179e+00, 1.8410e+00, 2.7611e+00, 1.0000e+00],\n",
      "        [1.3869e+00, 2.3544e+00, 1.6736e+00, 2.2131e+00, 1.9660e+00, 1.0000e+00],\n",
      "        [1.1523e+00, 2.9404e-01, 6.6261e-01, 2.6023e+00, 1.8618e+00, 1.0000e+00],\n",
      "        [5.0062e-01, 3.6599e-02, 2.7008e+00, 2.4632e+00, 1.0260e+00, 1.0000e+00],\n",
      "        [2.7031e+00, 2.5823e+00, 8.1651e-01, 2.3708e-02, 1.5901e+00, 1.0000e+00],\n",
      "        [7.2440e-01, 1.7925e+00, 1.0907e+00, 1.3922e+00, 2.8885e+00, 1.0000e+00],\n",
      "        [2.5889e+00, 1.5687e+00, 1.2595e+00, 3.9236e-01, 2.3423e+00, 1.0000e+00],\n",
      "        [5.9518e-01, 1.4913e+00, 9.5298e-01, 7.3678e-01, 1.5113e+00, 1.0000e+00],\n",
      "        [2.3455e-01, 2.5704e+00, 2.7571e+00, 3.6704e-01, 2.8797e+00, 1.0000e+00],\n",
      "        [5.4168e-01, 9.5958e-01, 2.0712e+00, 2.4199e+00, 2.8881e+00, 1.0000e+00],\n",
      "        [9.0561e-01, 1.2511e+00, 5.9562e-01, 1.9656e-02, 1.9944e+00, 1.0000e+00],\n",
      "        [2.6232e+00, 1.3485e+00, 2.3257e+00, 1.1255e+00, 2.3785e+00, 1.0000e+00],\n",
      "        [2.4580e+00, 6.0705e-01, 6.0524e-01, 2.9745e+00, 1.3674e+00, 1.0000e+00],\n",
      "        [2.3027e+00, 2.8116e+00, 1.1106e-01, 1.7462e-01, 1.5586e+00, 1.0000e+00],\n",
      "        [2.5260e+00, 1.7956e+00, 1.4556e+00, 1.0243e+00, 2.9286e+00, 1.0000e+00],\n",
      "        [2.6615e+00, 1.5526e+00, 2.4367e-01, 2.1188e+00, 2.8461e+00, 1.0000e+00],\n",
      "        [2.5980e+00, 4.9608e-01, 1.3966e+00, 1.2458e+00, 2.1387e+00, 1.0000e+00],\n",
      "        [1.8435e+00, 1.9494e+00, 1.4865e-01, 2.6765e+00, 2.1067e-01, 1.0000e+00],\n",
      "        [2.7325e+00, 7.0206e-02, 1.2652e+00, 2.1662e+00, 1.3290e+00, 1.0000e+00],\n",
      "        [3.2076e-01, 1.9430e-02, 1.3884e+00, 2.0140e+00, 6.6447e-01, 1.0000e+00],\n",
      "        [1.7707e+00, 1.4620e-01, 2.6354e+00, 7.4466e-01, 2.8126e+00, 1.0000e+00],\n",
      "        [1.1099e+00, 4.5251e-01, 1.7716e+00, 2.2710e+00, 1.2096e+00, 1.0000e+00],\n",
      "        [2.5341e+00, 1.6510e+00, 1.4159e+00, 2.7051e+00, 9.7369e-01, 1.0000e+00],\n",
      "        [1.9388e+00, 4.8090e-01, 5.5759e-02, 6.0301e-01, 2.2740e+00, 1.0000e+00],\n",
      "        [1.6786e+00, 3.4804e-01, 5.7173e-01, 2.3067e+00, 4.5683e-01, 1.0000e+00],\n",
      "        [1.7835e+00, 1.2635e+00, 9.6761e-01, 6.1024e-01, 7.3255e-01, 1.0000e+00],\n",
      "        [1.6259e+00, 9.4117e-01, 8.7737e-01, 2.8549e+00, 4.5742e-01, 1.0000e+00],\n",
      "        [2.9726e+00, 2.4945e+00, 8.0483e-01, 1.3876e+00, 1.1474e+00, 1.0000e+00],\n",
      "        [6.7524e-01, 1.9940e+00, 1.5134e+00, 6.4185e-01, 2.0775e+00, 1.0000e+00],\n",
      "        [1.2910e+00, 2.6350e+00, 2.5383e+00, 2.6227e+00, 1.8079e+00, 1.0000e+00],\n",
      "        [2.0436e+00, 3.0367e-01, 1.7168e+00, 2.9225e+00, 1.2775e+00, 1.0000e+00],\n",
      "        [2.9817e+00, 9.6190e-01, 5.7945e-01, 1.6836e+00, 3.3916e-01, 1.0000e+00],\n",
      "        [1.8654e+00, 2.7972e+00, 1.0140e+00, 2.5209e+00, 2.1490e+00, 1.0000e+00],\n",
      "        [5.2776e-01, 7.6593e-01, 2.1458e+00, 2.7365e+00, 1.3080e+00, 1.0000e+00],\n",
      "        [2.9562e+00, 1.3421e+00, 1.8065e+00, 4.9768e-01, 1.0501e+00, 1.0000e+00],\n",
      "        [1.3414e-01, 2.0209e+00, 2.9772e+00, 9.5065e-01, 2.8751e+00, 1.0000e+00],\n",
      "        [2.2277e-01, 2.0879e+00, 2.2132e+00, 2.0463e+00, 1.3238e+00, 2.0000e+00],\n",
      "        [2.0428e+00, 2.7625e+00, 3.0000e+00, 0.0000e+00, 6.1621e-01, 2.0000e+00]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(train_X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TL_GP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
