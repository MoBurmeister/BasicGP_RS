{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import time  \n",
    "import botorch\n",
    "from botorch.models import MultiTaskGP, SingleTaskGP, ModelList\n",
    "from botorch.models.transforms.outcome import OutcomeTransform, Standardize\n",
    "from botorch.models.transforms.input import InputTransform, Normalize\n",
    "from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood\n",
    "from botorch.fit import fit_gpytorch_model, fit_gpytorch_mll\n",
    "from botorch.acquisition.multi_objective import qNoisyExpectedHypervolumeImprovement\n",
    "from botorch.optim import optimize_acqf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea in this notebook: model multiple single task gps and compare with multi-task gp concerning pareto front etc. \n",
    "\n",
    "First intuition: multi-task is probably only \"better\" when the tasks are somehow correlated/uncorrelated?!\n",
    "\n",
    "In a paper it was mentioned, that the tasks need to be positively correlated - is that true?"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design of a multiple disc brake (Osyczka and Kundu)\n",
    "\n",
    "Objectives: Minimize mass of the brake and minimize stopping time\n",
    "\n",
    "Variables:\n",
    "\n",
    "x1: inner radius of the disc\n",
    "x2: outer radius of the disc\n",
    "x3: engaging force\n",
    "x4: number of friction surfaces\n",
    "\n",
    "where (55 <= x1 <= 80), (75 <= x2 <= 110), (1000 <= x3 <= 3000) and (2 <= x4 <= 20).\n",
    "\n",
    "Constraints (right now not used here):\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results: \n",
    "Pareto front:\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data generation: \n",
    " \n",
    "def objective_functions(tensor):\n",
    "    x1, x2, x3, x4 = tensor[0]\n",
    "    f1 = 4.9e-5 * (x2**2 - x1**2) * (x4 - 1)\n",
    "    f2 = 9.82e6 * (x2**2 - x1**2) / (x3 * x4 * (x2**3 - x1**3))\n",
    "    return torch.tensor([[-f1, -f2]])  # Negate the objectives for minimization\n",
    "\n",
    "#bounds definition:\n",
    "parameter_bounds = torch.tensor([[  55.,   75., 1000.,    2.], [  80.,  110., 3000.,   20.]], dtype=torch.float64)\n",
    "\n",
    "def get_initial_dataset(bounds: torch.Tensor, num_points: int = 2):\n",
    "    \"\"\"\n",
    "    Generates an initial dataset for the SingleTaskGP.\n",
    "\n",
    "    Parameters:\n",
    "    bounds (torch.Tensor): A 2 x d tensor specifying the lower and upper bounds for each dimension.\n",
    "    num_points (int): Number of points to sample. Default is 10.\n",
    "\n",
    "    Returns:\n",
    "    train_X (torch.Tensor): A n x d tensor of training features.\n",
    "    train_Y (torch.Tensor): A n x m tensor of training observations.\n",
    "    \"\"\"\n",
    "    # Ensure the bounds are of float type\n",
    "    bounds = bounds.float()\n",
    "\n",
    "    # Create a grid of points within the bounds\n",
    "    dim = bounds.size(1)\n",
    "    train_X = torch.zeros(num_points, dim)\n",
    "\n",
    "    # Calculate the step size for each dimension\n",
    "    steps = (bounds[1] - bounds[0]) / (num_points - 1)\n",
    "\n",
    "    # Generate points within the bounds\n",
    "    for i in range(num_points):\n",
    "        for j in range(dim):\n",
    "            train_X[i, j] = bounds[0, j] + i * steps[j]\n",
    "\n",
    "    # Evaluate the objective functions for each point\n",
    "    train_Y = torch.zeros(num_points, 2)  # Assuming there are 2 objective functions\n",
    "    for i in range(num_points):\n",
    "        train_Y[i] = objective_functions(train_X[i].unsqueeze(0))\n",
    "\n",
    "    train_X = train_X.to(dtype=torch.float64)\n",
    "    train_Y = train_Y.to(dtype=torch.float64)\n",
    "\n",
    "    return train_X, train_Y   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_train_Y(train_Y):\n",
    "    \"\"\"\n",
    "    Plots the training observations to visualize the Pareto front.\n",
    "\n",
    "    Parameters:\n",
    "    train_Y (torch.Tensor): A n x m tensor of training observations.\n",
    "    \"\"\"\n",
    "    # Convert train_Y to numpy for plotting\n",
    "    train_Y_np = -train_Y.numpy()\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(train_Y_np[:, 0], train_Y_np[:, 1], c='blue', marker='o')\n",
    "    plt.xlabel('Objective 1')\n",
    "    plt.ylabel('Objective 2')\n",
    "    plt.title('Training Observations')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.5000e+01, 7.5000e+01, 1.0000e+03, 2.0000e+00],\n",
      "        [8.0000e+01, 1.1000e+02, 3.0000e+03, 2.0000e+01]], dtype=torch.float64) tensor([[ -0.1274, -49.9648],\n",
      "        [ -5.3067,  -1.1391]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#model initiation\n",
    "\n",
    "#here I will use a multi-output singletaskGP, since the objectives all come from the same training data and are independent (at least I assume it for now)\n",
    "\n",
    "train_X, train_Y = get_initial_dataset(parameter_bounds, num_points=2)\n",
    "\n",
    "print(train_X, train_Y)\n",
    "\n",
    "train_X = train_X.to(dtype=torch.float64)\n",
    "train_Y = train_Y.to(dtype=torch.float64)\n",
    "\n",
    "model = SingleTaskGP(train_X=train_X, train_Y=train_Y, input_transform=Normalize(d=4, bounds=parameter_bounds), outcome_transform=Standardize(m=2))\n",
    "\n",
    "mll = ExactMarginalLogLikelihood(likelihood=model.likelihood, model=model) \n",
    "\n",
    "mll = fit_gpytorch_model(mll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = SingleTaskGP(train_X=train_X, train_Y=train_Y*0.7, input_transform=Normalize(d=4, bounds=parameter_bounds), outcome_transform=Standardize(m=2))\n",
    "\n",
    "mll_2 = ExactMarginalLogLikelihood(likelihood=model_2.likelihood, model=model_2) \n",
    "\n",
    "mll_2 = fit_gpytorch_model(mll_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.mlls import SumMarginalLogLikelihood\n",
    "from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from botorch.models.transforms.input import Normalize\n",
    "import torch\n",
    "from botorch.sampling.normal import SobolQMCNormalSampler\n",
    "from botorch.models.gpytorch import GPyTorchModel\n",
    "from gpytorch.models import GP\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from gpytorch.lazy import PsdSumLazyTensor\n",
    "from gpytorch.likelihoods import LikelihoodList\n",
    "from torch.nn import ModuleList\n",
    "from botorch.acquisition.multi_objective.logei import qLogNoisyExpectedHypervolumeImprovement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGPE(GP, GPyTorchModel):\n",
    "    \"\"\"\n",
    "    Rank-weighted GP ensemble. Note: this class inherits from GPyTorchModel which provides an\n",
    "        interface for GPyTorch models in botorch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, models, weights, num_outputs):\n",
    "        super().__init__()\n",
    "        self.models = ModuleList(models)\n",
    "        for m in models:\n",
    "            if not hasattr(m, \"likelihood\"):\n",
    "                raise ValueError(\n",
    "                    \"RGPE currently only supports models that have a likelihood (e.g. ExactGPs)\"\n",
    "                )\n",
    "        self.likelihood = LikelihoodList(*[m.likelihood for m in models])\n",
    "        self.weights = weights\n",
    "        self._num_outputs = num_outputs\n",
    "        self.to(weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.double()\n",
    "        weighted_means = []\n",
    "        weighted_covars = []\n",
    "        # filter model with zero weights\n",
    "        # weights on covariance matrices are weight**2\n",
    "        non_zero_weight_indices = (self.weights**2 > 0).nonzero()\n",
    "        non_zero_weights = self.weights[non_zero_weight_indices]\n",
    "        # re-normalize\n",
    "        non_zero_weights /= non_zero_weights.sum()\n",
    "\n",
    "        for non_zero_weight_idx in range(non_zero_weight_indices.shape[0]):\n",
    "            raw_idx = non_zero_weight_indices[non_zero_weight_idx].item()\n",
    "            model = self.models[raw_idx]\n",
    "            posterior = model.posterior(x)\n",
    "            # unstandardize predictions\n",
    "            #posterior_mean = posterior.mean.squeeze(-1) * model.outcome_transform.stdvs + model.outcome_transform.means\n",
    "            #posterior_cov = posterior.mvn.lazy_covariance_matrix * model.outcome_transform.stdvs.pow(2)\n",
    "            \n",
    "            #stdvs = model.outcome_transform.stdvs.squeeze(0)\n",
    "            # Number of points sampled\n",
    "            #n = x.shape[0]\n",
    "            # Number of output dimensions\n",
    "            #d = self._num_outputs\n",
    "            # Create the scaling matrix\n",
    "            #scaling_matrix = torch.kron(torch.eye(n), torch.diag(stdvs))\n",
    "            #scaling_matrix = scaling_matrix.double() \n",
    "           # posterior_cov = scaling_matrix @ posterior.mvn.lazy_covariance_matrix @ scaling_matrix.t()\n",
    "\n",
    "            # apply weight\n",
    "            weight = non_zero_weights[non_zero_weight_idx]\n",
    "            weighted_means.append(weight * posterior.mean)\n",
    "            weighted_covars.append( posterior.mvn.lazy_covariance_matrix * weight**2)\n",
    "        # set mean and covariance to be the rank-weighted sum the means and covariances of the\n",
    "        # base models and target model\n",
    "        mean_x = torch.stack(weighted_means).sum(dim=0)\n",
    "        print(f\"weighted_means: {weighted_means}\")\n",
    "        covar_x = PsdSumLazyTensor(*weighted_covars)\n",
    "        print(f\"weighted_covars: {weighted_covars}\")\n",
    "        print(mean_x, covar_x)\n",
    "        print(\"test\")\n",
    "        return MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted_means: [tensor([[ -0.2082, -23.6205],\n",
      "        [ -2.5089,  -1.9314]], dtype=torch.float64), tensor([[ -0.1457, -16.5343],\n",
      "        [ -1.7562,  -1.3520]], dtype=torch.float64)]\n",
      "weighted_covars: [<linear_operator.operators.block_diag_linear_operator.BlockDiagLinearOperator object at 0x0000018AEAF9D900>, <linear_operator.operators.block_diag_linear_operator.BlockDiagLinearOperator object at 0x0000018AEAF9FC40>]\n",
      "tensor([[ -0.3539, -40.1548],\n",
      "        [ -4.2651,  -3.2834]], dtype=torch.float64) <linear_operator.operators.psd_sum_linear_operator.PsdSumLinearOperator object at 0x0000018AEAF9FBB0>\n",
      "test\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[228], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m rgpe \u001b[38;5;241m=\u001b[39m RGPE(models\u001b[38;5;241m=\u001b[39m[model, model_2], weights\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64), num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m acq_function \u001b[38;5;241m=\u001b[39m \u001b[43mqLogNoisyExpectedHypervolumeImprovement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrgpe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43mref_point\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43mX_baseline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43mprune_baseline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m candidate, acq_value \u001b[38;5;241m=\u001b[39m optimize_acqf(\n\u001b[0;32m     10\u001b[0m acq_function\u001b[38;5;241m=\u001b[39macq_function,\n\u001b[0;32m     11\u001b[0m bounds\u001b[38;5;241m=\u001b[39mparameter_bounds,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m raw_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m\n\u001b[0;32m     15\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\multi_objective\\logei.py:420\u001b[0m, in \u001b[0;36mqLogNoisyExpectedHypervolumeImprovement.__init__\u001b[1;34m(self, model, ref_point, X_baseline, sampler, objective, constraints, X_pending, eta, prune_baseline, alpha, cache_pending, max_iep, incremental_nehvi, cache_root, tau_relu, tau_max, fat, marginalize_dim)\u001b[0m\n\u001b[0;32m    411\u001b[0m MultiObjectiveMCAcquisitionFunction\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    413\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m     eta\u001b[38;5;241m=\u001b[39meta,\n\u001b[0;32m    418\u001b[0m )\n\u001b[0;32m    419\u001b[0m SubsetIndexCachingMixin\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 420\u001b[0m \u001b[43mNoisyExpectedHypervolumeMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mref_point\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref_point\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_baseline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_baseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_pending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_pending\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprune_baseline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprune_baseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_pending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_pending\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mincremental_nehvi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mincremental_nehvi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_root\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_root\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmarginalize_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmarginalize_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;66;03m# parameters that are used by qLogEHVI\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtau_relu \u001b[38;5;241m=\u001b[39m tau_relu\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\utils\\multi_objective\\hypervolume.py:644\u001b[0m, in \u001b[0;36mNoisyExpectedHypervolumeMixin.__init__\u001b[1;34m(self, model, ref_point, X_baseline, sampler, objective, constraints, X_pending, prune_baseline, alpha, cache_pending, max_iep, incremental_nehvi, cache_root, marginalize_dim)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;66;03m# In the case that X_pending is not None, but there are fewer than\u001b[39;00m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;66;03m# max_iep pending points, the box decompositions are not performed in\u001b[39;00m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;66;03m# set_X_pending. Therefore, we need to perform a box decomposition over\u001b[39;00m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;66;03m# f(X_baseline) here.\u001b[39;00m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_pending \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m X_pending\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_iep:\n\u001b[1;32m--> 644\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_cell_bounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_new_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_baseline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;66;03m# Set q_in=-1 to so that self.sampler is updated at the next forward call.\u001b[39;00m\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_in \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\utils\\multi_objective\\hypervolume.py:696\u001b[0m, in \u001b[0;36mNoisyExpectedHypervolumeMixin._set_cell_bounds\u001b[1;34m(self, num_new_points)\u001b[0m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_in \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_sampler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    695\u001b[0m     \u001b[38;5;66;03m# Initialize the base sampler if needed.\u001b[39;00m\n\u001b[1;32m--> 696\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_posterior_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposterior\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_sampler \u001b[38;5;241m=\u001b[39m deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler)\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\acquisition\\acquisition.py:144\u001b[0m, in \u001b[0;36mMCSamplerMixin.get_posterior_samples\u001b[1;34m(self, posterior)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler \u001b[38;5;241m=\u001b[39m get_sampler(\n\u001b[0;32m    142\u001b[0m         posterior\u001b[38;5;241m=\u001b[39mposterior, sample_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_sample_shape\n\u001b[0;32m    143\u001b[0m     )\n\u001b[1;32m--> 144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposterior\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposterior\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\sampling\\normal.py:44\u001b[0m, in \u001b[0;36mNormalMCSampler.forward\u001b[1;34m(self, posterior)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Draws MC samples from the posterior.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m    The samples drawn from the posterior.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_base_samples(posterior\u001b[38;5;241m=\u001b[39mposterior)\n\u001b[1;32m---> 44\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[43mposterior\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsample_from_base_samples\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_samples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_extended_base_sample_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposterior\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposterior\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m samples\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\posteriors\\gpytorch.py:141\u001b[0m, in \u001b[0;36mGPyTorchPosterior.rsample_from_base_samples\u001b[1;34m(self, sample_shape, base_samples)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m linop_settings\u001b[38;5;241m.\u001b[39m_fast_covar_root_decomposition\u001b[38;5;241m.\u001b[39mis_default():\n\u001b[0;32m    140\u001b[0m         es\u001b[38;5;241m.\u001b[39menter_context(linop_settings\u001b[38;5;241m.\u001b[39m_fast_covar_root_decomposition(\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m--> 141\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_samples\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_mt:\n\u001b[0;32m    145\u001b[0m     samples \u001b[38;5;241m=\u001b[39m samples\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\gpytorch\\distributions\\multivariate_normal.py:248\u001b[0m, in \u001b[0;36mMultivariateNormal.rsample\u001b[1;34m(self, sample_shape, base_samples)\u001b[0m\n\u001b[0;32m    244\u001b[0m sample_shape \u001b[38;5;241m=\u001b[39m base_samples\u001b[38;5;241m.\u001b[39mshape[: base_samples\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc\u001b[38;5;241m.\u001b[39mdim()]\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# Reshape samples to be batch_size x num_dim x num_samples\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# or num_bim x num_samples\u001b[39;00m\n\u001b[1;32m--> 248\u001b[0m base_samples \u001b[38;5;241m=\u001b[39m \u001b[43mbase_samples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcovar_root\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m base_samples \u001b[38;5;241m=\u001b[39m base_samples\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# Now reparameterize those base samples\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# If necessary, adjust base_samples for rank of root decomposition\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "rgpe = RGPE(models=[model, model_2], weights=torch.tensor([0.5, 0.5], dtype=torch.float64), num_outputs=2)\n",
    "\n",
    "acq_function = qLogNoisyExpectedHypervolumeImprovement(model=rgpe, \n",
    "                                                            ref_point=[0, 0], \n",
    "                                                            X_baseline=train_X,\n",
    "                                                            prune_baseline=False)\n",
    "        \n",
    "\n",
    "candidate, acq_value = optimize_acqf(\n",
    "acq_function=acq_function,\n",
    "bounds=parameter_bounds,\n",
    "q=1,\n",
    "num_restarts=40,\n",
    "raw_samples=512\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_functions(tensor):\n",
    "    x1, x2, x3, x4 = tensor[0]\n",
    "    f1 = 4.9e-5 * (x2**2 - x1**2) * (x4 - 1)\n",
    "    f2 = 9.82e6 * (x2**2 - x1**2) / (x3 * x4 * (x2**3 - x1**3))\n",
    "    return torch.tensor([[-f1, -f2]])  # Negate the objectives for minimization\n",
    "\n",
    "#bounds definition:\n",
    "parameter_bounds = torch.tensor([[  55.,   75., 1000.,    2.], [  80.,  110., 3000.,   20.]], dtype=torch.float64)\n",
    "\n",
    "def get_initial_dataset(bounds: torch.Tensor, num_points: int = 10):\n",
    "    \"\"\"\n",
    "    Generates an initial dataset for the SingleTaskGP.\n",
    "\n",
    "    Parameters:\n",
    "    bounds (torch.Tensor): A 2 x d tensor specifying the lower and upper bounds for each dimension.\n",
    "    num_points (int): Number of points to sample. Default is 10.\n",
    "\n",
    "    Returns:\n",
    "    train_X (torch.Tensor): A n x d tensor of training features.\n",
    "    train_Y (torch.Tensor): A n x m tensor of training observations.\n",
    "    \"\"\"\n",
    "    # Ensure the bounds are of float type\n",
    "    bounds = bounds.float()\n",
    "\n",
    "    # Create a grid of points within the bounds\n",
    "    dim = bounds.size(1)\n",
    "    train_X = torch.zeros(num_points, dim)\n",
    "\n",
    "    # Calculate the step size for each dimension\n",
    "    steps = (bounds[1] - bounds[0]) / (num_points - 1)\n",
    "\n",
    "    # Generate points within the bounds\n",
    "    for i in range(num_points):\n",
    "        for j in range(dim):\n",
    "            train_X[i, j] = bounds[0, j] + i * steps[j]\n",
    "\n",
    "    # Evaluate the objective functions for each point\n",
    "    train_Y = torch.zeros(num_points, 2)  # Assuming there are 2 objective functions\n",
    "    for i in range(num_points):\n",
    "        train_Y[i] = objective_functions(train_X[i].unsqueeze(0))\n",
    "\n",
    "    train_X = train_X.to(dtype=torch.float64)\n",
    "    train_Y = train_Y.to(dtype=torch.float64)\n",
    "\n",
    "    return train_X, train_Y   \n",
    "\n",
    "\n",
    "#model initiation\n",
    "\n",
    "#here I will use a multi-output singletaskGP, since the objectives all come from the same training data and are independent (at least I assume it for now)\n",
    "\n",
    "train_X, train_Y = get_initial_dataset(parameter_bounds, num_points=7)\n",
    "\n",
    "print(train_X, train_Y)\n",
    "\n",
    "model = SingleTaskGP(train_X=train_X, train_Y=train_Y, input_transform=Normalize(d=4, bounds=parameter_bounds), outcome_transform=Standardize(m=2))\n",
    "\n",
    "mll = ExactMarginalLogLikelihood(likelihood=model.likelihood, model=model) \n",
    "\n",
    "mll = fit_gpytorch_model(mll)\n",
    "\n",
    "posterior = model.posterior(train_X)\n",
    "\n",
    "acq_function = qLogNoisyExpectedHypervolumeImprovement(model=model, X_baseline=train_X, ref_point=torch.tensor([0.0, 0.0], dtype=torch.float64))\n",
    "\n",
    "\n",
    "candidate, acq_value = optimize_acqf(\n",
    "    acq_function=acq_function,\n",
    "    bounds=parameter_bounds,\n",
    "    q=1,\n",
    "    num_restarts=40,\n",
    "    raw_samples=512,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<botorch.posteriors.gpytorch.GPyTorchPosterior object at 0x0000018AE80C8EE0>\n"
     ]
    }
   ],
   "source": [
    "posterior = model.posterior(train_X)\n",
    "\n",
    "print(posterior)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  3.0466, 270.7528],\n",
       "        [  3.0466, 270.7528]], dtype=torch.float64, grad_fn=<CloneBackward0>)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior.variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.0466e+00, 3.7685e-05, 0.0000e+00, 0.0000e+00],\n",
       "        [3.7685e-05, 3.0466e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 2.7075e+02, 3.3491e-03],\n",
       "        [0.0000e+00, 0.0000e+00, 3.3491e-03, 2.7075e+02]], dtype=torch.float64,\n",
       "       grad_fn=<MatmulBackward>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior.mvn.lazy_covariance_matrix.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdv_matrix = torch.diag(stdvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.6623,  0.0000],\n",
      "        [ 0.0000, 34.5250]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(stdv_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 20])\n"
     ]
    }
   ],
   "source": [
    "print(posterior.mvn.lazy_covariance_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Example covariance matrix (for general case)\n",
    "cov = posterior.mvn.lazy_covariance_matrix\n",
    "\n",
    "# Example standard deviations\n",
    "stdvs = model.outcome_transform.stdvs.squeeze(0)\n",
    "\n",
    "# Number of points sampled\n",
    "n = 2\n",
    "\n",
    "# Number of output dimensions\n",
    "d = len(stdvs)\n",
    "\n",
    "# Create the scaling matrix\n",
    "scaling_matrix = torch.kron(torch.eye(n), torch.diag(stdvs))\n",
    "\n",
    "# Unstandardize the covariance matrix\n",
    "unstandardized_cov = scaling_matrix @ cov @ scaling_matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.0863e+01, 4.7650e-03, 0.0000e+00, 0.0000e+00],\n",
      "        [4.7650e-03, 3.6315e+03, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 3.6315e+03, 4.2347e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 4.2347e-01, 3.2273e+05]], dtype=torch.float64,\n",
      "       grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(unstandardized_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Unknown attribute view for BlockDiagLinearOperator",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[126], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m unstandardized_cov \u001b[38;5;241m=\u001b[39m stdv_matrix \u001b[38;5;241m@\u001b[39m \u001b[43mcov\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m@\u001b[39m stdv_matrix\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\gpytorch\\lazy\\lazy_tensor.py:68\u001b[0m, in \u001b[0;36mdeprecated_lazy_tensor.<locals>.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m     63\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     64\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe property \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m#\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is deprecated. Use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     65\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m#\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     66\u001b[0m         )\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, new_name)\n\u001b[1;32m---> 68\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Unknown attribute view for BlockDiagLinearOperator"
     ]
    }
   ],
   "source": [
    "unstandardized_cov = stdv_matrix @ cov.view(2, 2, 2, 2) @ stdv_matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.tensor(0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_mean = posterior.mean * weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.distributions import MultivariateNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -0.0513, -19.7806],\n",
      "        [ -0.1693,  -8.0188],\n",
      "        [ -0.3124,  -4.0663],\n",
      "        [ -0.4801,  -2.6432],\n",
      "        [ -0.6756,  -1.7484],\n",
      "        [ -0.8999,  -1.2650],\n",
      "        [ -1.1553,  -0.9378],\n",
      "        [ -1.4423,  -0.7319],\n",
      "        [ -1.7655,  -0.5554],\n",
      "        [ -2.1220,  -0.4840]], dtype=torch.float64, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(weighted_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<linear_operator.operators.block_diag_linear_operator.BlockDiagLinearOperator object at 0x0000018AE6DF1120>\n"
     ]
    }
   ],
   "source": [
    "cov = posterior.mvn.lazy_covariance_matrix\n",
    "print(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<linear_operator.operators.block_diag_linear_operator.BlockDiagLinearOperator object at 0x0000018ABE5E8730>\n"
     ]
    }
   ],
   "source": [
    "weighted_cov = cov * weight\n",
    "\n",
    "print(weighted_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultivariateNormal(loc: torch.Size([10, 2]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultivariateNormal(weighted_mean, weighted_cov) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10\n",
    "\n",
    "from botorch.sampling.normal import SobolQMCNormalSampler\n",
    "sampler = SobolQMCNormalSampler(sample_shape=torch.Size([num_samples]))\n",
    "base_f_samps = sampler(posterior).squeeze(-1).squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "print(train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10, 2])\n"
     ]
    }
   ],
   "source": [
    "print(base_f_samps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ -0.1062, -49.0597],\n",
      "         [ -0.3964, -20.5315],\n",
      "         [ -0.8015, -11.7879],\n",
      "         [ -1.1748,  -6.6452],\n",
      "         [ -1.6819,  -4.7103],\n",
      "         [ -2.2581,  -2.0896],\n",
      "         [ -2.9032,  -2.8613],\n",
      "         [ -3.5878,  -0.9898],\n",
      "         [ -4.3823,  -2.4178],\n",
      "         [ -5.3205,  -2.9607]],\n",
      "\n",
      "        [[ -0.1370, -51.1381],\n",
      "         [ -0.4307, -19.7059],\n",
      "         [ -0.7770,  -7.9404],\n",
      "         [ -1.2083,  -6.7307],\n",
      "         [ -1.6914,  -3.7425],\n",
      "         [ -2.2451,  -4.4813],\n",
      "         [ -2.8862,  -2.3212],\n",
      "         [ -3.6499,  -1.9609],\n",
      "         [ -4.4449,  -1.0305],\n",
      "         [ -5.2950,  -1.0145]],\n",
      "\n",
      "        [[ -0.1472, -47.0243],\n",
      "         [ -0.4228, -21.2015],\n",
      "         [ -0.7491,  -9.7611],\n",
      "         [ -1.1891,  -7.7572],\n",
      "         [ -1.7139,  -3.1642],\n",
      "         [ -2.2341,  -3.8966],\n",
      "         [ -2.8926,  -4.1801],\n",
      "         [ -3.6096,  -1.4041],\n",
      "         [ -4.4261,  -2.0484],\n",
      "         [ -5.2877,  -2.0724]],\n",
      "\n",
      "        [[ -0.1233, -49.6468],\n",
      "         [ -0.4395, -18.2735],\n",
      "         [ -0.7931, -10.8235],\n",
      "         [ -1.2331,  -5.8078],\n",
      "         [ -1.6765,  -6.7648],\n",
      "         [ -2.2909,  -2.8099],\n",
      "         [ -2.8685,  -1.3105],\n",
      "         [ -3.5932,  -3.6786],\n",
      "         [ -4.4024,   0.0921],\n",
      "         [ -5.3133,   0.1596]],\n",
      "\n",
      "        [[ -0.1219, -48.1993],\n",
      "         [ -0.4257, -18.7406],\n",
      "         [ -0.7846, -11.1096],\n",
      "         [ -1.1989,  -8.2700],\n",
      "         [ -1.7020,  -4.3109],\n",
      "         [ -2.2102,  -2.7399],\n",
      "         [ -2.8956,  -1.6645],\n",
      "         [ -3.6061,  -3.0731],\n",
      "         [ -4.4116,  -0.4567],\n",
      "         [ -5.2757,  -2.4546]],\n",
      "\n",
      "        [[ -0.1552, -50.0427],\n",
      "         [ -0.4103, -22.0350],\n",
      "         [ -0.7605,  -8.9864],\n",
      "         [ -1.2145,  -4.2956],\n",
      "         [ -1.6638,  -4.8183],\n",
      "         [ -2.2635,  -3.3972],\n",
      "         [ -2.8612,  -2.6328],\n",
      "         [ -3.6128,  -1.5036],\n",
      "         [ -4.4162,  -1.5737],\n",
      "         [ -5.3067,  -0.3401]],\n",
      "\n",
      "        [[ -0.1324, -48.6493],\n",
      "         [ -0.4466, -19.5786],\n",
      "         [ -0.7703, -10.1343],\n",
      "         [ -1.1804,  -5.9654],\n",
      "         [ -1.6870,  -5.2712],\n",
      "         [ -2.2556,  -5.2597],\n",
      "         [ -2.9234,   0.2144],\n",
      "         [ -3.6210,  -2.2803],\n",
      "         [ -4.4283,  -0.7162],\n",
      "         [ -5.3305,  -1.2996]],\n",
      "\n",
      "        [[ -0.1079, -50.3798],\n",
      "         [ -0.4153, -20.3995],\n",
      "         [ -0.8104, -10.3893],\n",
      "         [ -1.2058,  -7.0776],\n",
      "         [ -1.6952,  -2.5006],\n",
      "         [ -2.2413,  -0.4561],\n",
      "         [ -2.8763,  -3.6785],\n",
      "         [ -3.5774,   1.6983],\n",
      "         [ -4.3994,  -3.1402],\n",
      "         [ -5.3019,   0.3097]],\n",
      "\n",
      "        [[ -0.1150, -47.8377],\n",
      "         [ -0.4601, -22.9286],\n",
      "         [ -0.7796, -10.8504],\n",
      "         [ -1.1956,  -8.8365],\n",
      "         [ -1.7059,  -6.1363],\n",
      "         [ -2.2406,  -1.7526],\n",
      "         [ -2.8561,  -0.5513],\n",
      "         [ -3.6068,  -2.6908],\n",
      "         [ -4.4203,   1.0070],\n",
      "         [ -5.2831,  -1.6246]],\n",
      "\n",
      "        [[ -0.1312, -49.7929],\n",
      "         [ -0.4129, -19.0598],\n",
      "         [ -0.7942,  -9.3857],\n",
      "         [ -1.2192,  -4.8605],\n",
      "         [ -1.6493,  -3.1421],\n",
      "         [ -2.2490,  -4.2122],\n",
      "         [ -2.8996,  -3.3823],\n",
      "         [ -3.5997,  -1.6611],\n",
      "         [ -4.4071,  -1.8104],\n",
      "         [ -5.3099,  -0.0944]]], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(base_f_samps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<linear_operator.operators.block_diag_linear_operator.BlockDiagLinearOperator object at 0x0000018AE6D84400>\n"
     ]
    }
   ],
   "source": [
    "print(model.posterior(train_X).mvn.lazy_covariance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.OrderedDict'>\n"
     ]
    }
   ],
   "source": [
    "dict = model.state_dict()\n",
    "\n",
    "dict.update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class MultiObjectiveRankingLoss:\n",
    "    def get_pareto_dominance(self, point_1, point_2):\n",
    "        # Check if point_1 dominates point_2\n",
    "        dominates = (point_1 <= point_2).all() and (point_1 < point_2).any()\n",
    "        \n",
    "        if dominates:\n",
    "            return 1  # point_1 dominates point_2\n",
    "        \n",
    "        # Check if point_2 dominates point_1\n",
    "        dominated = (point_2 <= point_1).all() and (point_2 < point_1).any()\n",
    "        \n",
    "        if dominated:\n",
    "            return -1  # point_2 dominates point_1\n",
    "        \n",
    "        return 0  # Neither point dominates the other\n",
    "    \n",
    "    def compute_ranking_loss(self, target_f_samples, true_train_Y):\n",
    "        # Check if target_f_samples and true_train_Y have the same shape\n",
    "        if target_f_samples.shape != true_train_Y.shape:\n",
    "            raise ValueError(\"The shapes of the target_f_samples and true_train_Y must be the same.\")\n",
    "\n",
    "        n, d = target_f_samples.shape\n",
    "        ranking_loss = 0\n",
    "\n",
    "        # Iterate over all pairs of training examples\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                    # Get the predicted and true values for the pair (i, j)\n",
    "                    pred_i, pred_j = target_f_samples[i], target_f_samples[j]\n",
    "                    true_i, true_j = true_train_Y[i], true_train_Y[j]\n",
    "\n",
    "                    # Compute Pareto dominance for both predicted and true values\n",
    "                    pred_dominance = self.get_pareto_dominance(pred_i, pred_j)\n",
    "                    #print(\"predict\")\n",
    "                    #print(pred_i, pred_j)\n",
    "                    #print(pred_dominance)\n",
    "                    true_dominance = self.get_pareto_dominance(true_i, true_j)\n",
    "                    #print(\"true\")\n",
    "                    #print(true_i, true_j)\n",
    "                    #print(true_dominance)\n",
    "\n",
    "                    # Increment ranking loss if the predicted dominance doesn't match the true dominance\n",
    "                    if pred_dominance != true_dominance:\n",
    "                        ranking_loss += 1\n",
    "                        print(ranking_loss)\n",
    "\n",
    "                    #print(\"next Point\")\n",
    "\n",
    "        return ranking_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pareto dominance (point_1 vs point_2): 0\n",
      "Pareto dominance (point_1 vs point_3): 0\n",
      "Pareto dominance (point_2 vs point_3): 1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "Computed ranking loss: 5\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the class\n",
    "loss_calculator = MultiObjectiveRankingLoss()\n",
    "\n",
    "# Example data (three-dimensional multi-objective example)\n",
    "target_f_samples = torch.tensor([[-1686.9345529751338, -9.694705981882207, -0.10764831622708651], [-1689.7025038207535, -10.155442392061087, -0.106731646573131], [-1689.7934184940452, -10.381630816142268, -0.12730377132127407], [-1673.3847492877574, -9.59549149256099, -0.08544080465945393], [-1673.2530928970825, -8.017307462006844, -0.1713744902330736]])  # Predicted values\n",
    "true_train_Y = torch.tensor([[-1667.71484375, -10.083209037780762, -0.2165755033493042], [-1672.8330078125, -10.222806930541992, -0.08668578416109085], [-1680.0157470703125, -9.050023078918457, -0.10142767429351807], [-1687.068603515625, -10.007349014282227, -0.06876835972070694], [-1697.1553955078125, -9.698583602905273, -0.03054405003786087]])       # True values\n",
    "\n",
    "# Test the get_pareto_dominance function with three-dimensional points\n",
    "point_1 = torch.tensor([1.0, 2.0, 3.0])\n",
    "point_2 = torch.tensor([2.0, 1.0, 0.5])\n",
    "point_3 = torch.tensor([3.0, 3.0, 1.0])\n",
    "print(\"Pareto dominance (point_1 vs point_2):\", loss_calculator.get_pareto_dominance(point_1, point_2))  # Expected: 0 (neither dominates)\n",
    "print(\"Pareto dominance (point_1 vs point_3):\", loss_calculator.get_pareto_dominance(point_1, point_3))  # Expected: 0 (neither dominates)\n",
    "print(\"Pareto dominance (point_2 vs point_3):\", loss_calculator.get_pareto_dominance(point_2, point_3))  # Expected: 1 (point_2 dominates)\n",
    "\n",
    "# Test the compute_ranking_loss function\n",
    "ranking_loss = loss_calculator.compute_ranking_loss(target_f_samples, true_train_Y)\n",
    "print(\"Computed ranking loss:\", ranking_loss)  # Expected output depends on the comparison\n",
    "\n",
    "# For the example provided, you should be able to manually verify if the loss is computed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pareto dominance (point_1 vs point_2): 0\n",
      "Pareto dominance (point_1 vs point_3): 1\n",
      "Computed ranking loss: 4\n"
     ]
    }
   ],
   "source": [
    "loss_calculator = MultiObjectiveRankingLoss()\n",
    "\n",
    "# Example data (simple multi-objective example)\n",
    "target_f_samples = torch.tensor([[1.0, 2.0], [2.0, 1.0], [3.0, 3.0]])  # Predicted values\n",
    "true_train_Y = torch.tensor([[1.5, 2.5], [2.5, 1.5], [2.0, 2.0]])       # True values\n",
    "\n",
    "# Test the get_pareto_dominance function\n",
    "point_1 = torch.tensor([1.0, 2.0])\n",
    "point_2 = torch.tensor([2.0, 1.0])\n",
    "point_3 = torch.tensor([1.5, 2.5])\n",
    "print(\"Pareto dominance (point_1 vs point_2):\", loss_calculator.get_pareto_dominance(point_1, point_2))  # Expected: 0 (neither dominates)\n",
    "print(\"Pareto dominance (point_1 vs point_3):\", loss_calculator.get_pareto_dominance(point_1, point_3))  # Expected: 1 (point_3 dominates)\n",
    "\n",
    "# Test the compute_ranking_loss function\n",
    "ranking_loss = loss_calculator.compute_ranking_loss(target_f_samples, true_train_Y)\n",
    "print(\"Computed ranking loss:\", ranking_loss)  # Expected output depends on the comparison\n",
    "\n",
    "# For the example provided, you should be able to manually verify if the loss is computed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary Key: model_info\n",
      "Dictionary Value: OrderedDict([('models.0.likelihood.noise_covar.raw_noise', tensor([0.0067], dtype=torch.float64)), ('models.0.likelihood.noise_covar.noise_prior.concentration', tensor(1.1000, dtype=torch.float64)), ('models.0.likelihood.noise_covar.noise_prior.rate', tensor(0.0500, dtype=torch.float64)), ('models.0.likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(1.0000e-04, dtype=torch.float64)), ('models.0.likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf, dtype=torch.float64)), ('models.0.mean_module.raw_constant', tensor(-0.1984, dtype=torch.float64)), ('models.0.covar_module.raw_outputscale', tensor(-0.2035, dtype=torch.float64)), ('models.0.covar_module.base_kernel.raw_lengthscale', tensor([[-0.2703, -0.0853, -0.1118, -0.6366, -0.3437]], dtype=torch.float64)), ('models.0.covar_module.base_kernel.lengthscale_prior.concentration', tensor(3., dtype=torch.float64)), ('models.0.covar_module.base_kernel.lengthscale_prior.rate', tensor(6., dtype=torch.float64)), ('models.0.covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0., dtype=torch.float64)), ('models.0.covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf, dtype=torch.float64)), ('models.0.covar_module.outputscale_prior.concentration', tensor(2., dtype=torch.float64)), ('models.0.covar_module.outputscale_prior.rate', tensor(0.1500, dtype=torch.float64)), ('models.0.covar_module.raw_outputscale_constraint.lower_bound', tensor(0., dtype=torch.float64)), ('models.0.covar_module.raw_outputscale_constraint.upper_bound', tensor(inf, dtype=torch.float64)), ('models.0.outcome_transform.means', tensor([[-1682.2140]], dtype=torch.float64)), ('models.0.outcome_transform.stdvs', tensor([[8.7705]], dtype=torch.float64)), ('models.0.outcome_transform._stdvs_sq', tensor([[76.9224]], dtype=torch.float64)), ('models.0.outcome_transform._is_trained', tensor(True)), ('models.0.input_transform._coefficient', tensor([[1.9859, 1.9033, 1.8359, 1.9510, 1.8152]], dtype=torch.float64)), ('models.0.input_transform._offset', tensor([[1.0141, 1.0000, 1.0000, 1.0490, 1.1848]], dtype=torch.float64)), ('models.1.likelihood.noise_covar.raw_noise', tensor([0.0106], dtype=torch.float64)), ('models.1.likelihood.noise_covar.noise_prior.concentration', tensor(1.1000, dtype=torch.float64)), ('models.1.likelihood.noise_covar.noise_prior.rate', tensor(0.0500, dtype=torch.float64)), ('models.1.likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(1.0000e-04, dtype=torch.float64)), ('models.1.likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf, dtype=torch.float64)), ('models.1.mean_module.raw_constant', tensor(-0.1826, dtype=torch.float64)), ('models.1.covar_module.raw_outputscale', tensor(-0.1246, dtype=torch.float64)), ('models.1.covar_module.base_kernel.raw_lengthscale', tensor([[-0.1919, -0.3216, -0.0872, -0.8934, -0.4763]], dtype=torch.float64)), ('models.1.covar_module.base_kernel.lengthscale_prior.concentration', tensor(3., dtype=torch.float64)), ('models.1.covar_module.base_kernel.lengthscale_prior.rate', tensor(6., dtype=torch.float64)), ('models.1.covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0., dtype=torch.float64)), ('models.1.covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf, dtype=torch.float64)), ('models.1.covar_module.outputscale_prior.concentration', tensor(2., dtype=torch.float64)), ('models.1.covar_module.outputscale_prior.rate', tensor(0.1500, dtype=torch.float64)), ('models.1.covar_module.raw_outputscale_constraint.lower_bound', tensor(0., dtype=torch.float64)), ('models.1.covar_module.raw_outputscale_constraint.upper_bound', tensor(inf, dtype=torch.float64)), ('models.1.outcome_transform.means', tensor([[-9.4084]], dtype=torch.float64)), ('models.1.outcome_transform.stdvs', tensor([[1.1179]], dtype=torch.float64)), ('models.1.outcome_transform._stdvs_sq', tensor([[1.2498]], dtype=torch.float64)), ('models.1.outcome_transform._is_trained', tensor(True)), ('models.1.input_transform._coefficient', tensor([[1.9859, 1.9033, 1.8359, 1.9510, 1.8152]], dtype=torch.float64)), ('models.1.input_transform._offset', tensor([[1.0141, 1.0000, 1.0000, 1.0490, 1.1848]], dtype=torch.float64)), ('models.2.likelihood.noise_covar.raw_noise', tensor([0.0376], dtype=torch.float64)), ('models.2.likelihood.noise_covar.noise_prior.concentration', tensor(1.1000, dtype=torch.float64)), ('models.2.likelihood.noise_covar.noise_prior.rate', tensor(0.0500, dtype=torch.float64)), ('models.2.likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(1.0000e-04, dtype=torch.float64)), ('models.2.likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf, dtype=torch.float64)), ('models.2.mean_module.raw_constant', tensor(-0.0262, dtype=torch.float64)), ('models.2.covar_module.raw_outputscale', tensor(0.5580, dtype=torch.float64)), ('models.2.covar_module.base_kernel.raw_lengthscale', tensor([[-0.4542, -1.0043, -0.8846, -0.6275, -0.7799]], dtype=torch.float64)), ('models.2.covar_module.base_kernel.lengthscale_prior.concentration', tensor(3., dtype=torch.float64)), ('models.2.covar_module.base_kernel.lengthscale_prior.rate', tensor(6., dtype=torch.float64)), ('models.2.covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0., dtype=torch.float64)), ('models.2.covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf, dtype=torch.float64)), ('models.2.covar_module.outputscale_prior.concentration', tensor(2., dtype=torch.float64)), ('models.2.covar_module.outputscale_prior.rate', tensor(0.1500, dtype=torch.float64)), ('models.2.covar_module.raw_outputscale_constraint.lower_bound', tensor(0., dtype=torch.float64)), ('models.2.covar_module.raw_outputscale_constraint.upper_bound', tensor(inf, dtype=torch.float64)), ('models.2.outcome_transform.means', tensor([[-0.1144]], dtype=torch.float64)), ('models.2.outcome_transform.stdvs', tensor([[0.0246]], dtype=torch.float64)), ('models.2.outcome_transform._stdvs_sq', tensor([[0.0006]], dtype=torch.float64)), ('models.2.outcome_transform._is_trained', tensor(True)), ('models.2.input_transform._coefficient', tensor([[1.9859, 1.9033, 1.8359, 1.9510, 1.8152]], dtype=torch.float64)), ('models.2.input_transform._offset', tensor([[1.0141, 1.0000, 1.0000, 1.0490, 1.1848]], dtype=torch.float64)), ('likelihood.likelihoods.0.noise_covar.raw_noise', tensor([0.0067], dtype=torch.float64)), ('likelihood.likelihoods.0.noise_covar.noise_prior.concentration', tensor(1.1000, dtype=torch.float64)), ('likelihood.likelihoods.0.noise_covar.noise_prior.rate', tensor(0.0500, dtype=torch.float64)), ('likelihood.likelihoods.0.noise_covar.raw_noise_constraint.lower_bound', tensor(1.0000e-04, dtype=torch.float64)), ('likelihood.likelihoods.0.noise_covar.raw_noise_constraint.upper_bound', tensor(inf, dtype=torch.float64)), ('likelihood.likelihoods.1.noise_covar.raw_noise', tensor([0.0106], dtype=torch.float64)), ('likelihood.likelihoods.1.noise_covar.noise_prior.concentration', tensor(1.1000, dtype=torch.float64)), ('likelihood.likelihoods.1.noise_covar.noise_prior.rate', tensor(0.0500, dtype=torch.float64)), ('likelihood.likelihoods.1.noise_covar.raw_noise_constraint.lower_bound', tensor(1.0000e-04, dtype=torch.float64)), ('likelihood.likelihoods.1.noise_covar.raw_noise_constraint.upper_bound', tensor(inf, dtype=torch.float64)), ('likelihood.likelihoods.2.noise_covar.raw_noise', tensor([0.0376], dtype=torch.float64)), ('likelihood.likelihoods.2.noise_covar.noise_prior.concentration', tensor(1.1000, dtype=torch.float64)), ('likelihood.likelihoods.2.noise_covar.noise_prior.rate', tensor(0.0500, dtype=torch.float64)), ('likelihood.likelihoods.2.noise_covar.raw_noise_constraint.lower_bound', tensor(1.0000e-04, dtype=torch.float64)), ('likelihood.likelihoods.2.noise_covar.raw_noise_constraint.upper_bound', tensor(inf, dtype=torch.float64))])\n",
      "\n",
      "Dictionary Key: dataset_info\n",
      "Dictionary Value: {'num_inputs': 5, 'num_outputs': 3, 'num_datapoints': 13, 'maximization_flags': [False, False, False], 'bounds': tensor([[1., 1., 1., 1., 1.],\n",
      "        [3., 3., 3., 3., 3.]], dtype=torch.float64), 'variation_factor': 0.0}\n",
      "\n",
      "Dictionary Key: dataset\n",
      "Dictionary Value: {'identifier': None, 'input_data': array([[1.45208414, 2.56221953, 1.1572678 , 1.46857467, 2.07673504],\n",
      "       [1.01407726, 2.12146244, 2.43217983, 1.23958865, 1.79515923],\n",
      "       [2.28231378, 1.3514496 , 2.38729181, 1.88685815, 1.88671   ],\n",
      "       [1.39379633, 2.21374494, 1.62762025, 2.28933103, 2.42072368],\n",
      "       [2.07782   , 1.55976116, 1.31844989, 1.04898922, 1.2864035 ],\n",
      "       [1.72972151, 1.07118003, 2.02384585, 1.75504756, 1.53071774],\n",
      "       [2.86745671, 2.78423875, 1.59183608, 2.12225598, 2.92424915],\n",
      "       [1.8666676 , 2.90332796, 2.83586244, 2.60930242, 2.37678223],\n",
      "       [2.4866743 , 1.79082106, 2.66642196, 2.49034538, 1.18478455],\n",
      "       [2.71278089, 1.85028614, 1.99238395, 2.84094831, 2.74559254],\n",
      "       [3.        , 1.        , 1.        , 3.        , 3.        ],\n",
      "       [1.30073822, 2.17796244, 1.61486286, 1.18711015, 1.77196933],\n",
      "       [2.0088358 , 2.58041406, 1.14547191, 1.13165062, 2.10711312]]), 'output_data': array([[-1.67553546e+03, -8.46289934e+00, -9.32731139e-02],\n",
      "       [-1.67628164e+03, -7.71548183e+00, -1.71837353e-01],\n",
      "       [-1.68268398e+03, -9.50180406e+00, -1.16793824e-01],\n",
      "       [-1.68460804e+03, -1.01292611e+01, -1.00974099e-01],\n",
      "       [-1.66865779e+03, -8.64753856e+00, -1.15704446e-01],\n",
      "       [-1.67646597e+03, -9.48957703e+00, -9.60988822e-02],\n",
      "       [-1.69019677e+03, -9.93654693e+00, -8.34010663e-02],\n",
      "       [-1.69511909e+03, -1.00312307e+01, -1.30215938e-01],\n",
      "       [-1.68699326e+03, -9.80740615e+00, -1.44588528e-01],\n",
      "       [-1.69424676e+03, -1.10384881e+01, -1.03390761e-01],\n",
      "       [-1.69077711e+03, -1.12622000e+01, -9.92000000e-02],\n",
      "       [-1.67284583e+03, -8.10701674e+00, -1.31716479e-01],\n",
      "       [-1.67437011e+03, -8.17963742e+00, -1.00094778e-01]]), 'bounds': tensor([[1., 1., 1., 1., 1.],\n",
      "        [3., 3., 3., 3., 3.]], dtype=torch.float64), 'maximization_flags': [False, False, False]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import pkl dataset: \n",
    "\n",
    "path = \"C:\\\\Users\\\\Moritz\\\\Documents\\\\Masterarbeit_GAMI\\\\BasicGP_RS\\\\smart_doe_bayesian_optimization\\\\data_export\\\\multi_singletaskgp_data_export\\\\20240812_1324_BOMOGP_TL_Opt_var_fac_0_0\\\\20240812_1324_BOMOGP_TL_Opt_var_fac_0_0_combined_dataset_info.pkl\"\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Load the pickle file\n",
    "with open(path, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# Print the loaded dictionaries\n",
    "for key, value in data.items():\n",
    "    print(f\"Dictionary Key: {key}\")\n",
    "    print(f\"Dictionary Value: {value}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6931, 0.6931, 0.6931, 0.6931]], dtype=torch.float64,\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tensor([[0.6931, 0.6931, 0.6931, 0.6931]], dtype=torch.float64,\n",
      "       grad_fn=<UnbindBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for kernel in model.covar_module.base_kernel.lengthscale:\n",
    "    print(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0., 0.], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.mean_module.constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExactMarginalLogLikelihood(\n",
       "  (likelihood): GaussianLikelihood(\n",
       "    (noise_covar): HomoskedasticNoise(\n",
       "      (noise_prior): GammaPrior()\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "  )\n",
       "  (model): SingleTaskGP(\n",
       "    (likelihood): GaussianLikelihood(\n",
       "      (noise_covar): HomoskedasticNoise(\n",
       "        (noise_prior): GammaPrior()\n",
       "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "      )\n",
       "    )\n",
       "    (mean_module): ConstantMean()\n",
       "    (covar_module): ScaleKernel(\n",
       "      (base_kernel): MaternKernel(\n",
       "        (lengthscale_prior): GammaPrior()\n",
       "        (raw_lengthscale_constraint): Positive()\n",
       "      )\n",
       "      (outputscale_prior): GammaPrior()\n",
       "      (raw_outputscale_constraint): Positive()\n",
       "    )\n",
       "    (outcome_transform): Standardize()\n",
       "    (input_transform): Normalize()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the model\n",
    "\n",
    "fit_gpytorch_mll(mll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-0.2088, -0.5427], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.mean_module.constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7869, 0.7869, 0.7869, 0.7869]], dtype=torch.float64,\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tensor([[0.4607, 0.4607, 0.4607, 0.4607]], dtype=torch.float64,\n",
      "       grad_fn=<UnbindBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for kernel in model.covar_module.base_kernel.lengthscale:\n",
    "    print(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on training data:\n",
      "tensor([[ -0.1283, -49.4515],\n",
      "        [ -0.4232, -20.0471],\n",
      "        [ -0.7809, -10.1657],\n",
      "        [ -1.2003,  -6.6080],\n",
      "        [ -1.6890,  -4.3711],\n",
      "        [ -2.2496,  -3.1624],\n",
      "        [ -2.8882,  -2.3445],\n",
      "        [ -3.6058,  -1.8297],\n",
      "        [ -4.4138,  -1.3884],\n",
      "        [ -5.3050,  -1.2101]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model.posterior(train_X).mean\n",
    "    print(\"Predictions on training data:\")\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_optimization_step(model, train_X, train_Y, bounds, num_restarts=10, raw_samples=512):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    qNEHVI = qNoisyExpectedHypervolumeImprovement(\n",
    "        model=model,\n",
    "        ref_point=train_Y.min(dim=0).values - 0.1,\n",
    "        X_baseline=train_X\n",
    "    )\n",
    "\n",
    "    # Optimize the acquisition function to find the next point to sample\n",
    "    new_X, acq_func_value = optimize_acqf(\n",
    "        acq_function=qNEHVI,\n",
    "        bounds=bounds,\n",
    "        q=1,\n",
    "        num_restarts=num_restarts,\n",
    "        raw_samples=raw_samples,\n",
    "        options={\"batch_limit\": 5, \"maxiter\": 200},\n",
    "    )\n",
    "\n",
    "    print(f\"Acquisition function value:{acq_func_value}\")\n",
    "    \n",
    "    return new_X, acq_func_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value:16.16283041727844\n",
      "tensor([[  60.1387,   75.6928, 2389.3547,    5.1235]], dtype=torch.float64)\n",
      "tensor([[-0.4269, -7.8398]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "new_X, acq_func_value = perform_optimization_step(model, train_X, train_Y, parameter_bounds)\n",
    "print(new_X)\n",
    "new_Y = objective_functions(new_X)\n",
    "print(new_Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2209,  1.0517,  0.8486,  0.6090,  0.3305,  0.0106, -0.3532, -0.7633,\n",
      "         -1.2223, -1.7326],\n",
      "        [-2.6406, -0.6209, -0.0264,  0.2358,  0.3751,  0.4578,  0.5108,  0.5466,\n",
      "          0.5718,  0.5901]], dtype=torch.float64)\n",
      "torch.Size([2, 10])\n",
      "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1111, 0.1111, 0.1111, 0.1111],\n",
      "         [0.2222, 0.2222, 0.2222, 0.2222],\n",
      "         [0.3333, 0.3333, 0.3333, 0.3333],\n",
      "         [0.4444, 0.4444, 0.4444, 0.4444],\n",
      "         [0.5556, 0.5556, 0.5556, 0.5556],\n",
      "         [0.6667, 0.6667, 0.6667, 0.6667],\n",
      "         [0.7778, 0.7778, 0.7778, 0.7778],\n",
      "         [0.8889, 0.8889, 0.8889, 0.8889],\n",
      "         [1.0000, 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1111, 0.1111, 0.1111, 0.1111],\n",
      "         [0.2222, 0.2222, 0.2222, 0.2222],\n",
      "         [0.3333, 0.3333, 0.3333, 0.3333],\n",
      "         [0.4444, 0.4444, 0.4444, 0.4444],\n",
      "         [0.5556, 0.5556, 0.5556, 0.5556],\n",
      "         [0.6667, 0.6667, 0.6667, 0.6667],\n",
      "         [0.7778, 0.7778, 0.7778, 0.7778],\n",
      "         [0.8889, 0.8889, 0.8889, 0.8889],\n",
      "         [1.0000, 1.0000, 1.0000, 1.0000]]], dtype=torch.float64),)\n",
      "torch.Size([2, 10, 4])\n"
     ]
    }
   ],
   "source": [
    "print(model.train_targets)\n",
    "print(model.train_targets.shape)\n",
    "print(model.train_inputs)\n",
    "print(model.train_inputs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2209,  1.0517,  0.8486,  0.6090,  0.3305,  0.0106, -0.3532, -0.7633,\n",
      "         -1.2223, -1.7326,  1.0501],\n",
      "        [-2.6406, -0.6209, -0.0264,  0.2358,  0.3751,  0.4578,  0.5108,  0.5466,\n",
      "          0.5718,  0.5901,  0.1468]], dtype=torch.float64)\n",
      "torch.Size([2, 11])\n",
      "[tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.1111e-01, 1.1111e-01, 1.1111e-01, 1.1111e-01],\n",
      "         [2.2222e-01, 2.2222e-01, 2.2222e-01, 2.2222e-01],\n",
      "         [3.3333e-01, 3.3333e-01, 3.3333e-01, 3.3333e-01],\n",
      "         [4.4444e-01, 4.4444e-01, 4.4444e-01, 4.4444e-01],\n",
      "         [5.5556e-01, 5.5556e-01, 5.5556e-01, 5.5556e-01],\n",
      "         [6.6667e-01, 6.6667e-01, 6.6667e-01, 6.6667e-01],\n",
      "         [7.7778e-01, 7.7778e-01, 7.7778e-01, 7.7778e-01],\n",
      "         [8.8889e-01, 8.8889e-01, 8.8889e-01, 8.8889e-01],\n",
      "         [1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "         [6.0139e+01, 7.5693e+01, 2.3894e+03, 5.1235e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.1111e-01, 1.1111e-01, 1.1111e-01, 1.1111e-01],\n",
      "         [2.2222e-01, 2.2222e-01, 2.2222e-01, 2.2222e-01],\n",
      "         [3.3333e-01, 3.3333e-01, 3.3333e-01, 3.3333e-01],\n",
      "         [4.4444e-01, 4.4444e-01, 4.4444e-01, 4.4444e-01],\n",
      "         [5.5556e-01, 5.5556e-01, 5.5556e-01, 5.5556e-01],\n",
      "         [6.6667e-01, 6.6667e-01, 6.6667e-01, 6.6667e-01],\n",
      "         [7.7778e-01, 7.7778e-01, 7.7778e-01, 7.7778e-01],\n",
      "         [8.8889e-01, 8.8889e-01, 8.8889e-01, 8.8889e-01],\n",
      "         [1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "         [6.0139e+01, 7.5693e+01, 2.3894e+03, 5.1235e+00]]],\n",
      "       dtype=torch.float64)]\n",
      "torch.Size([2, 11, 4])\n"
     ]
    }
   ],
   "source": [
    "model = model.condition_on_observations(new_X, new_Y)\n",
    "print(model.train_targets)\n",
    "print(model.train_targets.shape)\n",
    "print(model.train_inputs)\n",
    "print(model.train_inputs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SingleTaskGP(\n",
      "  (likelihood): GaussianLikelihood(\n",
      "    (noise_covar): HomoskedasticNoise(\n",
      "      (noise_prior): GammaPrior()\n",
      "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
      "    )\n",
      "  )\n",
      "  (mean_module): ConstantMean()\n",
      "  (covar_module): ScaleKernel(\n",
      "    (base_kernel): MaternKernel(\n",
      "      (lengthscale_prior): GammaPrior()\n",
      "      (raw_lengthscale_constraint): Positive()\n",
      "    )\n",
      "    (outputscale_prior): GammaPrior()\n",
      "    (raw_outputscale_constraint): Positive()\n",
      "  )\n",
      "  (outcome_transform): Standardize()\n",
      "  (input_transform): Normalize()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0501, 0.1468]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "transformed_Y , _= model.outcome_transform(new_Y)\n",
    "print(transformed_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_X = model.input_transform(new_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7073, 0.0401, 0.1629, 0.1882]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(transformed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_Y , _= model.outcome_transform(new_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2255, -0.1479]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(transformed_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1111, 0.1111, 0.1111, 0.1111],\n",
      "         [0.2222, 0.2222, 0.2222, 0.2222],\n",
      "         [0.3333, 0.3333, 0.3333, 0.3333],\n",
      "         [0.4444, 0.4444, 0.4444, 0.4444],\n",
      "         [0.5556, 0.5556, 0.5556, 0.5556],\n",
      "         [0.6667, 0.6667, 0.6667, 0.6667],\n",
      "         [0.7778, 0.7778, 0.7778, 0.7778],\n",
      "         [0.8889, 0.8889, 0.8889, 0.8889],\n",
      "         [1.0000, 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1111, 0.1111, 0.1111, 0.1111],\n",
      "         [0.2222, 0.2222, 0.2222, 0.2222],\n",
      "         [0.3333, 0.3333, 0.3333, 0.3333],\n",
      "         [0.4444, 0.4444, 0.4444, 0.4444],\n",
      "         [0.5556, 0.5556, 0.5556, 0.5556],\n",
      "         [0.6667, 0.6667, 0.6667, 0.6667],\n",
      "         [0.7778, 0.7778, 0.7778, 0.7778],\n",
      "         [0.8889, 0.8889, 0.8889, 0.8889],\n",
      "         [1.0000, 1.0000, 1.0000, 1.0000]]], dtype=torch.float64),)\n"
     ]
    }
   ],
   "source": [
    "print(model.train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2209,  1.0517,  0.8486,  0.6090,  0.3305,  0.0106, -0.3532, -0.7633,\n",
      "         -1.2223, -1.7326,  1.9924],\n",
      "        [-2.6406, -0.6209, -0.0264,  0.2358,  0.3751,  0.4578,  0.5108,  0.5466,\n",
      "          0.5718,  0.5901,  0.6557]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(model.train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.1111e-01, 1.1111e-01, 1.1111e-01, 1.1111e-01],\n",
      "         [2.2222e-01, 2.2222e-01, 2.2222e-01, 2.2222e-01],\n",
      "         [3.3333e-01, 3.3333e-01, 3.3333e-01, 3.3333e-01],\n",
      "         [4.4444e-01, 4.4444e-01, 4.4444e-01, 4.4444e-01],\n",
      "         [5.5556e-01, 5.5556e-01, 5.5556e-01, 5.5556e-01],\n",
      "         [6.6667e-01, 6.6667e-01, 6.6667e-01, 6.6667e-01],\n",
      "         [7.7778e-01, 7.7778e-01, 7.7778e-01, 7.7778e-01],\n",
      "         [8.8889e-01, 8.8889e-01, 8.8889e-01, 8.8889e-01],\n",
      "         [1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "         [5.5000e+01, 7.8191e+01, 1.8917e+03, 1.3045e+01]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.1111e-01, 1.1111e-01, 1.1111e-01, 1.1111e-01],\n",
      "         [2.2222e-01, 2.2222e-01, 2.2222e-01, 2.2222e-01],\n",
      "         [3.3333e-01, 3.3333e-01, 3.3333e-01, 3.3333e-01],\n",
      "         [4.4444e-01, 4.4444e-01, 4.4444e-01, 4.4444e-01],\n",
      "         [5.5556e-01, 5.5556e-01, 5.5556e-01, 5.5556e-01],\n",
      "         [6.6667e-01, 6.6667e-01, 6.6667e-01, 6.6667e-01],\n",
      "         [7.7778e-01, 7.7778e-01, 7.7778e-01, 7.7778e-01],\n",
      "         [8.8889e-01, 8.8889e-01, 8.8889e-01, 8.8889e-01],\n",
      "         [1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "         [5.5000e+01, 7.8191e+01, 1.8917e+03, 1.3045e+01]]],\n",
      "       dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "print(model.train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000],\n",
      "        [0.3333],\n",
      "        [0.6667],\n",
      "        [1.0000]], dtype=torch.float64)\n",
      "tensor([[ 0.0000e+00],\n",
      "        [ 8.6603e-01],\n",
      "        [-8.6603e-01],\n",
      "        [-2.4493e-16]], dtype=torch.float64)\n",
      "tensor([ 1.2585e-16,  1.2247e+00, -1.2247e+00, -2.2053e-16],\n",
      "       dtype=torch.float64)\n",
      "torch.Size([4])\n",
      "(tensor([[0.0000],\n",
      "        [0.3333],\n",
      "        [0.6667],\n",
      "        [1.0000]], dtype=torch.float64),)\n",
      "torch.Size([4, 1])\n",
      "tensor([[0.2881]], dtype=torch.float64)\n",
      "tensor([[0.9715]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import botorch\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from botorch.models.transforms.input import Normalize\n",
    "from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "def generate_initial_data(n_points):\n",
    "    train_X = torch.linspace(0, 1, n_points, dtype=torch.float64).unsqueeze(-1)\n",
    "    train_Y = torch.sin(train_X * (2 * torch.pi))\n",
    "    return train_X, train_Y\n",
    "\n",
    "train_X, train_Y = generate_initial_data(n_points=4)\n",
    "\n",
    "parameter_bounds = torch.tensor([[0.], [1.]], dtype=torch.float64)\n",
    "\n",
    "model = SingleTaskGP(train_X=train_X, train_Y=train_Y, outcome_transform=Standardize(m=1), input_transform=Normalize(d=1))\n",
    "\n",
    "print(train_X)\n",
    "print(train_Y)\n",
    "\n",
    "mll = ExactMarginalLogLikelihood(likelihood=model.likelihood, model=model) \n",
    "fit_gpytorch_mll(mll)\n",
    "\n",
    "print(model.train_targets)\n",
    "print(model.train_targets.shape)\n",
    "print(model.train_inputs)\n",
    "print(model.train_inputs[0].shape)\n",
    "\n",
    "acqf = botorch.acquisition.UpperConfidenceBound(model, beta=0.1)\n",
    "\n",
    "# Optimize the acquisition function\n",
    "candidate, acq_value = optimize_acqf(\n",
    "    acq_function=acqf,\n",
    "    bounds=parameter_bounds,\n",
    "    q=1,\n",
    "    num_restarts=5,\n",
    "    raw_samples=20,\n",
    ")\n",
    "\n",
    "next_X = candidate\n",
    "\n",
    "next_Y = torch.sin(next_X * (2 * torch.pi))\n",
    "\n",
    "print(next_X)\n",
    "print(next_Y)\n",
    "\n",
    "# train_X = torch.cat([train_X, next_X])\n",
    "# train_Y = torch.cat([train_Y, next_Y])\n",
    "\n",
    "# print(train_X)\n",
    "# print(train_Y)\n",
    "\n",
    "# print(train_X.shape)\n",
    "# print(train_Y.shape)\n",
    "\n",
    "# model = SingleTaskGP(train_X=train_X, train_Y=train_Y, outcome_transform=Standardize(m=1), input_transform=Normalize(d=1))\n",
    "\n",
    "# mll = ExactMarginalLogLikelihood(likelihood=model.likelihood, model=model) \n",
    "# fit_gpytorch_mll(mll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\models\\gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "c:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\models\\utils\\assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ..\\aten\\src\\ATen\\native\\ReduceOps.cpp:1760.)\n",
      "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import botorch\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from botorch.models.transforms.input import Normalize\n",
    "from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "\n",
    "model = SingleTaskGP(train_X=torch.Tensor([]).reshape(0,2), train_Y=torch.Tensor([]).reshape(0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training targets: tensor([ 3.1402e-17,  1.4142e+00,  2.0459e-16, -1.4142e+00, -3.1498e-16],\n",
      "       dtype=torch.float64)\n",
      "Training targets shape: torch.Size([5])\n",
      "Training inputs: (tensor([[0.0000],\n",
      "        [0.2500],\n",
      "        [0.5000],\n",
      "        [0.7500],\n",
      "        [1.0000]], dtype=torch.float64),)\n",
      "Training inputs shape: torch.Size([5, 1])\n",
      "Next evaluation point (X): tensor([[1.5639]], dtype=torch.float64)\n",
      "Next evaluation point (Y): tensor([[0.9978]], dtype=torch.float64)\n",
      "Transformed next X: tensor([[0.2607]], dtype=torch.float64)\n",
      "Transformed next Y: (tensor([[1.4110]], dtype=torch.float64), None)\n",
      "Updated training targets: tensor([ 3.1402e-17,  1.4142e+00,  2.0459e-16, -1.4142e+00, -3.1498e-16,\n",
      "         1.4110e+00], dtype=torch.float64)\n",
      "Updated training targets shape: torch.Size([6])\n",
      "Updated training inputs: [tensor([[0.0000],\n",
      "        [0.2500],\n",
      "        [0.5000],\n",
      "        [0.7500],\n",
      "        [1.0000],\n",
      "        [1.5639]], dtype=torch.float64)]\n",
      "Updated training inputs shape: torch.Size([6, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (6) must match the size of tensor b (5) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[151], line 57\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpdated training inputs shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mtrain_inputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     56\u001b[0m mll \u001b[38;5;241m=\u001b[39m ExactMarginalLogLikelihood(likelihood\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mlikelihood, model\u001b[38;5;241m=\u001b[39mmodel) \n\u001b[1;32m---> 57\u001b[0m \u001b[43mfit_gpytorch_mll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmll\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\fit.py:105\u001b[0m, in \u001b[0;36mfit_gpytorch_mll\u001b[1;34m(mll, closure, optimizer, closure_kwargs, optimizer_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# defer to per-method defaults\u001b[39;00m\n\u001b[0;32m    103\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m optimizer\n\u001b[1;32m--> 105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m FitGPyTorchMLL(\n\u001b[0;32m    106\u001b[0m     mll,\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28mtype\u001b[39m(mll\u001b[38;5;241m.\u001b[39mlikelihood),\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28mtype\u001b[39m(mll\u001b[38;5;241m.\u001b[39mmodel),\n\u001b[0;32m    109\u001b[0m     closure\u001b[38;5;241m=\u001b[39mclosure,\n\u001b[0;32m    110\u001b[0m     closure_kwargs\u001b[38;5;241m=\u001b[39mclosure_kwargs,\n\u001b[0;32m    111\u001b[0m     optimizer_kwargs\u001b[38;5;241m=\u001b[39moptimizer_kwargs,\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    113\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\utils\\dispatcher.py:93\u001b[0m, in \u001b[0;36mDispatcher.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(types\u001b[38;5;241m=\u001b[39mtypes)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MDNotImplementedError:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;66;03m# Traverses registered methods in order, yields whenever a match is found\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     funcs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_iter(\u001b[38;5;241m*\u001b[39mtypes)\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\fit.py:252\u001b[0m, in \u001b[0;36m_fit_fallback\u001b[1;34m(mll, _, __, closure, optimizer, closure_kwargs, optimizer_kwargs, max_attempts, warning_handler, caught_exception_types, **ignore)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m catch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m warning_list, debug(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    251\u001b[0m     simplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malways\u001b[39m\u001b[38;5;124m\"\u001b[39m, category\u001b[38;5;241m=\u001b[39mOptimizationWarning)\n\u001b[1;32m--> 252\u001b[0m     optimizer(mll, closure\u001b[38;5;241m=\u001b[39mclosure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptimizer_kwargs)\n\u001b[0;32m    254\u001b[0m \u001b[38;5;66;03m# Resolved warnings and determine whether or not to retry\u001b[39;00m\n\u001b[0;32m    255\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\optim\\fit.py:92\u001b[0m, in \u001b[0;36mfit_gpytorch_mll_scipy\u001b[1;34m(mll, parameters, bounds, closure, closure_kwargs, method, options, callback, timeout_sec)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m     closure \u001b[38;5;241m=\u001b[39m partial(closure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclosure_kwargs)\n\u001b[1;32m---> 92\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mscipy_minimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_sec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_sec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m!=\u001b[39m OptimizationStatus\u001b[38;5;241m.\u001b[39mSUCCESS:\n\u001b[0;32m    102\u001b[0m     warn(\n\u001b[0;32m    103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`scipy_minimize` terminated with status \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, displaying\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m original message from `scipy.optimize.minimize`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    105\u001b[0m         OptimizationWarning,\n\u001b[0;32m    106\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\optim\\core.py:109\u001b[0m, in \u001b[0;36mscipy_minimize\u001b[1;34m(closure, parameters, bounds, callback, x0, method, options, timeout_sec)\u001b[0m\n\u001b[0;32m    101\u001b[0m         result \u001b[38;5;241m=\u001b[39m OptimizationResult(\n\u001b[0;32m    102\u001b[0m             step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m(call_counter),\n\u001b[0;32m    103\u001b[0m             fval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(wrapped_closure(x)[\u001b[38;5;241m0\u001b[39m]),\n\u001b[0;32m    104\u001b[0m             status\u001b[38;5;241m=\u001b[39mOptimizationStatus\u001b[38;5;241m.\u001b[39mRUNNING,\n\u001b[0;32m    105\u001b[0m             runtime\u001b[38;5;241m=\u001b[39mmonotonic() \u001b[38;5;241m-\u001b[39m start_time,\n\u001b[0;32m    106\u001b[0m         )\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m callback(parameters, result)  \u001b[38;5;66;03m# pyre-ignore [29]\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m raw \u001b[38;5;241m=\u001b[39m \u001b[43mminimize_with_timeout\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrapped_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrapped_closure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp_float64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds_np\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrapped_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_sec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_sec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m# Post-processing and outcome handling\u001b[39;00m\n\u001b[0;32m    121\u001b[0m wrapped_closure\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m asarray(raw\u001b[38;5;241m.\u001b[39mx)  \u001b[38;5;66;03m# set parameter state to optimal values\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\optim\\utils\\timeout.py:80\u001b[0m, in \u001b[0;36mminimize_with_timeout\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options, timeout_sec)\u001b[0m\n\u001b[0;32m     77\u001b[0m     wrapped_callback \u001b[38;5;241m=\u001b[39m callback\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhessp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhessp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrapped_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OptimizationTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     95\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimization timed out after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mruntime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\scipy\\optimize\\_minimize.py:710\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    707\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    708\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 710\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m    711\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    713\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    714\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:307\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    305\u001b[0m         iprint \u001b[38;5;241m=\u001b[39m disp\n\u001b[1;32m--> 307\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_scalar_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_bounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    311\u001b[0m func_and_grad \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mfun_and_grad\n\u001b[0;32m    313\u001b[0m fortran_int \u001b[38;5;241m=\u001b[39m _lbfgsb\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mintvar\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\scipy\\optimize\\_optimize.py:383\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[1;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[0;32m    379\u001b[0m     bounds \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39minf)\n\u001b[0;32m    381\u001b[0m \u001b[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[1;32m--> 383\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43mScalarFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sf\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:158\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[1;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl \u001b[38;5;241m=\u001b[39m update_fun\n\u001b[1;32m--> 158\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# Gradient evaluation\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(grad):\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 251\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\scipy\\optimize\\_optimize.py:77\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\scipy\\optimize\\_optimize.py:71\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 71\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\optim\\closures\\core.py:160\u001b[0m, in \u001b[0;36mNdarrayOptimizationClosure.__call__\u001b[1;34m(self, state, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m         index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m size\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 160\u001b[0m     value, grads \u001b[38;5;241m=\u001b[39m \u001b[43m_handle_numerical_errors\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp_float64\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m value, grads\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\optim\\utils\\common.py:52\u001b[0m, in \u001b[0;36m_handle_numerical_errors\u001b[1;34m(error, x, dtype)\u001b[0m\n\u001b[0;32m     50\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m dtype\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mfull((), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m_dtype), np\u001b[38;5;241m.\u001b[39mfull_like(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m_dtype)\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\optim\\closures\\core.py:150\u001b[0m, in \u001b[0;36mNdarrayOptimizationClosure.__call__\u001b[1;34m(self, state, **kwargs)\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m state\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m     value_tensor, grad_tensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclosure(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_array(value_tensor)\n\u001b[0;32m    152\u001b[0m     grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_gradient_ndarray(fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_value)\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\optim\\closures\\core.py:64\u001b[0m, in \u001b[0;36mForwardBackwardClosure.__call__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Tensor, Tuple[Optional[Tensor], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]:\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_manager():\n\u001b[1;32m---> 64\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m         value \u001b[38;5;241m=\u001b[39m values \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreducer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreducer(values)\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackward(value)\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\botorch\\optim\\closures\\model_closures.py:176\u001b[0m, in \u001b[0;36m_get_loss_closure_exact_internal.<locals>.closure\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    175\u001b[0m     model_output \u001b[38;5;241m=\u001b[39m mll\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39mmll\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain_inputs)\n\u001b[1;32m--> 176\u001b[0m     log_likelihood \u001b[38;5;241m=\u001b[39m mll(\n\u001b[0;32m    177\u001b[0m         model_output, mll\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain_targets, \u001b[38;5;241m*\u001b[39mmll\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    178\u001b[0m     )\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mlog_likelihood\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\gpytorch\\module.py:31\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[1;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\gpytorch\\mlls\\exact_marginal_log_likelihood.py:64\u001b[0m, in \u001b[0;36mExactMarginalLogLikelihood.forward\u001b[1;34m(self, function_dist, target, *params)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Get the log prob of the marginal distribution\u001b[39;00m\n\u001b[0;32m     63\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlikelihood(function_dist, \u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m---> 64\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_other_terms(res, params)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Scale by the amount of data we have\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\gpytorch\\distributions\\multivariate_normal.py:171\u001b[0m, in \u001b[0;36mMultivariateNormal.log_prob\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03mSee :py:meth:`torch.distributions.Distribution.log_prob\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;124;03m<torch.distributions.distribution.Distribution.log_prob>`.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m settings\u001b[38;5;241m.\u001b[39mfast_computations\u001b[38;5;241m.\u001b[39mlog_prob\u001b[38;5;241m.\u001b[39moff():\n\u001b[1;32m--> 171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_args:\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_sample(value)\n",
      "File \u001b[1;32mc:\\Users\\Moritz\\anaconda3\\envs\\TL_GP\\lib\\site-packages\\torch\\distributions\\multivariate_normal.py:247\u001b[0m, in \u001b[0;36mMultivariateNormal.log_prob\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_args:\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_sample(value)\n\u001b[1;32m--> 247\u001b[0m diff \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\n\u001b[0;32m    248\u001b[0m M \u001b[38;5;241m=\u001b[39m _batch_mahalanobis(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unbroadcasted_scale_tril, diff)\n\u001b[0;32m    249\u001b[0m half_log_det \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unbroadcasted_scale_tril\u001b[38;5;241m.\u001b[39mdiagonal(dim1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, dim2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlog()\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    251\u001b[0m )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (6) must match the size of tensor b (5) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import botorch\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from botorch.models.transforms.input import Normalize\n",
    "from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "def generate_initial_data(n_points):\n",
    "    train_X = torch.linspace(0, 6, n_points, dtype=torch.float64).unsqueeze(-1)\n",
    "    train_Y = torch.sin(train_X * (2 * torch.pi) / 6)\n",
    "    return train_X, train_Y\n",
    "\n",
    "train_X, train_Y = generate_initial_data(n_points=5)\n",
    "\n",
    "parameter_bounds = torch.tensor([[0.], [6.]], dtype=torch.float64)\n",
    "\n",
    "model = SingleTaskGP(train_X=train_X, train_Y=train_Y, input_transform=Normalize(d=1, bounds=parameter_bounds), outcome_transform=Standardize(m=1))\n",
    "\n",
    "mll = ExactMarginalLogLikelihood(likelihood=model.likelihood, model=model) \n",
    "fit_gpytorch_mll(mll)\n",
    "\n",
    "print(f\"Training targets: {model.train_targets}\")\n",
    "print(f\"Training targets shape: {model.train_targets.shape}\")\n",
    "print(f\"Training inputs: {model.train_inputs}\")\n",
    "print(f\"Training inputs shape: {model.train_inputs[0].shape}\")\n",
    "\n",
    "acqf = botorch.acquisition.UpperConfidenceBound(model, beta=0.1)\n",
    "\n",
    "# Optimize the acquisition function\n",
    "candidate, acq_value = optimize_acqf(\n",
    "    acq_function=acqf,\n",
    "    bounds=parameter_bounds,\n",
    "    q=1,\n",
    "    num_restarts=5,\n",
    "    raw_samples=20,\n",
    ")\n",
    "\n",
    "next_X = candidate\n",
    "next_Y = torch.sin(next_X * (2 * torch.pi) / 6)\n",
    "\n",
    "print(f\"Next evaluation point (X): {next_X}\")\n",
    "print(f\"Next evaluation point (Y): {next_Y}\")\n",
    "\n",
    "print(f\"Transformed next X: {model.input_transform(next_X)}\")\n",
    "print(f\"Transformed next Y: {model.outcome_transform(next_Y)}\")\n",
    "\n",
    "model = model.condition_on_observations(next_X, next_Y)\n",
    "\n",
    "print(f\"Updated training targets: {model.train_targets}\")\n",
    "print(f\"Updated training targets shape: {model.train_targets.shape}\")\n",
    "print(f\"Updated training inputs: {model.train_inputs}\")\n",
    "print(f\"Updated training inputs shape: {model.train_inputs[0].shape}\")\n",
    "\n",
    "mll = ExactMarginalLogLikelihood(likelihood=model.likelihood, model=model) \n",
    "fit_gpytorch_mll(mll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000],\n",
      "        [1.5000],\n",
      "        [3.0000],\n",
      "        [4.5000],\n",
      "        [6.0000]], dtype=torch.float64)\n",
      "tensor([[ 0.0000e+00],\n",
      "        [ 1.0000e+00],\n",
      "        [ 1.2246e-16],\n",
      "        [-1.0000e+00],\n",
      "        [-2.4493e-16]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "def generate_initial_data(n_points):\n",
    "    train_X = torch.linspace(0, 6, n_points, dtype=torch.float64).unsqueeze(-1)\n",
    "    train_Y = torch.sin(train_X * (2 * torch.pi) / 6)\n",
    "    return train_X, train_Y\n",
    "\n",
    "train_X, train_Y = generate_initial_data(n_points=5)\n",
    "\n",
    "print(train_X)\n",
    "print(train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_optimization(train_X, train_Y, model, bounds, num_iterations: int = 10):\n",
    "    acq_func_values = []\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        start_time = time.time()  # Start timing\n",
    "\n",
    "        new_X, acq_func_value = perform_optimization_step(model, train_X, train_Y, bounds)\n",
    "        acq_func_values.append(acq_func_value)\n",
    "        new_Y = objective_functions(new_X)\n",
    "        train_X = torch.cat([train_X, new_X])\n",
    "        train_Y = torch.cat([train_Y, new_Y])\n",
    "        print(f\"Iteration {i}: {new_X} - {new_Y}\")\n",
    "\n",
    "        # Update the model\n",
    "        model = SingleTaskGP(\n",
    "            train_X=train_X, \n",
    "            train_Y=train_Y, \n",
    "            input_transform=Normalize(d=4, bounds=bounds), \n",
    "            outcome_transform=Standardize(m=2)\n",
    "        )\n",
    "        mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "        fit_gpytorch_mll(mll)\n",
    "\n",
    "        end_time = time.time()  # End timing\n",
    "        iteration_time = end_time - start_time\n",
    "        print(f\"Iteration {i} took {iteration_time:.4f} seconds\")\n",
    "\n",
    "    return train_X, train_Y, acq_func_values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition function value:17.01079662445396\n",
      "Iteration 0: tensor([[  55.6073,   75.4146, 2140.0391,   10.9895]], dtype=torch.float64) - tensor([[-1.2703, -4.2171]], dtype=torch.float64)\n",
      "Iteration 0 took 5.3739 seconds\n",
      "Acquisition function value:16.218479468062444\n",
      "Iteration 1: tensor([[  55.0000,   83.8656, 1383.4189,   14.3237]], dtype=torch.float64) - tensor([[-2.6170, -4.6907]], dtype=torch.float64)\n",
      "Iteration 1 took 11.9624 seconds\n",
      "Acquisition function value:22.368296859894258\n",
      "Iteration 2: tensor([[  61.3451,   75.2688, 2391.8647,    2.7690]], dtype=torch.float64) - tensor([[ -0.1649, -14.4212]], dtype=torch.float64)\n",
      "Iteration 2 took 10.4564 seconds\n",
      "Acquisition function value:15.09487646075326\n",
      "Iteration 3: tensor([[  55.0000,   89.7666, 2455.9836,    2.5163]], dtype=torch.float64) - tensor([[ -0.3740, -14.3588]], dtype=torch.float64)\n",
      "Iteration 3 took 9.5429 seconds\n",
      "Acquisition function value:11.479866009110996\n",
      "Iteration 4: tensor([[  62.6055,   82.5424, 2679.1055,   10.7630]], dtype=torch.float64) - tensor([[-1.3844, -3.1088]], dtype=torch.float64)\n",
      "Iteration 4 took 10.5255 seconds\n",
      "Acquisition function value:10.093780149845626\n",
      "Iteration 5: tensor([[7.1191e+01, 8.8695e+01, 2.4824e+03, 2.0000e+00]], dtype=torch.float64) - tensor([[ -0.1371, -16.4289]], dtype=torch.float64)\n",
      "Iteration 5 took 8.0219 seconds\n",
      "Acquisition function value:11.4077158696446\n",
      "Iteration 6: tensor([[  77.5513,   75.0000, 1619.3040,    2.0000]], dtype=torch.float64) - tensor([[ 1.9071e-02, -2.6499e+01]], dtype=torch.float64)\n",
      "Iteration 6 took 7.4913 seconds\n",
      "Acquisition function value:11.482006278216902\n",
      "Iteration 7: tensor([[  67.9749,   81.1515, 1963.7945,    2.0000]], dtype=torch.float64) - tensor([[ -0.0963, -22.2967]], dtype=torch.float64)\n",
      "Iteration 7 took 10.2480 seconds\n",
      "Acquisition function value:9.999110920050246\n",
      "Iteration 8: tensor([[  55.0000,   75.0000, 3000.0000,    7.0132]], dtype=torch.float64) - tensor([[-0.7661, -4.7496]], dtype=torch.float64)\n",
      "Iteration 8 took 14.4886 seconds\n",
      "Acquisition function value:7.894945402065181\n",
      "Iteration 9: tensor([[  74.0558,   75.0000, 3000.0000,    7.0779]], dtype=torch.float64) - tensor([[-0.0419, -4.1369]], dtype=torch.float64)\n",
      "Iteration 9 took 21.2905 seconds\n",
      "Acquisition function value:14.322797383105264\n",
      "Iteration 10: tensor([[  80.0000,   75.0000, 3000.0000,    3.5448]], dtype=torch.float64) - tensor([[ 0.0966, -7.9406]], dtype=torch.float64)\n",
      "Iteration 10 took 17.1864 seconds\n",
      "Acquisition function value:9.516598005496656\n",
      "Iteration 11: tensor([[  80.0000,   75.0000, 2293.6335,   10.5278]], dtype=torch.float64) - tensor([[ 0.3618, -3.4971]], dtype=torch.float64)\n",
      "Iteration 11 took 12.0189 seconds\n",
      "Acquisition function value:11.62663538127914\n",
      "Iteration 12: tensor([[  80.0000,   75.0000, 2188.8432,    7.6150]], dtype=torch.float64) - tensor([[ 0.2512, -5.0662]], dtype=torch.float64)\n",
      "Iteration 12 took 11.1151 seconds\n",
      "Acquisition function value:11.45943555400633\n",
      "Iteration 13: tensor([[  80.0000,   75.0000, 2015.3698,   15.1475]], dtype=torch.float64) - tensor([[ 0.5373, -2.7661]], dtype=torch.float64)\n",
      "Iteration 13 took 18.3547 seconds\n",
      "Acquisition function value:13.54507639042275\n",
      "Iteration 14: tensor([[  80.0000,   75.0000, 1071.0205,   13.3522]], dtype=torch.float64) - tensor([[ 0.4691, -5.9050]], dtype=torch.float64)\n",
      "Iteration 14 took 11.5052 seconds\n",
      "Acquisition function value:10.877182003674863\n",
      "Iteration 15: tensor([[  80.0000,   75.0000, 1478.8168,   18.4929]], dtype=torch.float64) - tensor([[ 0.6643, -3.0878]], dtype=torch.float64)\n",
      "Iteration 15 took 12.0519 seconds\n",
      "Acquisition function value:10.520564514556087\n",
      "Iteration 16: tensor([[  80.0000,   75.0000, 2754.7659,   18.8780]], dtype=torch.float64) - tensor([[ 0.6789, -1.6238]], dtype=torch.float64)\n",
      "Iteration 16 took 14.2678 seconds\n",
      "Acquisition function value:10.276295431173711\n",
      "Iteration 17: tensor([[  80.0000,   75.0000, 2175.1731,   20.0000]], dtype=torch.float64) - tensor([[ 0.7215, -1.9411]], dtype=torch.float64)\n",
      "Iteration 17 took 26.4303 seconds\n",
      "Acquisition function value:8.860388198815233\n",
      "Iteration 18: tensor([[  80.0000,   84.8863, 2307.1208,   17.9910]], dtype=torch.float64) - tensor([[-0.6708, -1.9125]], dtype=torch.float64)\n",
      "Iteration 18 took 17.8199 seconds\n",
      "Acquisition function value:8.006327418931594\n",
      "Iteration 19: tensor([[  80.0000,   75.0000, 3000.0000,   14.6790]], dtype=torch.float64) - tensor([[ 0.5195, -1.9176]], dtype=torch.float64)\n",
      "Iteration 19 took 10.0648 seconds\n"
     ]
    }
   ],
   "source": [
    "new_train_X, new_train_Y, acq_func_values = perform_optimization(train_X, train_Y, model, parameter_bounds, num_iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acquisition_function_values(acq_func_values):\n",
    "    \"\"\"\n",
    "    Plots the acquisition function values over iterations.\n",
    "\n",
    "    Parameters:\n",
    "    acq_func_values (list of float): The acquisition function values collected over iterations.\n",
    "    \"\"\"\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(acq_func_values, marker='o', linestyle='-', color='blue')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Acquisition Function Value')\n",
    "    plt.title('Acquisition Function Values Over Iterations')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 2])\n"
     ]
    }
   ],
   "source": [
    "print(new_train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train_Y(new_train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_acquisition_function_values(acq_func_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[  80.,  110., 1000.,   20.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(type(new_train_X))\n",
    "print(new_train_X)\n",
    "print(type(new_train_Y))\n",
    "print(new_train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "n_gen  |  n_eval  | n_nds  |      eps      |   indicator  \n",
      "==========================================================\n",
      "     1 |     1000 |      5 |             - |             -\n",
      "     2 |     2000 |      7 |  0.0308596354 |         ideal\n",
      "     3 |     3000 |     10 |  0.0763449588 |         nadir\n",
      "     4 |     4000 |     16 |  0.1974336952 |         ideal\n",
      "     5 |     5000 |     20 |  0.0062085685 |         ideal\n",
      "     6 |     6000 |     29 |  0.0230250122 |         ideal\n",
      "     7 |     7000 |     22 |  0.0136230191 |         ideal\n",
      "     8 |     8000 |     36 |  0.0191493722 |             f\n",
      "     9 |     9000 |     45 |  0.0145585764 |         ideal\n",
      "    10 |    10000 |     62 |  0.0129126789 |         ideal\n",
      "    11 |    11000 |     77 |  0.0079541337 |         nadir\n",
      "    12 |    12000 |     87 |  0.4522141391 |         nadir\n",
      "    13 |    13000 |    120 |  0.0311591565 |         ideal\n",
      "    14 |    14000 |    158 |  0.0035701063 |             f\n",
      "    15 |    15000 |    197 |  0.0031178981 |             f\n",
      "    16 |    16000 |    271 |  0.0023005832 |             f\n",
      "    17 |    17000 |    308 |  0.1776630825 |         nadir\n",
      "    18 |    18000 |    408 |  0.0012468792 |             f\n",
      "    19 |    19000 |    474 |  0.0019370567 |             f\n",
      "    20 |    20000 |    570 |  0.0024688923 |             f\n",
      "    21 |    21000 |    709 |  0.0029165008 |             f\n",
      "    22 |    22000 |    843 |  0.0438433753 |         nadir\n",
      "    23 |    23000 |   1000 |  0.0003075758 |             f\n",
      "    24 |    24000 |   1000 |  0.0006079525 |             f\n",
      "    25 |    25000 |   1000 |  0.0007867357 |             f\n",
      "    26 |    26000 |   1000 |  0.0009061993 |             f\n",
      "    27 |    27000 |   1000 |  0.0009856314 |             f\n",
      "    28 |    28000 |   1000 |  0.0010608806 |             f\n",
      "    29 |    29000 |   1000 |  0.0011117452 |             f\n",
      "    30 |    30000 |   1000 |  0.0011422835 |             f\n",
      "    31 |    31000 |   1000 |  0.0011648121 |             f\n",
      "    32 |    32000 |   1000 |  0.0011834997 |             f\n",
      "    33 |    33000 |   1000 |  0.0012120609 |             f\n",
      "    34 |    34000 |   1000 |  0.0012333511 |             f\n",
      "    35 |    35000 |   1000 |  0.0504857599 |         nadir\n",
      "    36 |    36000 |   1000 |  0.0001143850 |             f\n",
      "    37 |    37000 |   1000 |  0.0002015896 |             f\n",
      "    38 |    38000 |   1000 |  0.0002639211 |             f\n",
      "    39 |    39000 |   1000 |  0.0003132333 |             f\n",
      "    40 |    40000 |   1000 |  0.0003479390 |             f\n",
      "    41 |    41000 |   1000 |  0.0127805598 |         nadir\n",
      "    42 |    42000 |   1000 |  0.0001220920 |             f\n",
      "    43 |    43000 |   1000 |  0.0001941966 |             f\n",
      "    44 |    44000 |   1000 |  0.0002689109 |             f\n",
      "    45 |    45000 |   1000 |  0.0003210298 |             f\n",
      "    46 |    46000 |   1000 |  0.0039892359 |         nadir\n",
      "    47 |    47000 |   1000 |  0.0001293891 |             f\n",
      "    48 |    48000 |   1000 |  0.0002228724 |             f\n",
      "    49 |    49000 |   1000 |  0.0002697885 |             f\n",
      "    50 |    50000 |   1000 |  0.0003204262 |             f\n",
      "    51 |    51000 |   1000 |  0.0003369116 |             f\n",
      "    52 |    52000 |   1000 |  0.0003633761 |             f\n",
      "    53 |    53000 |   1000 |  0.0003827285 |             f\n",
      "    54 |    54000 |   1000 |  0.0003960754 |             f\n",
      "    55 |    55000 |   1000 |  0.0003980689 |             f\n",
      "    56 |    56000 |   1000 |  0.0090348251 |         nadir\n",
      "    57 |    57000 |   1000 |  0.0001212811 |             f\n",
      "    58 |    58000 |   1000 |  0.0002017517 |             f\n",
      "    59 |    59000 |   1000 |  0.0002689377 |             f\n",
      "    60 |    60000 |   1000 |  0.0003075464 |             f\n",
      "    61 |    61000 |   1000 |  0.0003461808 |             f\n",
      "    62 |    62000 |   1000 |  0.0003673730 |             f\n",
      "    63 |    63000 |   1000 |  0.0003906531 |             f\n",
      "    64 |    64000 |   1000 |  0.0004013844 |             f\n",
      "    65 |    65000 |   1000 |  0.0004191123 |             f\n",
      "    66 |    66000 |   1000 |  0.0004211495 |             f\n",
      "    67 |    67000 |   1000 |  0.0004283881 |             f\n",
      "    68 |    68000 |   1000 |  0.0004287319 |             f\n",
      "    69 |    69000 |   1000 |  0.0004368741 |             f\n",
      "    70 |    70000 |   1000 |  0.0004485040 |             f\n",
      "    71 |    71000 |   1000 |  0.0004380832 |             f\n",
      "    72 |    72000 |   1000 |  0.0004338864 |             f\n",
      "    73 |    73000 |   1000 |  0.0004384022 |             f\n",
      "    74 |    74000 |   1000 |  0.0004450519 |             f\n",
      "    75 |    75000 |   1000 |  0.0004460127 |             f\n",
      "    76 |    76000 |   1000 |  0.0004507254 |             f\n",
      "    77 |    77000 |   1000 |  0.0004612860 |             f\n",
      "    78 |    78000 |   1000 |  0.0004646293 |             f\n",
      "    79 |    79000 |   1000 |  0.0004661192 |             f\n",
      "    80 |    80000 |   1000 |  0.0004609276 |             f\n",
      "    81 |    81000 |   1000 |  0.0004629155 |             f\n",
      "    82 |    82000 |   1000 |  0.0004598803 |             f\n",
      "    83 |    83000 |   1000 |  0.0004536770 |             f\n",
      "    84 |    84000 |   1000 |  0.0004406411 |             f\n",
      "    85 |    85000 |   1000 |  0.0004409788 |             f\n",
      "    86 |    86000 |   1000 |  0.0004441630 |             f\n",
      "    87 |    87000 |   1000 |  0.0004481757 |             f\n",
      "    88 |    88000 |   1000 |  0.0004504222 |             f\n",
      "    89 |    89000 |   1000 |  0.0004541951 |             f\n",
      "    90 |    90000 |   1000 |  0.0004455622 |             f\n",
      "    91 |    91000 |   1000 |  0.0004431650 |             f\n",
      "    92 |    92000 |   1000 |  0.0004432669 |             f\n",
      "    93 |    93000 |   1000 |  0.0004466293 |             f\n",
      "    94 |    94000 |   1000 |  0.0004552215 |             f\n",
      "    95 |    95000 |   1000 |  0.0004571026 |             f\n",
      "    96 |    96000 |   1000 |  0.0004494791 |             f\n",
      "    97 |    97000 |   1000 |  0.0004443976 |             f\n",
      "    98 |    98000 |   1000 |  0.0004486533 |             f\n",
      "    99 |    99000 |   1000 |  0.0004632112 |             f\n",
      "   100 |   100000 |   1000 |  0.0004595951 |             f\n",
      "   101 |   101000 |   1000 |  0.0004538193 |             f\n",
      "   102 |   102000 |   1000 |  0.0004439575 |             f\n",
      "   103 |   103000 |   1000 |  0.0004374529 |             f\n",
      "   104 |   104000 |   1000 |  0.0004376028 |             f\n",
      "   105 |   105000 |   1000 |  0.0004354513 |             f\n",
      "   106 |   106000 |   1000 |  0.0004384877 |             f\n",
      "   107 |   107000 |   1000 |  0.0004359519 |             f\n",
      "   108 |   108000 |   1000 |  0.0004401668 |             f\n",
      "   109 |   109000 |   1000 |  0.0004321430 |             f\n",
      "   110 |   110000 |   1000 |  0.0004389360 |             f\n",
      "   111 |   111000 |   1000 |  0.0004369745 |             f\n",
      "   112 |   112000 |   1000 |  0.0004385271 |             f\n",
      "   113 |   113000 |   1000 |  0.0004429252 |             f\n",
      "   114 |   114000 |   1000 |  0.0004483181 |             f\n",
      "   115 |   115000 |   1000 |  0.0004496186 |             f\n",
      "   116 |   116000 |   1000 |  0.0004452345 |             f\n",
      "   117 |   117000 |   1000 |  0.0004390690 |             f\n",
      "   118 |   118000 |   1000 |  0.0004421672 |             f\n",
      "   119 |   119000 |   1000 |  0.0004370087 |             f\n",
      "   120 |   120000 |   1000 |  0.0004382736 |             f\n",
      "   121 |   121000 |   1000 |  0.0004371336 |             f\n",
      "   122 |   122000 |   1000 |  0.0004377793 |             f\n",
      "   123 |   123000 |   1000 |  0.0004483465 |             f\n",
      "   124 |   124000 |   1000 |  0.0004452734 |             f\n",
      "   125 |   125000 |   1000 |  0.0004349213 |             f\n",
      "   126 |   126000 |   1000 |  0.0004503809 |             f\n",
      "   127 |   127000 |   1000 |  0.0004484561 |             f\n",
      "   128 |   128000 |   1000 |  0.0004574126 |             f\n",
      "   129 |   129000 |   1000 |  0.0004537705 |             f\n",
      "   130 |   130000 |   1000 |  0.0004650280 |             f\n",
      "   131 |   131000 |   1000 |  0.0004573439 |             f\n",
      "   132 |   132000 |   1000 |  0.0004529619 |             f\n",
      "   133 |   133000 |   1000 |  0.0004515157 |             f\n",
      "   134 |   134000 |   1000 |  0.0004511133 |             f\n",
      "   135 |   135000 |   1000 |  0.0004583676 |             f\n",
      "   136 |   136000 |   1000 |  0.0004561833 |             f\n",
      "   137 |   137000 |   1000 |  0.0004575470 |             f\n",
      "   138 |   138000 |   1000 |  0.0004601218 |             f\n",
      "   139 |   139000 |   1000 |  0.0894554887 |         nadir\n",
      "   140 |   140000 |   1000 |  0.0000981870 |             f\n",
      "   141 |   141000 |   1000 |  0.0001749610 |             f\n",
      "   142 |   142000 |   1000 |  0.0983155749 |         nadir\n",
      "   143 |   143000 |   1000 |  0.0001046272 |             f\n",
      "   144 |   144000 |   1000 |  0.0001756410 |             f\n",
      "   145 |   145000 |   1000 |  0.0002404834 |             f\n",
      "   146 |   146000 |   1000 |  0.0002814112 |             f\n",
      "   147 |   147000 |   1000 |  0.0003217747 |             f\n",
      "   148 |   148000 |   1000 |  0.0003574369 |             f\n",
      "   149 |   149000 |   1000 |  0.0003815907 |             f\n",
      "   150 |   150000 |   1000 |  0.0004029068 |             f\n",
      "   151 |   151000 |   1000 |  0.0004123438 |             f\n",
      "   152 |   152000 |   1000 |  0.0004126489 |             f\n",
      "   153 |   153000 |   1000 |  0.0004238885 |             f\n",
      "   154 |   154000 |   1000 |  0.0004246336 |             f\n",
      "   155 |   155000 |   1000 |  0.0004280813 |             f\n",
      "   156 |   156000 |   1000 |  0.0004244160 |             f\n",
      "   157 |   157000 |   1000 |  0.0004262857 |             f\n",
      "   158 |   158000 |   1000 |  0.0004312642 |             f\n",
      "   159 |   159000 |   1000 |  0.0004211315 |             f\n",
      "   160 |   160000 |   1000 |  0.0004201152 |             f\n",
      "   161 |   161000 |   1000 |  0.0004149891 |             f\n",
      "   162 |   162000 |   1000 |  0.0004265539 |             f\n",
      "   163 |   163000 |   1000 |  0.0031053554 |         nadir\n",
      "   164 |   164000 |   1000 |  0.0001245014 |             f\n",
      "   165 |   165000 |   1000 |  0.0002065740 |             f\n",
      "   166 |   166000 |   1000 |  0.0002679559 |             f\n",
      "   167 |   167000 |   1000 |  0.0003055929 |             f\n",
      "   168 |   168000 |   1000 |  0.0003427477 |             f\n",
      "   169 |   169000 |   1000 |  0.0003780595 |             f\n",
      "   170 |   170000 |   1000 |  0.0003871189 |             f\n",
      "   171 |   171000 |   1000 |  0.0004104475 |             f\n",
      "   172 |   172000 |   1000 |  0.0004162934 |             f\n",
      "   173 |   173000 |   1000 |  0.0004315526 |             f\n",
      "   174 |   174000 |   1000 |  0.0004282886 |             f\n",
      "   175 |   175000 |   1000 |  0.0004350695 |             f\n",
      "   176 |   176000 |   1000 |  0.0004502746 |             f\n",
      "   177 |   177000 |   1000 |  0.0004610703 |             f\n",
      "   178 |   178000 |   1000 |  0.0004489933 |             f\n",
      "   179 |   179000 |   1000 |  0.0026978040 |         nadir\n",
      "   180 |   180000 |   1000 |  0.0001232499 |             f\n",
      "   181 |   181000 |   1000 |  0.0002074865 |             f\n",
      "   182 |   182000 |   1000 |  0.0664079920 |         nadir\n",
      "   183 |   183000 |   1000 |  0.0001053445 |             f\n",
      "   184 |   184000 |   1000 |  0.0001871644 |             f\n",
      "   185 |   185000 |   1000 |  0.0002514100 |             f\n",
      "   186 |   186000 |   1000 |  0.0002954219 |             f\n",
      "   187 |   187000 |   1000 |  0.0003349845 |             f\n",
      "   188 |   188000 |   1000 |  0.0003524782 |             f\n",
      "   189 |   189000 |   1000 |  0.0003684529 |             f\n",
      "   190 |   190000 |   1000 |  0.0671309286 |         nadir\n",
      "   191 |   191000 |   1000 |  0.0001020582 |             f\n",
      "   192 |   192000 |   1000 |  0.0001876006 |             f\n",
      "   193 |   193000 |   1000 |  0.0002427262 |             f\n",
      "   194 |   194000 |   1000 |  0.0002905025 |             f\n",
      "   195 |   195000 |   1000 |  0.0003265758 |             f\n",
      "   196 |   196000 |   1000 |  0.0003445824 |             f\n",
      "   197 |   197000 |   1000 |  0.0003609658 |             f\n",
      "   198 |   198000 |   1000 |  0.0003673239 |             f\n",
      "   199 |   199000 |   1000 |  0.0003839010 |             f\n",
      "   200 |   200000 |   1000 |  0.0003864585 |             f\n",
      "   201 |   201000 |   1000 |  0.0004012006 |             f\n",
      "   202 |   202000 |   1000 |  0.0004156097 |             f\n",
      "   203 |   203000 |   1000 |  0.0004235107 |             f\n",
      "   204 |   204000 |   1000 |  0.0004349435 |             f\n",
      "   205 |   205000 |   1000 |  0.0004288290 |             f\n",
      "   206 |   206000 |   1000 |  0.0004357407 |             f\n",
      "   207 |   207000 |   1000 |  0.0040606756 |         nadir\n",
      "   208 |   208000 |   1000 |  0.0001146902 |             f\n",
      "   209 |   209000 |   1000 |  0.0001870851 |             f\n",
      "   210 |   210000 |   1000 |  0.0002513164 |             f\n",
      "   211 |   211000 |   1000 |  0.0002884156 |             f\n",
      "   212 |   212000 |   1000 |  0.0003110723 |             f\n",
      "   213 |   213000 |   1000 |  0.0003463896 |             f\n",
      "   214 |   214000 |   1000 |  0.0003612723 |             f\n",
      "   215 |   215000 |   1000 |  0.0003803527 |             f\n",
      "   216 |   216000 |   1000 |  0.0003903902 |             f\n",
      "   217 |   217000 |   1000 |  0.0003964553 |             f\n",
      "   218 |   218000 |   1000 |  0.0004056477 |             f\n",
      "   219 |   219000 |   1000 |  0.0004168898 |             f\n",
      "   220 |   220000 |   1000 |  0.0004219601 |             f\n",
      "   221 |   221000 |   1000 |  0.0004233075 |             f\n",
      "   222 |   222000 |   1000 |  0.0004277071 |             f\n",
      "   223 |   223000 |   1000 |  0.0004242273 |             f\n",
      "   224 |   224000 |   1000 |  0.0004317641 |             f\n",
      "   225 |   225000 |   1000 |  0.0004255764 |             f\n",
      "   226 |   226000 |   1000 |  0.0004303506 |             f\n",
      "   227 |   227000 |   1000 |  0.0004379339 |             f\n",
      "   228 |   228000 |   1000 |  0.0004350542 |             f\n",
      "   229 |   229000 |   1000 |  0.0004496313 |             f\n",
      "   230 |   230000 |   1000 |  0.0004455196 |             f\n",
      "   231 |   231000 |   1000 |  0.0004466229 |             f\n",
      "   232 |   232000 |   1000 |  0.0004443151 |             f\n",
      "   233 |   233000 |   1000 |  0.0004438186 |             f\n",
      "   234 |   234000 |   1000 |  0.0004467217 |             f\n",
      "   235 |   235000 |   1000 |  0.0004377196 |             f\n",
      "   236 |   236000 |   1000 |  0.0004391122 |             f\n",
      "   237 |   237000 |   1000 |  0.0004405349 |             f\n",
      "   238 |   238000 |   1000 |  0.0004421911 |             f\n",
      "   239 |   239000 |   1000 |  0.0004436113 |             f\n",
      "   240 |   240000 |   1000 |  0.0004465560 |             f\n",
      "   241 |   241000 |   1000 |  0.0004432798 |             f\n",
      "   242 |   242000 |   1000 |  0.0004368870 |             f\n",
      "   243 |   243000 |   1000 |  0.0004364811 |             f\n",
      "   244 |   244000 |   1000 |  0.0004362930 |             f\n",
      "   245 |   245000 |   1000 |  0.0004323964 |             f\n",
      "   246 |   246000 |   1000 |  0.0004254908 |             f\n",
      "   247 |   247000 |   1000 |  0.0004301799 |             f\n",
      "   248 |   248000 |   1000 |  0.0004248534 |             f\n",
      "   249 |   249000 |   1000 |  0.0004347173 |             f\n",
      "   250 |   250000 |   1000 |  0.0004458983 |             f\n",
      "   251 |   251000 |   1000 |  0.0004373273 |             f\n",
      "   252 |   252000 |   1000 |  0.0004310962 |             f\n",
      "   253 |   253000 |   1000 |  0.0004394356 |             f\n",
      "   254 |   254000 |   1000 |  0.0004440528 |             f\n",
      "   255 |   255000 |   1000 |  0.0004482814 |             f\n",
      "   256 |   256000 |   1000 |  0.0004499820 |             f\n",
      "   257 |   257000 |   1000 |  0.0004489630 |             f\n",
      "   258 |   258000 |   1000 |  0.0004480434 |             f\n",
      "   259 |   259000 |   1000 |  0.0004463595 |             f\n",
      "   260 |   260000 |   1000 |  0.0004571189 |             f\n",
      "   261 |   261000 |   1000 |  0.2021897832 |         nadir\n",
      "   262 |   262000 |   1000 |  0.0001009574 |             f\n",
      "   263 |   263000 |   1000 |  0.3012855961 |         nadir\n",
      "   264 |   264000 |   1000 |  0.0000974033 |             f\n",
      "   265 |   265000 |   1000 |  0.0001540906 |             f\n",
      "   266 |   266000 |   1000 |  0.0002028427 |             f\n",
      "   267 |   267000 |   1000 |  0.0002426941 |             f\n",
      "   268 |   268000 |   1000 |  0.0002657276 |             f\n",
      "   269 |   269000 |   1000 |  0.7941006965 |         nadir\n",
      "   270 |   270000 |   1000 |  0.0001066517 |             f\n",
      "   271 |   271000 |   1000 |  0.0001961695 |             f\n",
      "   272 |   272000 |   1000 |  0.0002514467 |             f\n",
      "   273 |   273000 |   1000 |  0.0002973947 |             f\n",
      "   274 |   274000 |   1000 |  0.0003359484 |             f\n",
      "   275 |   275000 |   1000 |  0.0003675152 |             f\n",
      "   276 |   276000 |   1000 |  0.0003878728 |             f\n",
      "   277 |   277000 |   1000 |  0.0003995890 |             f\n",
      "   278 |   278000 |   1000 |  0.0004096566 |             f\n",
      "   279 |   279000 |   1000 |  0.0004204644 |             f\n",
      "   280 |   280000 |   1000 |  0.0004254564 |             f\n",
      "   281 |   281000 |   1000 |  0.0004344139 |             f\n",
      "   282 |   282000 |   1000 |  0.0004419941 |             f\n",
      "   283 |   283000 |   1000 |  0.0004337884 |             f\n",
      "   284 |   284000 |   1000 |  0.0004440821 |             f\n",
      "   285 |   285000 |   1000 |  0.0004350524 |             f\n",
      "   286 |   286000 |   1000 |  0.0004301610 |             f\n",
      "   287 |   287000 |   1000 |  0.0004405027 |             f\n",
      "   288 |   288000 |   1000 |  0.0004436184 |             f\n",
      "   289 |   289000 |   1000 |  0.0004518167 |             f\n",
      "   290 |   290000 |   1000 |  0.0004509707 |             f\n",
      "   291 |   291000 |   1000 |  0.0004549499 |             f\n",
      "   292 |   292000 |   1000 |  0.0004598204 |             f\n",
      "   293 |   293000 |   1000 |  0.0004566473 |             f\n",
      "   294 |   294000 |   1000 |  0.0004596046 |             f\n",
      "   295 |   295000 |   1000 |  0.0340268815 |         nadir\n",
      "   296 |   296000 |   1000 |  0.0001014516 |             f\n",
      "   297 |   297000 |   1000 |  0.0001878277 |             f\n",
      "   298 |   298000 |   1000 |  0.0002433758 |             f\n",
      "   299 |   299000 |   1000 |  0.0352254952 |         nadir\n",
      "   300 |   300000 |   1000 |  0.0001133542 |             f\n",
      "   301 |   301000 |   1000 |  0.0001895601 |             f\n",
      "   302 |   302000 |   1000 |  0.0002520339 |             f\n",
      "   303 |   303000 |   1000 |  0.0003026243 |             f\n",
      "   304 |   304000 |   1000 |  0.0003439321 |             f\n",
      "   305 |   305000 |   1000 |  0.0003677937 |             f\n",
      "   306 |   306000 |   1000 |  0.0003937771 |             f\n",
      "   307 |   307000 |   1000 |  0.0004071188 |             f\n",
      "   308 |   308000 |   1000 |  0.0004188912 |             f\n",
      "   309 |   309000 |   1000 |  0.0004309896 |             f\n",
      "   310 |   310000 |   1000 |  0.0004265516 |             f\n",
      "   311 |   311000 |   1000 |  0.0004356116 |             f\n",
      "   312 |   312000 |   1000 |  0.0004367362 |             f\n",
      "   313 |   313000 |   1000 |  0.0004470237 |             f\n",
      "   314 |   314000 |   1000 |  0.0004550979 |             f\n",
      "   315 |   315000 |   1000 |  0.0004527790 |             f\n",
      "   316 |   316000 |   1000 |  0.0004552367 |             f\n",
      "   317 |   317000 |   1000 |  0.0004504738 |             f\n",
      "   318 |   318000 |   1000 |  0.0004596126 |             f\n",
      "   319 |   319000 |   1000 |  0.0004500639 |             f\n",
      "   320 |   320000 |   1000 |  0.0004356153 |             f\n",
      "   321 |   321000 |   1000 |  0.0004372783 |             f\n",
      "   322 |   322000 |   1000 |  0.0004431316 |             f\n",
      "   323 |   323000 |   1000 |  0.0004370931 |             f\n",
      "   324 |   324000 |   1000 |  0.0004468543 |             f\n",
      "   325 |   325000 |   1000 |  0.0004420161 |             f\n",
      "   326 |   326000 |   1000 |  0.0004375713 |             f\n",
      "   327 |   327000 |   1000 |  0.0004458655 |             f\n",
      "   328 |   328000 |   1000 |  0.0004496030 |             f\n",
      "   329 |   329000 |   1000 |  0.0004543312 |             f\n",
      "   330 |   330000 |   1000 |  0.0004479375 |             f\n",
      "   331 |   331000 |   1000 |  0.0004530577 |             f\n",
      "   332 |   332000 |   1000 |  0.0004549361 |             f\n",
      "   333 |   333000 |   1000 |  0.0004488629 |             f\n",
      "   334 |   334000 |   1000 |  0.0004514777 |             f\n",
      "   335 |   335000 |   1000 |  0.0004434317 |             f\n",
      "   336 |   336000 |   1000 |  0.0004558360 |             f\n",
      "   337 |   337000 |   1000 |  0.0004599327 |             f\n",
      "   338 |   338000 |   1000 |  0.0004537790 |             f\n",
      "   339 |   339000 |   1000 |  0.0004551277 |             f\n",
      "   340 |   340000 |   1000 |  0.0004537995 |             f\n",
      "   341 |   341000 |   1000 |  0.0004535356 |             f\n",
      "   342 |   342000 |   1000 |  0.0004521729 |             f\n",
      "   343 |   343000 |   1000 |  0.0004499595 |             f\n",
      "   344 |   344000 |   1000 |  0.0004389884 |             f\n",
      "   345 |   345000 |   1000 |  0.0004399840 |             f\n",
      "   346 |   346000 |   1000 |  0.0004424186 |             f\n",
      "   347 |   347000 |   1000 |  0.0004429204 |             f\n",
      "   348 |   348000 |   1000 |  0.0004515262 |             f\n",
      "   349 |   349000 |   1000 |  0.0004515037 |             f\n",
      "   350 |   350000 |   1000 |  0.0004581456 |             f\n",
      "   351 |   351000 |   1000 |  0.0004485132 |             f\n",
      "   352 |   352000 |   1000 |  0.0004456027 |             f\n",
      "   353 |   353000 |   1000 |  0.0004496136 |             f\n",
      "   354 |   354000 |   1000 |  0.0004478937 |             f\n",
      "   355 |   355000 |   1000 |  0.0004523032 |             f\n",
      "   356 |   356000 |   1000 |  0.0004388781 |             f\n",
      "   357 |   357000 |   1000 |  0.0004373925 |             f\n",
      "   358 |   358000 |   1000 |  0.0004404004 |             f\n",
      "   359 |   359000 |   1000 |  0.0004403207 |             f\n",
      "   360 |   360000 |   1000 |  0.0004362753 |             f\n",
      "   361 |   361000 |   1000 |  0.0004393341 |             f\n",
      "   362 |   362000 |   1000 |  0.0004456761 |             f\n",
      "   363 |   363000 |   1000 |  0.0004450120 |             f\n",
      "   364 |   364000 |   1000 |  0.0004463920 |             f\n",
      "   365 |   365000 |   1000 |  0.0004488422 |             f\n",
      "   366 |   366000 |   1000 |  0.0004540261 |             f\n",
      "   367 |   367000 |   1000 |  0.0004454151 |             f\n",
      "   368 |   368000 |   1000 |  0.0004482619 |             f\n",
      "   369 |   369000 |   1000 |  0.0004510280 |             f\n",
      "   370 |   370000 |   1000 |  0.0004536257 |             f\n",
      "   371 |   371000 |   1000 |  0.0004434224 |             f\n",
      "   372 |   372000 |   1000 |  0.0004466936 |             f\n",
      "   373 |   373000 |   1000 |  0.0004412896 |             f\n",
      "   374 |   374000 |   1000 |  0.0004507661 |             f\n",
      "   375 |   375000 |   1000 |  0.0004566756 |             f\n",
      "   376 |   376000 |   1000 |  0.0004495551 |             f\n",
      "   377 |   377000 |   1000 |  0.0004522968 |             f\n",
      "   378 |   378000 |   1000 |  0.0004585200 |             f\n",
      "   379 |   379000 |   1000 |  0.0004617255 |             f\n",
      "   380 |   380000 |   1000 |  0.0004630590 |             f\n",
      "   381 |   381000 |   1000 |  0.0004603310 |             f\n",
      "   382 |   382000 |   1000 |  0.0004534099 |             f\n",
      "   383 |   383000 |   1000 |  0.0004581103 |             f\n",
      "   384 |   384000 |   1000 |  0.0004552489 |             f\n",
      "   385 |   385000 |   1000 |  0.0004598912 |             f\n",
      "   386 |   386000 |   1000 |  0.0004555894 |             f\n",
      "   387 |   387000 |   1000 |  0.0004617745 |             f\n",
      "   388 |   388000 |   1000 |  0.0004680880 |             f\n",
      "   389 |   389000 |   1000 |  0.0004638728 |             f\n",
      "   390 |   390000 |   1000 |  0.0004685091 |             f\n",
      "   391 |   391000 |   1000 |  0.0004725258 |             f\n",
      "   392 |   392000 |   1000 |  0.0004691370 |             f\n",
      "   393 |   393000 |   1000 |  0.0004704502 |             f\n",
      "   394 |   394000 |   1000 |  0.0004651155 |             f\n",
      "   395 |   395000 |   1000 |  0.0004524287 |             f\n",
      "   396 |   396000 |   1000 |  0.0004479991 |             f\n",
      "   397 |   397000 |   1000 |  0.0004495138 |             f\n",
      "   398 |   398000 |   1000 |  0.0004533883 |             f\n",
      "   399 |   399000 |   1000 |  0.0004525586 |             f\n",
      "   400 |   400000 |   1000 |  0.0004558743 |             f\n",
      "   401 |   401000 |   1000 |  0.0004523478 |             f\n",
      "   402 |   402000 |   1000 |  0.0004380894 |             f\n",
      "   403 |   403000 |   1000 |  0.0004468593 |             f\n",
      "   404 |   404000 |   1000 |  0.0004392033 |             f\n",
      "   405 |   405000 |   1000 |  0.0004491239 |             f\n",
      "   406 |   406000 |   1000 |  0.0004503788 |             f\n",
      "   407 |   407000 |   1000 |  0.0004591728 |             f\n",
      "   408 |   408000 |   1000 |  0.0004543310 |             f\n",
      "   409 |   409000 |   1000 |  0.0004432251 |             f\n",
      "   410 |   410000 |   1000 |  0.0004518781 |             f\n",
      "   411 |   411000 |   1000 |  0.0004493592 |             f\n",
      "   412 |   412000 |   1000 |  0.0004529586 |             f\n",
      "   413 |   413000 |   1000 |  0.0004604505 |             f\n",
      "   414 |   414000 |   1000 |  0.0004525037 |             f\n",
      "   415 |   415000 |   1000 |  0.0004471581 |             f\n",
      "   416 |   416000 |   1000 |  0.0004465547 |             f\n",
      "   417 |   417000 |   1000 |  0.0004500599 |             f\n",
      "   418 |   418000 |   1000 |  0.0004581055 |             f\n",
      "   419 |   419000 |   1000 |  0.0004603308 |             f\n",
      "   420 |   420000 |   1000 |  0.0004552428 |             f\n",
      "   421 |   421000 |   1000 |  0.0004520833 |             f\n",
      "   422 |   422000 |   1000 |  0.0004413983 |             f\n",
      "   423 |   423000 |   1000 |  0.0004441647 |             f\n",
      "   424 |   424000 |   1000 |  0.0004418185 |             f\n",
      "   425 |   425000 |   1000 |  0.0004523574 |             f\n",
      "   426 |   426000 |   1000 |  0.0004481753 |             f\n",
      "   427 |   427000 |   1000 |  0.0004483317 |             f\n",
      "   428 |   428000 |   1000 |  0.0004490755 |             f\n",
      "   429 |   429000 |   1000 |  0.0004493026 |             f\n",
      "   430 |   430000 |   1000 |  0.0004394555 |             f\n",
      "   431 |   431000 |   1000 |  0.0004371689 |             f\n",
      "   432 |   432000 |   1000 |  0.0004373683 |             f\n",
      "   433 |   433000 |   1000 |  0.0004350370 |             f\n",
      "   434 |   434000 |   1000 |  0.0004458574 |             f\n",
      "   435 |   435000 |   1000 |  0.0004507887 |             f\n",
      "   436 |   436000 |   1000 |  0.0004453561 |             f\n",
      "   437 |   437000 |   1000 |  0.0004550210 |             f\n",
      "   438 |   438000 |   1000 |  0.0004493560 |             f\n",
      "   439 |   439000 |   1000 |  0.0004588974 |             f\n",
      "   440 |   440000 |   1000 |  0.0004597604 |             f\n",
      "   441 |   441000 |   1000 |  0.0004630807 |             f\n",
      "   442 |   442000 |   1000 |  0.0004563680 |             f\n",
      "   443 |   443000 |   1000 |  0.0004468344 |             f\n",
      "   444 |   444000 |   1000 |  0.0004496169 |             f\n",
      "   445 |   445000 |   1000 |  0.0004511627 |             f\n",
      "   446 |   446000 |   1000 |  0.0004555661 |             f\n",
      "   447 |   447000 |   1000 |  0.0004325949 |             f\n",
      "   448 |   448000 |   1000 |  0.0004406660 |             f\n",
      "   449 |   449000 |   1000 |  0.0004486673 |             f\n",
      "   450 |   450000 |   1000 |  0.0004495732 |             f\n",
      "   451 |   451000 |   1000 |  0.0004623178 |             f\n",
      "   452 |   452000 |   1000 |  0.0004626694 |             f\n",
      "   453 |   453000 |   1000 |  0.0004623408 |             f\n",
      "   454 |   454000 |   1000 |  0.0004514570 |             f\n",
      "   455 |   455000 |   1000 |  0.0004592432 |             f\n",
      "   456 |   456000 |   1000 |  0.0004520295 |             f\n",
      "   457 |   457000 |   1000 |  0.0004549373 |             f\n",
      "   458 |   458000 |   1000 |  0.0004549011 |             f\n",
      "   459 |   459000 |   1000 |  0.0004583629 |             f\n",
      "   460 |   460000 |   1000 |  0.0004576408 |             f\n",
      "   461 |   461000 |   1000 |  0.0004577197 |             f\n",
      "   462 |   462000 |   1000 |  0.0004561686 |             f\n",
      "   463 |   463000 |   1000 |  0.0004622236 |             f\n",
      "   464 |   464000 |   1000 |  0.0004534868 |             f\n",
      "   465 |   465000 |   1000 |  0.0004495274 |             f\n",
      "   466 |   466000 |   1000 |  0.0004524728 |             f\n",
      "   467 |   467000 |   1000 |  0.0004520237 |             f\n",
      "   468 |   468000 |   1000 |  0.0004524458 |             f\n",
      "   469 |   469000 |   1000 |  0.0004444670 |             f\n",
      "   470 |   470000 |   1000 |  0.0004427268 |             f\n",
      "   471 |   471000 |   1000 |  0.0004373992 |             f\n",
      "   472 |   472000 |   1000 |  0.0004367862 |             f\n",
      "   473 |   473000 |   1000 |  0.0004511215 |             f\n",
      "   474 |   474000 |   1000 |  0.0004462485 |             f\n",
      "   475 |   475000 |   1000 |  0.0004540993 |             f\n",
      "   476 |   476000 |   1000 |  0.0004563124 |             f\n",
      "   477 |   477000 |   1000 |  0.0004465178 |             f\n",
      "   478 |   478000 |   1000 |  0.0004498012 |             f\n",
      "   479 |   479000 |   1000 |  0.0004495685 |             f\n",
      "   480 |   480000 |   1000 |  0.0004427812 |             f\n",
      "   481 |   481000 |   1000 |  0.0004518069 |             f\n",
      "   482 |   482000 |   1000 |  0.0004615591 |             f\n",
      "   483 |   483000 |   1000 |  0.0004497260 |             f\n",
      "   484 |   484000 |   1000 |  0.0004467920 |             f\n",
      "   485 |   485000 |   1000 |  0.0004431069 |             f\n",
      "   486 |   486000 |   1000 |  0.0004435857 |             f\n",
      "   487 |   487000 |   1000 |  0.0004447167 |             f\n",
      "   488 |   488000 |   1000 |  0.0004416236 |             f\n",
      "   489 |   489000 |   1000 |  0.0004455109 |             f\n",
      "   490 |   490000 |   1000 |  0.0004446956 |             f\n",
      "   491 |   491000 |   1000 |  0.0004477038 |             f\n",
      "   492 |   492000 |   1000 |  0.0004474239 |             f\n",
      "   493 |   493000 |   1000 |  0.0004521453 |             f\n",
      "   494 |   494000 |   1000 |  0.0004523052 |             f\n",
      "   495 |   495000 |   1000 |  0.0004523336 |             f\n",
      "   496 |   496000 |   1000 |  0.0004447575 |             f\n",
      "   497 |   497000 |   1000 |  0.0004538821 |             f\n",
      "   498 |   498000 |   1000 |  0.0004474481 |             f\n",
      "   499 |   499000 |   1000 |  0.0004359800 |             f\n",
      "   500 |   500000 |   1000 |  0.0004395993 |             f\n",
      "   501 |   501000 |   1000 |  0.0004389812 |             f\n",
      "   502 |   502000 |   1000 |  0.0004450936 |             f\n",
      "   503 |   503000 |   1000 |  0.0004400088 |             f\n",
      "   504 |   504000 |   1000 |  0.0004431014 |             f\n",
      "   505 |   505000 |   1000 |  0.0004308790 |             f\n",
      "   506 |   506000 |   1000 |  0.0004377157 |             f\n",
      "   507 |   507000 |   1000 |  0.0004436885 |             f\n",
      "   508 |   508000 |   1000 |  0.0004563447 |             f\n",
      "   509 |   509000 |   1000 |  0.0004455095 |             f\n",
      "   510 |   510000 |   1000 |  0.0004374537 |             f\n",
      "   511 |   511000 |   1000 |  0.0004499865 |             f\n",
      "   512 |   512000 |   1000 |  0.0004548557 |             f\n",
      "   513 |   513000 |   1000 |  0.0004562694 |             f\n",
      "   514 |   514000 |   1000 |  0.0004641493 |             f\n",
      "   515 |   515000 |   1000 |  0.0004683115 |             f\n",
      "   516 |   516000 |   1000 |  0.0004602483 |             f\n",
      "   517 |   517000 |   1000 |  0.0004577297 |             f\n",
      "   518 |   518000 |   1000 |  0.0004587962 |             f\n",
      "   519 |   519000 |   1000 |  0.0004648783 |             f\n",
      "   520 |   520000 |   1000 |  0.0004646572 |             f\n",
      "   521 |   521000 |   1000 |  0.0004554940 |             f\n",
      "   522 |   522000 |   1000 |  0.0004657072 |             f\n",
      "   523 |   523000 |   1000 |  0.0004664430 |             f\n",
      "   524 |   524000 |   1000 |  0.0004635388 |             f\n",
      "   525 |   525000 |   1000 |  0.0004678871 |             f\n",
      "   526 |   526000 |   1000 |  0.0004597322 |             f\n",
      "   527 |   527000 |   1000 |  0.0004495311 |             f\n",
      "   528 |   528000 |   1000 |  0.0004560840 |             f\n",
      "   529 |   529000 |   1000 |  0.0004552932 |             f\n",
      "   530 |   530000 |   1000 |  0.0004534456 |             f\n",
      "   531 |   531000 |   1000 |  0.0004492663 |             f\n",
      "   532 |   532000 |   1000 |  0.0004509920 |             f\n",
      "   533 |   533000 |   1000 |  0.0004521576 |             f\n",
      "   534 |   534000 |   1000 |  0.0004492662 |             f\n",
      "   535 |   535000 |   1000 |  0.0004562296 |             f\n",
      "   536 |   536000 |   1000 |  0.0004478241 |             f\n",
      "   537 |   537000 |   1000 |  0.0004474163 |             f\n",
      "   538 |   538000 |   1000 |  0.0004484451 |             f\n",
      "   539 |   539000 |   1000 |  0.0004511044 |             f\n",
      "   540 |   540000 |   1000 |  0.0004593744 |             f\n",
      "   541 |   541000 |   1000 |  0.0004529464 |             f\n",
      "   542 |   542000 |   1000 |  0.0004515380 |             f\n",
      "   543 |   543000 |   1000 |  0.0004447122 |             f\n",
      "   544 |   544000 |   1000 |  0.0004475535 |             f\n",
      "   545 |   545000 |   1000 |  0.0004430734 |             f\n",
      "   546 |   546000 |   1000 |  0.0004450838 |             f\n",
      "   547 |   547000 |   1000 |  0.0004427426 |             f\n",
      "   548 |   548000 |   1000 |  0.0004436550 |             f\n",
      "   549 |   549000 |   1000 |  0.0004425154 |             f\n",
      "   550 |   550000 |   1000 |  0.0004486354 |             f\n",
      "   551 |   551000 |   1000 |  0.0004439556 |             f\n",
      "   552 |   552000 |   1000 |  0.0004509528 |             f\n",
      "   553 |   553000 |   1000 |  0.0004407241 |             f\n",
      "   554 |   554000 |   1000 |  0.0004439087 |             f\n",
      "   555 |   555000 |   1000 |  0.0004468412 |             f\n",
      "   556 |   556000 |   1000 |  0.0004399253 |             f\n",
      "   557 |   557000 |   1000 |  0.0004554169 |             f\n",
      "   558 |   558000 |   1000 |  0.0004526022 |             f\n",
      "   559 |   559000 |   1000 |  0.0004575489 |             f\n",
      "   560 |   560000 |   1000 |  0.0004570435 |             f\n",
      "   561 |   561000 |   1000 |  0.0004586243 |             f\n",
      "   562 |   562000 |   1000 |  0.0004513520 |             f\n",
      "   563 |   563000 |   1000 |  0.0004428945 |             f\n",
      "   564 |   564000 |   1000 |  0.0004392669 |             f\n",
      "   565 |   565000 |   1000 |  0.0004361467 |             f\n",
      "   566 |   566000 |   1000 |  0.0004436128 |             f\n",
      "   567 |   567000 |   1000 |  0.0004315692 |             f\n",
      "   568 |   568000 |   1000 |  0.0004484135 |             f\n",
      "   569 |   569000 |   1000 |  0.0004651850 |             f\n",
      "   570 |   570000 |   1000 |  0.0004600452 |             f\n",
      "   571 |   571000 |   1000 |  0.0004670372 |             f\n",
      "   572 |   572000 |   1000 |  0.0004627664 |             f\n",
      "   573 |   573000 |   1000 |  0.0004644751 |             f\n",
      "   574 |   574000 |   1000 |  0.0004627402 |             f\n",
      "   575 |   575000 |   1000 |  0.0004657669 |             f\n",
      "   576 |   576000 |   1000 |  0.0004581413 |             f\n",
      "   577 |   577000 |   1000 |  0.0004505735 |             f\n",
      "   578 |   578000 |   1000 |  0.0004478277 |             f\n",
      "   579 |   579000 |   1000 |  0.0004474726 |             f\n",
      "   580 |   580000 |   1000 |  0.0004506570 |             f\n",
      "   581 |   581000 |   1000 |  0.0004541079 |             f\n",
      "   582 |   582000 |   1000 |  0.0004521119 |             f\n",
      "   583 |   583000 |   1000 |  0.0004522545 |             f\n",
      "   584 |   584000 |   1000 |  0.0004465144 |             f\n",
      "   585 |   585000 |   1000 |  0.0004557579 |             f\n",
      "   586 |   586000 |   1000 |  0.0004479642 |             f\n",
      "   587 |   587000 |   1000 |  0.0004508289 |             f\n",
      "   588 |   588000 |   1000 |  0.0004504138 |             f\n",
      "   589 |   589000 |   1000 |  0.0004480264 |             f\n",
      "   590 |   590000 |   1000 |  0.0004451210 |             f\n",
      "   591 |   591000 |   1000 |  0.0004459086 |             f\n",
      "   592 |   592000 |   1000 |  0.0004622341 |             f\n",
      "   593 |   593000 |   1000 |  0.0004627318 |             f\n",
      "   594 |   594000 |   1000 |  0.0004596137 |             f\n",
      "   595 |   595000 |   1000 |  0.0004609967 |             f\n",
      "   596 |   596000 |   1000 |  0.0004642233 |             f\n",
      "   597 |   597000 |   1000 |  0.0004523212 |             f\n",
      "   598 |   598000 |   1000 |  0.0004496435 |             f\n",
      "   599 |   599000 |   1000 |  0.0004597529 |             f\n",
      "   600 |   600000 |   1000 |  0.0004630853 |             f\n",
      "   601 |   601000 |   1000 |  0.0004551821 |             f\n",
      "   602 |   602000 |   1000 |  0.0004493407 |             f\n",
      "   603 |   603000 |   1000 |  0.0004567442 |             f\n",
      "   604 |   604000 |   1000 |  0.0004573023 |             f\n",
      "   605 |   605000 |   1000 |  0.0004537593 |             f\n",
      "   606 |   606000 |   1000 |  0.0004586609 |             f\n",
      "   607 |   607000 |   1000 |  0.0004523200 |             f\n",
      "   608 |   608000 |   1000 |  0.0004620971 |             f\n",
      "   609 |   609000 |   1000 |  0.0004524259 |             f\n",
      "   610 |   610000 |   1000 |  0.0004530749 |             f\n",
      "   611 |   611000 |   1000 |  0.0004493686 |             f\n",
      "   612 |   612000 |   1000 |  0.0004519186 |             f\n",
      "   613 |   613000 |   1000 |  0.0004567848 |             f\n",
      "   614 |   614000 |   1000 |  0.0004447910 |             f\n",
      "   615 |   615000 |   1000 |  0.0004369286 |             f\n",
      "   616 |   616000 |   1000 |  0.0004471912 |             f\n",
      "   617 |   617000 |   1000 |  0.0004536371 |             f\n",
      "   618 |   618000 |   1000 |  0.0004527477 |             f\n",
      "   619 |   619000 |   1000 |  0.0004459271 |             f\n",
      "   620 |   620000 |   1000 |  0.0004511534 |             f\n",
      "   621 |   621000 |   1000 |  0.0004634612 |             f\n",
      "   622 |   622000 |   1000 |  0.0004567282 |             f\n",
      "   623 |   623000 |   1000 |  0.0004482769 |             f\n",
      "   624 |   624000 |   1000 |  0.0004464441 |             f\n",
      "   625 |   625000 |   1000 |  0.0004423947 |             f\n",
      "   626 |   626000 |   1000 |  0.0004562228 |             f\n",
      "   627 |   627000 |   1000 |  0.0004576632 |             f\n",
      "   628 |   628000 |   1000 |  0.0004575765 |             f\n",
      "   629 |   629000 |   1000 |  0.0004677459 |             f\n",
      "   630 |   630000 |   1000 |  0.0004654252 |             f\n",
      "   631 |   631000 |   1000 |  0.0004643464 |             f\n",
      "   632 |   632000 |   1000 |  0.0004575062 |             f\n",
      "   633 |   633000 |   1000 |  0.0004466906 |             f\n",
      "   634 |   634000 |   1000 |  0.0004542694 |             f\n",
      "   635 |   635000 |   1000 |  0.0004430377 |             f\n",
      "   636 |   636000 |   1000 |  0.0004393601 |             f\n",
      "   637 |   637000 |   1000 |  0.0004418563 |             f\n",
      "   638 |   638000 |   1000 |  0.0004461435 |             f\n",
      "   639 |   639000 |   1000 |  0.0004454505 |             f\n",
      "   640 |   640000 |   1000 |  0.0004574656 |             f\n",
      "   641 |   641000 |   1000 |  0.0004536009 |             f\n",
      "   642 |   642000 |   1000 |  0.0004539662 |             f\n",
      "   643 |   643000 |   1000 |  0.0004617513 |             f\n",
      "   644 |   644000 |   1000 |  0.0004617087 |             f\n",
      "   645 |   645000 |   1000 |  0.0004539580 |             f\n",
      "   646 |   646000 |   1000 |  0.0004431617 |             f\n",
      "   647 |   647000 |   1000 |  0.0004477391 |             f\n",
      "   648 |   648000 |   1000 |  0.0004475349 |             f\n",
      "   649 |   649000 |   1000 |  0.0004466595 |             f\n",
      "   650 |   650000 |   1000 |  0.0004546959 |             f\n",
      "   651 |   651000 |   1000 |  0.0004585481 |             f\n",
      "   652 |   652000 |   1000 |  0.0004637690 |             f\n",
      "   653 |   653000 |   1000 |  0.0004633889 |             f\n",
      "   654 |   654000 |   1000 |  0.0004662499 |             f\n",
      "   655 |   655000 |   1000 |  0.0004758556 |             f\n",
      "   656 |   656000 |   1000 |  0.0004646025 |             f\n",
      "   657 |   657000 |   1000 |  0.0004637891 |             f\n",
      "   658 |   658000 |   1000 |  0.0004693052 |             f\n",
      "   659 |   659000 |   1000 |  0.0004494703 |             f\n",
      "   660 |   660000 |   1000 |  0.0004563223 |             f\n",
      "   661 |   661000 |   1000 |  0.0004492206 |             f\n",
      "   662 |   662000 |   1000 |  0.0004556700 |             f\n",
      "   663 |   663000 |   1000 |  0.0004578662 |             f\n",
      "   664 |   664000 |   1000 |  0.0004564513 |             f\n",
      "   665 |   665000 |   1000 |  0.0004542579 |             f\n",
      "   666 |   666000 |   1000 |  0.0004541461 |             f\n",
      "   667 |   667000 |   1000 |  0.0004566758 |             f\n",
      "   668 |   668000 |   1000 |  0.0004646371 |             f\n",
      "   669 |   669000 |   1000 |  0.0004697816 |             f\n",
      "   670 |   670000 |   1000 |  0.0004573941 |             f\n",
      "   671 |   671000 |   1000 |  0.0004613848 |             f\n",
      "   672 |   672000 |   1000 |  0.0004563280 |             f\n",
      "   673 |   673000 |   1000 |  0.0004476325 |             f\n",
      "   674 |   674000 |   1000 |  0.0004438841 |             f\n",
      "   675 |   675000 |   1000 |  0.0004522186 |             f\n",
      "   676 |   676000 |   1000 |  0.0004533430 |             f\n",
      "   677 |   677000 |   1000 |  0.0004500316 |             f\n",
      "   678 |   678000 |   1000 |  0.0004508895 |             f\n",
      "   679 |   679000 |   1000 |  0.0004512710 |             f\n",
      "   680 |   680000 |   1000 |  0.0004475287 |             f\n",
      "   681 |   681000 |   1000 |  0.0004484152 |             f\n",
      "   682 |   682000 |   1000 |  0.0004541369 |             f\n",
      "   683 |   683000 |   1000 |  0.0004585246 |             f\n",
      "   684 |   684000 |   1000 |  0.0004602461 |             f\n",
      "   685 |   685000 |   1000 |  0.0004578428 |             f\n",
      "   686 |   686000 |   1000 |  0.0004556262 |             f\n",
      "   687 |   687000 |   1000 |  0.0004538864 |             f\n",
      "   688 |   688000 |   1000 |  0.0004565380 |             f\n",
      "   689 |   689000 |   1000 |  0.0004507789 |             f\n",
      "   690 |   690000 |   1000 |  0.0004538270 |             f\n",
      "   691 |   691000 |   1000 |  0.0004378459 |             f\n",
      "   692 |   692000 |   1000 |  0.0004421655 |             f\n",
      "   693 |   693000 |   1000 |  0.0004477895 |             f\n",
      "   694 |   694000 |   1000 |  0.0004585053 |             f\n",
      "   695 |   695000 |   1000 |  0.0004450769 |             f\n",
      "   696 |   696000 |   1000 |  0.0004277877 |             f\n",
      "   697 |   697000 |   1000 |  0.0004306998 |             f\n",
      "   698 |   698000 |   1000 |  0.0004364061 |             f\n",
      "   699 |   699000 |   1000 |  0.0004441869 |             f\n",
      "   700 |   700000 |   1000 |  0.0004458949 |             f\n",
      "   701 |   701000 |   1000 |  0.0004474011 |             f\n",
      "   702 |   702000 |   1000 |  0.0004476552 |             f\n",
      "   703 |   703000 |   1000 |  0.0004483878 |             f\n",
      "   704 |   704000 |   1000 |  0.0004427542 |             f\n",
      "   705 |   705000 |   1000 |  0.0004336861 |             f\n",
      "   706 |   706000 |   1000 |  0.0004334656 |             f\n",
      "   707 |   707000 |   1000 |  0.0004436060 |             f\n",
      "   708 |   708000 |   1000 |  0.0004506373 |             f\n",
      "   709 |   709000 |   1000 |  0.0004449226 |             f\n",
      "   710 |   710000 |   1000 |  0.0004378950 |             f\n",
      "   711 |   711000 |   1000 |  0.0004494724 |             f\n",
      "   712 |   712000 |   1000 |  0.0004527184 |             f\n",
      "   713 |   713000 |   1000 |  0.0004516059 |             f\n",
      "   714 |   714000 |   1000 |  0.0004491477 |             f\n",
      "   715 |   715000 |   1000 |  0.0004425760 |             f\n",
      "   716 |   716000 |   1000 |  0.0004400495 |             f\n",
      "   717 |   717000 |   1000 |  0.0004366724 |             f\n",
      "   718 |   718000 |   1000 |  0.0004498619 |             f\n",
      "   719 |   719000 |   1000 |  0.0004532225 |             f\n",
      "   720 |   720000 |   1000 |  0.0004655185 |             f\n",
      "   721 |   721000 |   1000 |  0.0004611020 |             f\n",
      "   722 |   722000 |   1000 |  0.0004466600 |             f\n",
      "   723 |   723000 |   1000 |  0.0004417614 |             f\n",
      "   724 |   724000 |   1000 |  0.0004476648 |             f\n",
      "   725 |   725000 |   1000 |  0.0004527273 |             f\n",
      "   726 |   726000 |   1000 |  0.0004623332 |             f\n",
      "   727 |   727000 |   1000 |  0.0004577626 |             f\n",
      "   728 |   728000 |   1000 |  0.0004568529 |             f\n",
      "   729 |   729000 |   1000 |  0.0004564188 |             f\n",
      "   730 |   730000 |   1000 |  0.0004495074 |             f\n",
      "   731 |   731000 |   1000 |  0.0004555558 |             f\n",
      "   732 |   732000 |   1000 |  0.0004633265 |             f\n",
      "   733 |   733000 |   1000 |  0.0004589466 |             f\n",
      "   734 |   734000 |   1000 |  0.0004591847 |             f\n",
      "   735 |   735000 |   1000 |  0.0004575917 |             f\n",
      "   736 |   736000 |   1000 |  0.0004594381 |             f\n",
      "   737 |   737000 |   1000 |  0.0004511600 |             f\n",
      "   738 |   738000 |   1000 |  0.0004649403 |             f\n",
      "   739 |   739000 |   1000 |  0.0004624597 |             f\n",
      "   740 |   740000 |   1000 |  0.0004480542 |             f\n",
      "   741 |   741000 |   1000 |  0.0004499469 |             f\n",
      "   742 |   742000 |   1000 |  0.0004365364 |             f\n",
      "   743 |   743000 |   1000 |  0.0004407781 |             f\n",
      "   744 |   744000 |   1000 |  0.0004329128 |             f\n",
      "   745 |   745000 |   1000 |  0.0004362244 |             f\n",
      "   746 |   746000 |   1000 |  0.0004462736 |             f\n",
      "   747 |   747000 |   1000 |  0.0004452314 |             f\n",
      "   748 |   748000 |   1000 |  0.0004453784 |             f\n",
      "   749 |   749000 |   1000 |  0.0004477845 |             f\n",
      "   750 |   750000 |   1000 |  0.0004383421 |             f\n",
      "   751 |   751000 |   1000 |  0.0004233844 |             f\n",
      "   752 |   752000 |   1000 |  0.0004262432 |             f\n",
      "   753 |   753000 |   1000 |  0.0004268807 |             f\n",
      "   754 |   754000 |   1000 |  0.0004335381 |             f\n",
      "   755 |   755000 |   1000 |  0.0004402344 |             f\n",
      "   756 |   756000 |   1000 |  0.0004465295 |             f\n",
      "   757 |   757000 |   1000 |  0.0004456705 |             f\n",
      "   758 |   758000 |   1000 |  0.0004389730 |             f\n",
      "   759 |   759000 |   1000 |  0.0004460966 |             f\n",
      "   760 |   760000 |   1000 |  0.0004418209 |             f\n",
      "   761 |   761000 |   1000 |  0.0004441281 |             f\n",
      "   762 |   762000 |   1000 |  0.0004429299 |             f\n",
      "   763 |   763000 |   1000 |  0.0004553923 |             f\n",
      "   764 |   764000 |   1000 |  0.0004516046 |             f\n",
      "   765 |   765000 |   1000 |  0.0004522574 |             f\n",
      "   766 |   766000 |   1000 |  0.0004454801 |             f\n",
      "   767 |   767000 |   1000 |  0.0004555171 |             f\n",
      "   768 |   768000 |   1000 |  0.0004644363 |             f\n",
      "   769 |   769000 |   1000 |  0.0004587343 |             f\n",
      "   770 |   770000 |   1000 |  0.0004614973 |             f\n",
      "   771 |   771000 |   1000 |  0.0004626986 |             f\n",
      "   772 |   772000 |   1000 |  0.0004559240 |             f\n",
      "   773 |   773000 |   1000 |  0.0004617200 |             f\n",
      "   774 |   774000 |   1000 |  0.0004660737 |             f\n",
      "   775 |   775000 |   1000 |  0.0004660062 |             f\n",
      "   776 |   776000 |   1000 |  0.0004621695 |             f\n",
      "   777 |   777000 |   1000 |  0.0004582310 |             f\n",
      "   778 |   778000 |   1000 |  0.0004617201 |             f\n",
      "   779 |   779000 |   1000 |  0.0004588167 |             f\n",
      "   780 |   780000 |   1000 |  0.0004520593 |             f\n",
      "   781 |   781000 |   1000 |  0.0004413802 |             f\n",
      "   782 |   782000 |   1000 |  0.0004447759 |             f\n",
      "   783 |   783000 |   1000 |  0.0004524343 |             f\n",
      "   784 |   784000 |   1000 |  0.0004397923 |             f\n",
      "   785 |   785000 |   1000 |  0.0004438849 |             f\n",
      "   786 |   786000 |   1000 |  0.0004444148 |             f\n",
      "   787 |   787000 |   1000 |  0.0004508825 |             f\n",
      "   788 |   788000 |   1000 |  0.0004461572 |             f\n",
      "   789 |   789000 |   1000 |  0.0004421692 |             f\n",
      "   790 |   790000 |   1000 |  0.0004352643 |             f\n",
      "   791 |   791000 |   1000 |  0.0004455334 |             f\n",
      "   792 |   792000 |   1000 |  0.0004511794 |             f\n",
      "   793 |   793000 |   1000 |  0.0004434112 |             f\n",
      "   794 |   794000 |   1000 |  0.0004465153 |             f\n",
      "   795 |   795000 |   1000 |  0.0004371699 |             f\n",
      "   796 |   796000 |   1000 |  0.0004426569 |             f\n",
      "   797 |   797000 |   1000 |  0.0004575806 |             f\n",
      "   798 |   798000 |   1000 |  0.0004542071 |             f\n",
      "   799 |   799000 |   1000 |  0.0004495486 |             f\n",
      "   800 |   800000 |   1000 |  0.0004581523 |             f\n",
      "   801 |   801000 |   1000 |  0.0004508139 |             f\n",
      "   802 |   802000 |   1000 |  0.0004568470 |             f\n",
      "   803 |   803000 |   1000 |  0.0004502083 |             f\n",
      "   804 |   804000 |   1000 |  0.0004504279 |             f\n",
      "   805 |   805000 |   1000 |  0.0004500139 |             f\n",
      "   806 |   806000 |   1000 |  0.0004494927 |             f\n",
      "   807 |   807000 |   1000 |  0.0004557596 |             f\n",
      "   808 |   808000 |   1000 |  0.0004595613 |             f\n",
      "   809 |   809000 |   1000 |  0.0004511665 |             f\n",
      "   810 |   810000 |   1000 |  0.0004564207 |             f\n",
      "   811 |   811000 |   1000 |  0.0004599625 |             f\n",
      "   812 |   812000 |   1000 |  0.0004651062 |             f\n",
      "   813 |   813000 |   1000 |  0.0004621481 |             f\n",
      "   814 |   814000 |   1000 |  0.0004547277 |             f\n",
      "   815 |   815000 |   1000 |  0.0004652049 |             f\n",
      "   816 |   816000 |   1000 |  0.0004577342 |             f\n",
      "   817 |   817000 |   1000 |  0.0004577711 |             f\n",
      "   818 |   818000 |   1000 |  0.0004525428 |             f\n",
      "   819 |   819000 |   1000 |  0.0004570974 |             f\n",
      "   820 |   820000 |   1000 |  0.0004593245 |             f\n",
      "   821 |   821000 |   1000 |  0.0004584381 |             f\n",
      "   822 |   822000 |   1000 |  0.0004660664 |             f\n",
      "   823 |   823000 |   1000 |  0.0004758737 |             f\n",
      "   824 |   824000 |   1000 |  0.0004668621 |             f\n",
      "   825 |   825000 |   1000 |  0.0004693362 |             f\n",
      "   826 |   826000 |   1000 |  0.0004625868 |             f\n",
      "   827 |   827000 |   1000 |  0.0004555066 |             f\n",
      "   828 |   828000 |   1000 |  0.0004534007 |             f\n",
      "   829 |   829000 |   1000 |  0.0004501596 |             f\n",
      "   830 |   830000 |   1000 |  0.0004494649 |             f\n",
      "   831 |   831000 |   1000 |  0.0004584170 |             f\n",
      "   832 |   832000 |   1000 |  0.0004638160 |             f\n",
      "   833 |   833000 |   1000 |  0.0004622961 |             f\n",
      "   834 |   834000 |   1000 |  0.0004503777 |             f\n",
      "   835 |   835000 |   1000 |  0.0004479567 |             f\n",
      "   836 |   836000 |   1000 |  0.0004541131 |             f\n",
      "   837 |   837000 |   1000 |  0.0004612886 |             f\n",
      "   838 |   838000 |   1000 |  0.0004667261 |             f\n",
      "   839 |   839000 |   1000 |  0.0004653881 |             f\n",
      "   840 |   840000 |   1000 |  0.0004599065 |             f\n",
      "   841 |   841000 |   1000 |  0.0004569398 |             f\n",
      "   842 |   842000 |   1000 |  0.0004558388 |             f\n",
      "   843 |   843000 |   1000 |  0.0004566456 |             f\n",
      "   844 |   844000 |   1000 |  0.0004708044 |             f\n",
      "   845 |   845000 |   1000 |  0.0004656913 |             f\n",
      "   846 |   846000 |   1000 |  0.0004692971 |             f\n",
      "   847 |   847000 |   1000 |  0.0004670198 |             f\n",
      "   848 |   848000 |   1000 |  0.0004561606 |             f\n",
      "   849 |   849000 |   1000 |  0.0004495594 |             f\n",
      "   850 |   850000 |   1000 |  0.0004500332 |             f\n",
      "   851 |   851000 |   1000 |  0.0004418550 |             f\n",
      "   852 |   852000 |   1000 |  0.0004377459 |             f\n",
      "   853 |   853000 |   1000 |  0.0004372067 |             f\n",
      "   854 |   854000 |   1000 |  0.0004486999 |             f\n",
      "   855 |   855000 |   1000 |  0.0004615200 |             f\n",
      "   856 |   856000 |   1000 |  0.0004653897 |             f\n",
      "   857 |   857000 |   1000 |  0.0004605535 |             f\n",
      "   858 |   858000 |   1000 |  0.0004560333 |             f\n",
      "   859 |   859000 |   1000 |  0.0004535650 |             f\n",
      "   860 |   860000 |   1000 |  0.0004561731 |             f\n",
      "   861 |   861000 |   1000 |  0.0004486478 |             f\n",
      "   862 |   862000 |   1000 |  0.0004475981 |             f\n",
      "   863 |   863000 |   1000 |  0.0004421035 |             f\n",
      "   864 |   864000 |   1000 |  0.0004482669 |             f\n",
      "   865 |   865000 |   1000 |  0.0004412093 |             f\n",
      "   866 |   866000 |   1000 |  0.0004501719 |             f\n",
      "   867 |   867000 |   1000 |  0.0004580106 |             f\n",
      "   868 |   868000 |   1000 |  0.0004564389 |             f\n",
      "   869 |   869000 |   1000 |  0.0004569486 |             f\n",
      "   870 |   870000 |   1000 |  0.0004542358 |             f\n",
      "   871 |   871000 |   1000 |  0.0004488230 |             f\n",
      "   872 |   872000 |   1000 |  0.0004573576 |             f\n",
      "   873 |   873000 |   1000 |  0.0004581857 |             f\n",
      "   874 |   874000 |   1000 |  0.0004484796 |             f\n",
      "   875 |   875000 |   1000 |  0.0004583553 |             f\n",
      "   876 |   876000 |   1000 |  0.0004445094 |             f\n",
      "   877 |   877000 |   1000 |  0.0004445868 |             f\n",
      "   878 |   878000 |   1000 |  0.0004483306 |             f\n",
      "   879 |   879000 |   1000 |  0.0004487072 |             f\n",
      "   880 |   880000 |   1000 |  0.0004417442 |             f\n",
      "   881 |   881000 |   1000 |  0.0004455486 |             f\n",
      "   882 |   882000 |   1000 |  0.0004515482 |             f\n",
      "   883 |   883000 |   1000 |  0.0004527876 |             f\n",
      "   884 |   884000 |   1000 |  0.0004461760 |             f\n",
      "   885 |   885000 |   1000 |  0.0004435274 |             f\n",
      "   886 |   886000 |   1000 |  0.0004448412 |             f\n",
      "   887 |   887000 |   1000 |  0.0004546656 |             f\n",
      "   888 |   888000 |   1000 |  0.0004521005 |             f\n",
      "   889 |   889000 |   1000 |  0.0004426981 |             f\n",
      "   890 |   890000 |   1000 |  0.0004449834 |             f\n",
      "   891 |   891000 |   1000 |  0.0004465955 |             f\n",
      "   892 |   892000 |   1000 |  0.0004461299 |             f\n",
      "   893 |   893000 |   1000 |  0.0004531720 |             f\n",
      "   894 |   894000 |   1000 |  0.0004520395 |             f\n",
      "   895 |   895000 |   1000 |  0.0004667349 |             f\n",
      "   896 |   896000 |   1000 |  0.0004661446 |             f\n",
      "   897 |   897000 |   1000 |  0.0004768258 |             f\n",
      "   898 |   898000 |   1000 |  0.0004608833 |             f\n",
      "   899 |   899000 |   1000 |  0.0004561340 |             f\n",
      "   900 |   900000 |   1000 |  0.0004567827 |             f\n",
      "   901 |   901000 |   1000 |  0.0004551800 |             f\n",
      "   902 |   902000 |   1000 |  0.0004485425 |             f\n",
      "   903 |   903000 |   1000 |  0.0004441419 |             f\n",
      "   904 |   904000 |   1000 |  0.0004534818 |             f\n",
      "   905 |   905000 |   1000 |  0.0004494121 |             f\n",
      "   906 |   906000 |   1000 |  0.0004546231 |             f\n",
      "   907 |   907000 |   1000 |  0.0004436657 |             f\n",
      "   908 |   908000 |   1000 |  0.0004452734 |             f\n",
      "   909 |   909000 |   1000 |  0.0004587839 |             f\n",
      "   910 |   910000 |   1000 |  0.0004621306 |             f\n",
      "   911 |   911000 |   1000 |  0.0004518897 |             f\n",
      "   912 |   912000 |   1000 |  0.0004533745 |             f\n",
      "   913 |   913000 |   1000 |  0.0004486328 |             f\n",
      "   914 |   914000 |   1000 |  0.0004638652 |             f\n",
      "   915 |   915000 |   1000 |  0.0004508323 |             f\n",
      "   916 |   916000 |   1000 |  0.0004552520 |             f\n",
      "   917 |   917000 |   1000 |  0.0004534354 |             f\n",
      "   918 |   918000 |   1000 |  0.0004469611 |             f\n",
      "   919 |   919000 |   1000 |  0.0004576395 |             f\n",
      "   920 |   920000 |   1000 |  0.0004574309 |             f\n",
      "   921 |   921000 |   1000 |  0.0004597897 |             f\n",
      "   922 |   922000 |   1000 |  0.0004515506 |             f\n",
      "   923 |   923000 |   1000 |  0.0004596849 |             f\n",
      "   924 |   924000 |   1000 |  0.0004496509 |             f\n",
      "   925 |   925000 |   1000 |  0.0004577266 |             f\n",
      "   926 |   926000 |   1000 |  0.0004584201 |             f\n",
      "   927 |   927000 |   1000 |  0.0004435768 |             f\n",
      "   928 |   928000 |   1000 |  0.0004508165 |             f\n",
      "   929 |   929000 |   1000 |  0.0004417903 |             f\n",
      "   930 |   930000 |   1000 |  0.0004401143 |             f\n",
      "   931 |   931000 |   1000 |  0.0004406957 |             f\n",
      "   932 |   932000 |   1000 |  0.0004499857 |             f\n",
      "   933 |   933000 |   1000 |  0.0004470358 |             f\n",
      "   934 |   934000 |   1000 |  0.0004455607 |             f\n",
      "   935 |   935000 |   1000 |  0.0004459709 |             f\n",
      "   936 |   936000 |   1000 |  0.0004560223 |             f\n",
      "   937 |   937000 |   1000 |  0.0004483642 |             f\n",
      "   938 |   938000 |   1000 |  0.0004468450 |             f\n",
      "   939 |   939000 |   1000 |  0.0004515730 |             f\n",
      "   940 |   940000 |   1000 |  0.0004402606 |             f\n",
      "   941 |   941000 |   1000 |  0.0004367673 |             f\n",
      "   942 |   942000 |   1000 |  0.0004446043 |             f\n",
      "   943 |   943000 |   1000 |  0.0004525948 |             f\n",
      "   944 |   944000 |   1000 |  0.0004585036 |             f\n",
      "   945 |   945000 |   1000 |  0.0004635806 |             f\n",
      "   946 |   946000 |   1000 |  0.0004489041 |             f\n",
      "   947 |   947000 |   1000 |  0.0004564082 |             f\n",
      "   948 |   948000 |   1000 |  0.0004575117 |             f\n",
      "   949 |   949000 |   1000 |  0.0004517932 |             f\n",
      "   950 |   950000 |   1000 |  0.0004460163 |             f\n",
      "   951 |   951000 |   1000 |  0.0004461419 |             f\n",
      "   952 |   952000 |   1000 |  0.0004526947 |             f\n",
      "   953 |   953000 |   1000 |  0.0004454615 |             f\n",
      "   954 |   954000 |   1000 |  0.0004549679 |             f\n",
      "   955 |   955000 |   1000 |  0.0004592663 |             f\n",
      "   956 |   956000 |   1000 |  0.0004492134 |             f\n",
      "   957 |   957000 |   1000 |  0.0004514761 |             f\n",
      "   958 |   958000 |   1000 |  0.0004474925 |             f\n",
      "   959 |   959000 |   1000 |  0.0004503757 |             f\n",
      "   960 |   960000 |   1000 |  0.0004573433 |             f\n",
      "   961 |   961000 |   1000 |  0.0004550282 |             f\n",
      "   962 |   962000 |   1000 |  0.0004505059 |             f\n",
      "   963 |   963000 |   1000 |  0.0004495706 |             f\n",
      "   964 |   964000 |   1000 |  0.0004566427 |             f\n",
      "   965 |   965000 |   1000 |  0.0004562929 |             f\n",
      "   966 |   966000 |   1000 |  0.0004487087 |             f\n",
      "   967 |   967000 |   1000 |  0.0004384269 |             f\n",
      "   968 |   968000 |   1000 |  0.0004400241 |             f\n",
      "   969 |   969000 |   1000 |  0.0004404285 |             f\n",
      "   970 |   970000 |   1000 |  0.0004370589 |             f\n",
      "   971 |   971000 |   1000 |  0.0004458811 |             f\n",
      "   972 |   972000 |   1000 |  0.0004494705 |             f\n",
      "   973 |   973000 |   1000 |  0.0004468816 |             f\n",
      "   974 |   974000 |   1000 |  0.0004339478 |             f\n",
      "   975 |   975000 |   1000 |  0.0004481689 |             f\n",
      "   976 |   976000 |   1000 |  0.0004528482 |             f\n",
      "   977 |   977000 |   1000 |  0.0004548031 |             f\n",
      "   978 |   978000 |   1000 |  0.0004530120 |             f\n",
      "   979 |   979000 |   1000 |  0.0004558696 |             f\n",
      "   980 |   980000 |   1000 |  0.0004610700 |             f\n",
      "   981 |   981000 |   1000 |  0.0004534761 |             f\n",
      "   982 |   982000 |   1000 |  0.0004520649 |             f\n",
      "   983 |   983000 |   1000 |  0.0004459703 |             f\n",
      "   984 |   984000 |   1000 |  0.0004425263 |             f\n",
      "   985 |   985000 |   1000 |  0.0004498916 |             f\n",
      "   986 |   986000 |   1000 |  0.0004521170 |             f\n",
      "   987 |   987000 |   1000 |  0.0004555443 |             f\n",
      "   988 |   988000 |   1000 |  0.0004629176 |             f\n",
      "   989 |   989000 |   1000 |  0.0004550449 |             f\n",
      "   990 |   990000 |   1000 |  0.0004542185 |             f\n",
      "   991 |   991000 |   1000 |  0.0004498041 |             f\n",
      "   992 |   992000 |   1000 |  0.0004500889 |             f\n",
      "   993 |   993000 |   1000 |  0.0004515207 |             f\n",
      "   994 |   994000 |   1000 |  0.0004486558 |             f\n",
      "   995 |   995000 |   1000 |  0.0004434072 |             f\n",
      "   996 |   996000 |   1000 |  0.0004440847 |             f\n",
      "   997 |   997000 |   1000 |  0.0004507511 |             f\n",
      "   998 |   998000 |   1000 |  0.0004453637 |             f\n",
      "   999 |   999000 |   1000 |  0.0004454544 |             f\n",
      "  1000 |  1000000 |   1000 |  0.0004478835 |             f\n",
      "Pareto front points:\n",
      "f1: -0.7215250000000001, f2: 1.4073971336107258, x: [  80.   75. 3000.   20.]\n",
      "f1: 5.306699999999996, f2: 1.139072039072039, x: [  80.  110. 3000.   20.]\n",
      "f1: 4.285747121318406, f2: 1.1731463817746608, x: [  80.          104.89699885 3000.           20.        ]\n",
      "f1: 3.4218326887205857, f2: 1.2046907629755297, x: [  80.          100.37648086 3000.           19.99999997]\n",
      "f1: 0.689791050300419, f2: 1.326215791494553, x: [  80.           84.50392964 3000.           20.        ]\n",
      "f1: 4.26411722771973, f2: 1.1739040621103882, x: [  80.          104.78619851 3000.           20.        ]\n",
      "f1: 2.2346669277538687, f2: 1.2528863583468788, x: [  80.           93.80984336 3000.           19.99999999]\n",
      "f1: 3.9664234947101935, f2: 1.1844943438681448, x: [  79.99999998  103.24916674 3000.           20.        ]\n",
      "f1: 4.037556054145733, f2: 1.1819359462727115, x: [  80.          103.61850656 3000.           20.        ]\n",
      "f1: 2.2194525212871716, f2: 1.2535500416297973, x: [  79.99999997   93.7227011  2999.98873543   20.        ]\n",
      "f1: 0.6749013219128277, f2: 1.3269929851504931, x: [  80.           84.4092463  3000.           19.99999999]\n",
      "f1: 4.303291669380565, f2: 1.1725329595113196, x: [  80.          104.98678588 3000.           20.        ]\n",
      "f1: -0.5160648716454984, f2: 1.3945352052586968, x: [  80.           76.45709627 3000.           20.        ]\n",
      "f1: 4.3161139829029525, f2: 1.1720852942819053, x: [  80.          105.05235758 2999.99999998   20.        ]\n",
      "f1: -0.31079228996456504, f2: 1.3820710847471565, x: [  79.9999976    77.88564252 3000.           20.        ]\n",
      "f1: 4.116508675111263, f2: 1.1791169715018068, x: [  80.          104.02691482 3000.           20.        ]\n",
      "f1: 2.7433329726323428, f2: 1.2314823844547815, x: [  80.           96.67808416 3000.           20.        ]\n",
      "f1: 4.727297146944984, f2: 1.1580138592917193, x: [  79.99999992  107.13381985 3000.           20.        ]\n",
      "f1: 1.250556501181896, f2: 1.2979950936070144, x: [  80.           87.99568209 3000.           20.        ]\n",
      "f1: 3.133329478252639, f2: 1.2158506755977379, x: [  80.           98.82081061 2999.99999999   20.        ]\n",
      "f1: -0.24205311499496365, f2: 1.3779798250882709, x: [  80.           78.35819929 3000.           20.        ]\n",
      "f1: 3.7529691926712716, f2: 1.1922798365403868, x: [  80.          102.13283611 3000.           20.        ]\n",
      "f1: 2.723362048854744, f2: 1.2323004827542898, x: [  80.           96.56707986 3000.           20.        ]\n",
      "f1: 3.779024029997975, f2: 1.191320685558102, x: [  80.          102.26975152 3000.           19.99999999]\n",
      "f1: 0.921487119595469, f2: 1.3143124041999452, x: [  80.           85.9638418  2999.99999997   19.99999972]\n",
      "f1: 1.2370874720905745, f2: 1.2986499576588861, x: [  80.           87.91343923 3000.           19.99999997]\n",
      "f1: 4.101227145683254, f2: 1.1796609075581574, x: [  80.          103.94799134 3000.           20.        ]\n",
      "f1: -0.09114548957242101, f2: 1.369138233288705, x: [  80.         79.385763 3000.         20.      ]\n",
      "f1: 1.3449269203267578, f2: 1.2934370197073588, x: [  80.           88.56977272 3000.           20.        ]\n",
      "f1: 0.25095049031546235, f2: 1.3497749585223366, x: [  80.           81.66730924 3000.           20.        ]\n",
      "f1: 3.120451092203358, f2: 1.2163566613027388, x: [  80.           98.75079625 3000.           19.99999997]\n",
      "f1: 3.6922299556373184, f2: 1.194525588875067, x: [  79.99999293  101.81293743 3000.           19.99999998]\n",
      "f1: 0.34566728654448053, f2: 1.344572632473481, x: [  80.           82.28782426 3000.           20.        ]\n",
      "f1: -0.30155181302434336, f2: 1.3815187006828487, x: [  80.           77.94933623 3000.           20.        ]\n",
      "f1: -0.10296353673188599, f2: 1.3698238198597728, x: [  80.           79.30577179 3000.           20.        ]\n",
      "f1: 3.409496900797719, f2: 1.2051611898201438, x: [  80.         100.3104574 3000.          20.       ]\n",
      "f1: 2.8123653036330754, f2: 1.228668010403029, x: [  80.           97.06080849 3000.           19.99999997]\n",
      "f1: 0.9123295954595665, f2: 1.3147761883276379, x: [  80.           85.90661127 3000.           20.        ]\n",
      "f1: 0.002732987661563083, f2: 1.3637325222789292, x: [  80.           80.01834502 3000.           20.        ]\n",
      "f1: -0.405345389006969, f2: 1.3877657373254029, x: [  79.99999924   77.2309056  3000.           20.        ]\n",
      "f1: 4.630486512703701, f2: 1.1612781679663036, x: [  80.          106.64740843 3000.           20.        ]\n",
      "f1: 4.480428280659901, f2: 1.1663967067245558, x: [  79.99999761  105.88904436 2999.99999994   20.        ]\n",
      "f1: 1.8689867763715604, f2: 1.2690447092004244, x: [  80.           91.69244573 3000.           19.9999999 ]\n",
      "f1: 2.3890391078876205, f2: 1.2462631818327714, x: [  80.          94.6894926 3000.          20.       ]\n",
      "f1: 2.343346876698946, f2: 1.2482117007264941, x: [  79.99999909   94.42998043 3000.           20.        ]\n",
      "f1: -0.5280647539555412, f2: 1.3952755689832619, x: [  80.           76.37275909 3000.           20.        ]\n",
      "f1: 2.444520138124356, f2: 1.2439104743114, x: [  80.           95.00364705 3000.           20.        ]\n",
      "f1: -0.4412518796376863, f2: 1.3899489841422497, x: [  80.           76.98081087 3000.           20.        ]\n",
      "f1: 3.035040311042579, f2: 1.219729718621841, x: [  80.           98.28519142 3000.           20.        ]\n",
      "f1: 2.899807761525321, f2: 1.2251327971685118, x: [  80.           97.54344518 3000.           20.        ]\n",
      "f1: 2.1671052143378624, f2: 1.2558212840207552, x: [  80.           93.42225505 3000.           19.99999999]\n",
      "f1: 4.05207866290576, f2: 1.1814157964801935, x: [  80.          103.69375023 3000.           20.        ]\n",
      "f1: -0.4120693297103864, f2: 1.3881736912937246, x: [  80.           77.18413453 3000.           20.        ]\n",
      "f1: 4.170832285497927, f2: 1.1771898915285781, x: [  79.99999702  104.30699053 3000.           20.        ]\n",
      "f1: 0.7854081344700484, f2: 1.3212604752044002, x: [  80.           85.10944577 2999.99999997   20.        ]\n",
      "f1: 2.176278460997485, f2: 1.2554214781307234, x: [  80.           93.47497446 3000.           20.        ]\n",
      "f1: 2.8775866235732313, f2: 1.2260280533990173, x: [  80.          97.4210227 3000.          20.       ]\n",
      "f1: -0.0702583080579062, f2: 1.3679293250320403, x: [  79.99999995   79.52694241 3000.           20.        ]\n",
      "f1: 3.0803822148839224, f2: 1.2179353073063193, x: [  80.           98.53264037 3000.           20.        ]\n",
      "f1: 4.7397181872704826, f2: 1.1575971798472942, x: [  79.99999831  107.19606666 3000.           20.        ]\n",
      "f1: 0.33679621743077875, f2: 1.3450570545407463, x: [  80.           82.22990626 3000.           20.        ]\n",
      "f1: 3.3760080361241758, f2: 1.2064412907744126, x: [  80.          100.13099925 3000.           20.        ]\n",
      "f1: -0.63545529584384, f2: 1.4019606834185991, x: [  80.           75.61381264 3000.           20.        ]\n",
      "f1: -0.714429153278986, f2: 1.4069462468803997, x: [  80.           75.05079445 3000.           20.        ]\n",
      "f1: 3.343940554764044, f2: 1.207671181176173, x: [  80.           99.95885595 3000.           20.        ]\n",
      "f1: 0.29815060245743835, f2: 1.3471741522758243, x: [  80.           81.97711689 3000.           20.        ]\n",
      "f1: 4.902176031713812, f2: 1.152190886943617, x: [  80.          108.00692201 3000.           20.        ]\n",
      "f1: 4.293447704252749, f2: 1.1728770158700015, x: [  80.          104.93641731 3000.           19.99999996]\n",
      "f1: 1.7751177388909936, f2: 1.2733034219115944, x: [  80.           91.14098179 3000.           19.99999997]\n",
      "f1: 3.195168763244688, f2: 1.2134304850413156, x: [  80.           99.1563162  3000.           19.99999999]\n",
      "f1: -0.009976688289096636, f2: 1.3644602100831171, x: [  79.99999989   79.93299621 3000.           20.        ]\n",
      "f1: 0.080965833970099, f2: 1.359281637619066, x: [  80.           80.54170674 3000.           20.        ]\n",
      "f1: 0.08961111407166249, f2: 1.3587927460097182, x: [  80.           80.59933337 3000.           20.        ]\n",
      "f1: 0.9868087402738737, f2: 1.3110196008709791, x: [  80.           86.37097279 3000.           20.        ]\n",
      "f1: 5.185326531046979, f2: 1.142958038876943, x: [  80.          109.40580915 3000.           20.        ]\n",
      "f1: 4.619706095510157, f2: 1.16164349372806, x: [  80.          106.59310638 3000.           20.        ]\n",
      "f1: -0.0233233261814078, f2: 1.3652257582720293, x: [  80.           79.84327205 3000.           20.        ]\n",
      "f1: 0.9659010401784783, f2: 1.3120705773475552, x: [  80.           86.2408702  3000.           19.99999997]\n",
      "f1: 4.9221354015965, f2: 1.1515322332831859, x: [  80.          108.10612303 3000.           20.        ]\n",
      "f1: -0.6283225501271648, f2: 1.4015133207842014, x: [  80.           75.66445693 3000.           20.        ]\n",
      "f1: 0.2859305120987575, f2: 1.3478459040664732, x: [  80.           81.89702025 3000.           19.99999999]\n",
      "f1: 4.325820527776787, f2: 1.1717467746189467, x: [  80.          105.10196844 2999.99999999   19.99999999]\n",
      "f1: 3.0692078558887954, f2: 1.2183771516952921, x: [  79.99996635   98.47168781 2999.99999999   20.        ]\n",
      "f1: 0.7624099695460363, f2: 1.322446761778083, x: [  80.         84.964199 3000.         20.      ]\n",
      "f1: 3.6156418049371033, f2: 1.1973766620320356, x: [  80.          101.40814051 3000.           20.        ]\n",
      "f1: 3.4339457175075054, f2: 1.204229403938276, x: [  80.          100.44126979 2999.99999996   20.        ]\n",
      "f1: 3.086207986097643, f2: 1.217705369968281, x: [  80.           98.56438891 3000.           20.        ]\n",
      "f1: 0.4578052489788237, f2: 1.3384985770214268, x: [  80.           83.01647404 2999.99999998   20.        ]\n",
      "f1: 3.7898303105995885, f2: 1.1909236034297062, x: [  80.          102.32648361 3000.           20.        ]\n",
      "f1: 2.0844304160793534, f2: 1.259443381574022, x: [  80.           92.94576694 3000.           20.        ]\n",
      "f1: 3.152658545930146, f2: 1.2150925225585483, x: [  80.           98.92580163 3000.           20.        ]\n",
      "f1: 1.3591461431796548, f2: 1.2927547759635711, x: [  80.           88.65595132 3000.           20.        ]\n",
      "f1: 3.7675828154508233, f2: 1.191741563750145, x: [  80.          102.20965176 3000.           19.99999997]\n",
      "f1: 4.65527403785084, f2: 1.1604395644260472, x: [  79.99999997  106.7721609  3000.           20.        ]\n",
      "f1: 4.212007986197188, f2: 1.1757358821554411, x: [  80.          104.51878367 3000.           20.        ]\n",
      "f1: 2.800432522105815, f2: 1.2291530347526505, x: [  79.9999978    96.99475772 3000.           19.99999998]\n",
      "f1: -0.5853439501481927, f2: 1.3988278505877134, x: [  80.           75.96890122 3000.           20.        ]\n",
      "f1: 2.318446818965261, f2: 1.2492777099760755, x: [  79.99999997   94.28825934 3000.           20.        ]\n",
      "f1: 1.7345470838619084, f2: 1.2751585674239034, x: [  80.           90.90160096 3000.           20.        ]\n",
      "f1: -0.34950583101846744, f2: 1.3843931763070778, x: [  80.           77.61823848 3000.           20.        ]\n",
      "f1: 0.8249058790261306, f2: 1.319231279370009, x: [  80.           85.35832024 3000.           20.        ]\n",
      "f1: 1.8898106959397136, f2: 1.2681062349203251, x: [  80.           91.8143336  3000.           19.99999999]\n",
      "f1: 2.8856328759004244, f2: 1.2257036375538184, x: [  80.           97.46536952 3000.           20.        ]\n",
      "f1: -0.17917259759004492, f2: 1.3742725575316281, x: [  79.99999992   78.78799538 3000.           20.        ]\n",
      "f1: -0.04845544974685376, f2: 1.3666712094226865, x: [  80.           79.67404427 3000.           19.99999999]\n",
      "f1: -0.01882901979881773, f2: 1.364967809369276, x: [  80.           79.87349679 3000.           20.        ]\n",
      "f1: -0.6415048152758928, f2: 1.4023404837516589, x: [  80.           75.57083293 3000.           20.        ]\n",
      "f1: 0.24350453212949383, f2: 1.350186844820239, x: [  79.9999954    81.61832427 3000.           20.        ]\n",
      "f1: 0.2752547690131047, f2: 1.3484336719578531, x: [  80.           81.82698187 3000.           19.99999999]\n",
      "f1: 4.930407396645071, f2: 1.1512596125801977, x: [  80.         108.1472094 3000.          20.       ]\n",
      "f1: -0.6228464757662174, f2: 1.401170203865089, x: [  79.99999925   75.70331466 3000.           20.        ]\n",
      "f1: 4.239810321850511, f2: 1.174757393254498, x: [  80.          104.66154506 2999.99999998   20.        ]\n",
      "f1: 2.4004976578529162, f2: 1.2457761140421577, x: [  79.99999816   94.75445901 3000.           20.        ]\n",
      "f1: 0.7704577580476897, f2: 1.3220312425950809, x: [  80.           85.01505369 2999.99999997   20.        ]\n",
      "f1: 0.15712294573151658, f2: 1.3549949647945962, x: [  80.           81.04793602 3000.           20.        ]\n",
      "f1: -0.18718536996552995, f2: 1.3747431174371847, x: [  79.99999988   78.73335749 3000.           20.        ]\n",
      "f1: 2.3630076784434046, f2: 1.2473720573219909, x: [  80.           94.54173306 3000.           20.        ]\n",
      "f1: 4.860099334530127, f2: 1.1535833625554464, x: [  80.          107.7974955  2999.99999996   20.        ]\n",
      "f1: 0.04770171511290786, f2: 1.3611682055287158, x: [  80.           80.31959333 3000.           20.        ]\n",
      "f1: 1.2222987192805297, f2: 1.2993702345744056, x: [  80.           87.82304931 3000.           20.        ]\n",
      "f1: -0.4190771075071047, f2: 1.388599308815998, x: [  80.           77.13535812 3000.           20.        ]\n",
      "f1: 4.644803670427665, f2: 1.1607935576846296, x: [  80.          106.71948267 3000.           20.        ]\n",
      "f1: 5.0157597071837605, f2: 1.1484586449808984, x: [  80.          108.57023995 3000.           19.99999999]\n",
      "f1: 4.74553783193634, f2: 1.157402091873875, x: [  80.          107.22522063 3000.           20.        ]\n",
      "f1: 4.450161573059363, f2: 1.1674378851372844, x: [  80.          105.73542575 3000.           19.9999998 ]\n",
      "f1: 1.6915185615035866, f2: 1.277135790844996, x: [  80.           90.64702712 3000.           19.99999999]\n",
      "f1: 1.030083106826939, f2: 1.3088530905580344, x: [  80.           86.63963607 3000.           19.99999999]\n",
      "f1: 2.3272810360260907, f2: 1.2488991724224674, x: [  79.99999909   94.33856402 3000.           20.        ]\n",
      "f1: 3.1598813814537485, f2: 1.2148096100218784, x: [  80.           98.96500582 3000.           20.        ]\n",
      "f1: -0.06312148255627716, f2: 1.3675170756277164, x: [  80.           79.57512388 3000.           19.99999998]\n",
      "f1: 3.7464832313140164, f2: 1.1925190252049196, x: [  79.99999691  102.09872211 3000.           20.        ]\n",
      "f1: -0.16333333115024706, f2: 1.3733439584748521, x: [  80.           78.89588966 3000.           20.        ]\n",
      "f1: 5.216246518677347, f2: 1.1419640608544408, x: [  80.          109.55748567 3000.           19.99999999]\n",
      "f1: 2.3513385900097528, f2: 1.2478701744650251, x: [  79.99999997   94.47542197 3000.           20.        ]\n",
      "f1: -0.33601095088483574, f2: 1.3835822367408488, x: [  80.          77.7115563 3000.          20.       ]\n",
      "f1: 2.9142966510926906, f2: 1.2245502000384254, x: [  80.           97.62318584 3000.           20.        ]\n",
      "f1: 5.22648812275522, f2: 1.1416354335539245, x: [  80.          109.60767907 3000.           20.        ]\n",
      "f1: 4.96137250328325, f2: 1.150240921978645, x: [  80.          108.30087235 3000.           20.        ]\n",
      "f1: 3.737696360568948, f2: 1.1928432292514655, x: [  80.         102.0524936 3000.          20.       ]\n",
      "f1: 1.9164376343504377, f2: 1.2669095528359486, x: [  80.           91.96995297 3000.           19.9999997 ]\n",
      "f1: 4.679564541440807, f2: 1.1596196550784443, x: [  80.          106.89427076 3000.           19.99999997]\n",
      "f1: 3.204917168020636, f2: 1.2130503816903015, x: [  80.           99.20910209 2999.99999999   20.        ]\n",
      "f1: 1.7090638175401471, f2: 1.2763283509304286, x: [  80.           90.75091805 3000.           20.        ]\n",
      "f1: 2.123403196588836, f2: 1.2577316963582128, x: [  80.           93.17068636 2999.99999999   19.99999999]\n",
      "f1: 1.4087561203699261, f2: 1.2903836793570542, x: [  80.           88.95596927 3000.           20.        ]\n",
      "f1: 1.291356601451033, f2: 1.2960179952323863, x: [  80.          88.2443427 3000.          20.       ]\n",
      "f1: 2.773701403989219, f2: 1.2302417242313797, x: [  80.           96.84663706 3000.           20.        ]\n",
      "f1: 2.291393901858234, f2: 1.2504392614323085, x: [  79.99999996   94.13404238 3000.           20.        ]\n",
      "f1: -0.4700197164359145, f2: 1.3917065260152441, x: [  80.           76.77984963 3000.           20.        ]\n",
      "f1: 5.09719626918574, f2: 1.1458063790908701, x: [  80.          108.97233199 3000.           20.        ]\n",
      "f1: 4.24896760370484, f2: 1.1744356791589703, x: [  80.         104.7085239 3000.          20.       ]\n",
      "f1: 2.694354236727403, f2: 1.233491916707723, x: [  80.           96.40561819 3000.           20.        ]\n",
      "f1: 0.8333977076582088, f2: 1.3187963530742597, x: [  80.           85.41173236 3000.           20.        ]\n",
      "f1: -0.48091763864104703, f2: 1.3923742746916155, x: [  80.           76.70358336 2999.99999997   20.        ]\n",
      "f1: 4.891076655829574, f2: 1.1525576848850019, x: [  80.          107.95171702 3000.           20.        ]\n",
      "f1: -0.4574808586397207, f2: 1.3909395608414559, x: [  80.           76.86750595 3000.           20.        ]\n",
      "f1: 4.7981676623532845, f2: 1.155642742880947, x: [  80.          107.48850343 3000.           20.        ]\n",
      "f1: 0.48336246977095865, f2: 1.33712692318054, x: [  80.           83.18164657 3000.           19.99999999]\n",
      "f1: 2.5884637911959, f2: 1.23787310114256, x: [  79.99999739   95.81390508 3000.           20.        ]\n",
      "f1: -0.19142809230539184, f2: 1.3749925464923891, x: [  79.99999689   78.70440862 3000.           20.        ]\n",
      "f1: 1.9081610366150046, f2: 1.2672811170402163, x: [  80.           91.92160904 2999.99999999   20.        ]\n",
      "f1: 0.05397982370092796, f2: 1.3608114770681443, x: [  80.           80.36156094 3000.           19.99999999]\n",
      "f1: 0.06459302345093162, f2: 1.3602091294097156, x: [  80.           80.43245776 2999.99999979   20.        ]\n",
      "f1: 3.2762088078101166, f2: 1.2102822686827712, x: [  80.           99.59428335 3000.           20.        ]\n",
      "f1: 0.11416796057827135, f2: 1.3574072424421073, x: [  79.99999983   80.76279688 3000.           20.        ]\n",
      "f1: 4.335889109238524, f2: 1.171395959304977, x: [  80.          105.15340495 3000.           20.        ]\n",
      "f1: 1.2729105754906733, f2: 1.2969106319691261, x: [  79.99999991   88.13200822 3000.           20.        ]\n",
      "f1: 3.81876248027859, f2: 1.1898625710604978, x: [  80.          102.47822058 3000.           20.        ]\n",
      "f1: 2.2694032196079137, f2: 1.2513860519165414, x: [  80.           94.00849666 3000.           20.        ]\n",
      "f1: 3.505725896712794, f2: 1.2015071046932433, x: [  80.          100.82434608 3000.           20.        ]\n",
      "f1: 2.6602348643647886, f2: 1.2348980891530688, x: [  80.           96.21535807 3000.           20.        ]\n",
      "f1: 3.4486358377044843, f2: 1.203670656079643, x: [  80.          100.51978682 3000.           19.99999997]\n",
      "f1: 3.8949305950746838, f2: 1.187083726043846, x: [  80.          102.87661989 3000.           20.        ]\n",
      "f1: -0.4762222364742454, f2: 1.392086441481413, x: [  80.           76.73645221 3000.           20.        ]\n",
      "f1: 4.59654210935647, f2: 1.162429720091267, x: [  80.          106.47633339 3000.           19.99999999]\n",
      "f1: 0.35271238676975586, f2: 1.3441883332729283, x: [  80.           82.33379174 2999.99999993   20.        ]\n",
      "f1: 0.7474032656692753, f2: 1.3232227325263435, x: [  80.           84.86928893 3000.           20.        ]\n",
      "f1: 4.971848957181461, f2: 1.1498969193350617, x: [  80.          108.35281194 3000.           20.        ]\n",
      "f1: 2.818575396409569, f2: 1.2284159614994106, x: [  79.99999116   97.09515681 3000.           19.99999998]\n",
      "f1: 5.2905943075754776, f2: 1.1395852674069953, x: [  80.          109.92133848 3000.           20.        ]\n",
      "f1: 3.39159267592812, f2: 1.2058450275249881, x: [  80.          100.21455327 3000.           20.        ]\n",
      "f1: 1.4186016969977295, f2: 1.2899148075742863, x: [  79.99999988   89.01539036 3000.           20.        ]\n",
      "f1: -0.032167242743281886, f2: 1.3657338263170398, x: [  80.           79.78376225 3000.           20.        ]\n",
      "f1: 2.596592183884002, f2: 1.2375349701045055, x: [  80.           95.85945777 3000.           20.        ]\n",
      "f1: 0.23147414037376673, f2: 1.3508530119171114, x: [  80.           81.53912914 2999.99999999   19.99999998]\n",
      "f1: 3.835005137585262, f2: 1.1892682346768582, x: [  80.          102.56330806 3000.           19.99999998]\n",
      "f1: -0.23289847631340638, f2: 1.377438010981675, x: [  80.           78.42091889 3000.           20.        ]\n",
      "f1: 2.926609786007401, f2: 1.2240557941136556, x: [  80.           97.69090092 3000.           20.        ]\n",
      "f1: 2.936910875832203, f2: 1.2236426730470515, x: [  80.           97.74751488 3000.           20.        ]\n",
      "f1: 4.639226389791405, f2: 1.1609822616598986, x: [  80.          106.69141178 2999.99999999   20.        ]\n",
      "f1: 3.558672208144703, f2: 1.1995117545476632, x: [  80.          101.10597969 2999.9999998    19.99999999]\n",
      "f1: 1.0026877793035427, f2: 1.3102232536821603, x: [  80.           86.46965269 3000.           20.        ]\n",
      "f1: 0.01425918455128593, f2: 1.3630737132097226, x: [  80.           80.09566772 3000.           20.        ]\n",
      "f1: 0.7955681949308429, f2: 1.320737518683799, x: [  79.99999999   85.17353356 3000.           20.        ]\n",
      "f1: 0.39547373647552136, f2: 1.3418635596118969, x: [  79.99999996   82.61224978 3000.           20.        ]\n",
      "f1: 1.3650506554444015, f2: 1.2924718220796414, x: [  80.           88.69171226 3000.           20.        ]\n",
      "f1: 3.059802496781792, f2: 1.2187486934786649, x: [  80.          98.4204057 3000.          20.       ]\n",
      "f1: 2.1389247698608966, f2: 1.2570520944608767, x: [  80.          93.2601133 3000.          20.       ]\n",
      "f1: 5.046273524937559, f2: 1.147555769944111, x: [  79.99088974  108.71437236 3000.           20.        ]\n",
      "f1: 0.3628154505463897, f2: 1.3436378629466077, x: [  80.           82.39966689 3000.           19.99999999]\n",
      "f1: 5.002879036706271, f2: 1.1488799484940797, x: [  80.          108.50650531 3000.           20.        ]\n",
      "f1: -0.5368630244661822, f2: 1.3958192405705443, x: [  80.           76.31086415 3000.           20.        ]\n",
      "f1: 1.090546183879555, f2: 1.3058456691014704, x: [  80.           87.01362403 3000.           20.        ]\n",
      "f1: 2.018635505300443, f2: 1.2623504041493534, x: [  80.           92.56481171 3000.           19.99999999]\n",
      "f1: -0.49312311921823326, f2: 1.393123420017085, x: [  80.           76.61807636 3000.           20.        ]\n",
      "f1: -0.34217585889217866, f2: 1.383952503208967, x: [  80.           77.66893954 3000.           20.        ]\n",
      "f1: 0.42075696290398773, f2: 1.3404952604426488, x: [  80.           82.77645126 2999.99999998   20.        ]\n",
      "f1: 1.9999242627496996, f2: 1.2631811277097587, x: [  80.           92.45618617 3000.           20.        ]\n",
      "f1: 0.873728916433845, f2: 1.3167371474379117, x: [  79.99999986   85.66495382 3000.           20.        ]\n",
      "f1: 1.741317515627234, f2: 1.2748483676000049, x: [  79.99999991   90.94159256 3000.           20.        ]\n",
      "f1: 2.753901887703062, f2: 1.2310501466135302, x: [  79.99999997   96.73677776 2999.99999997   20.        ]\n",
      "f1: 5.066075232954102, f2: 1.1468176319573244, x: [  80.          108.81884765 3000.           20.        ]\n",
      "f1: 2.582901200651739, f2: 1.2381046147458012, x: [  80.          95.7827227 3000.          20.       ]\n",
      "f1: 4.755817509159828, f2: 1.1570577815542205, x: [  80.          107.2766959  2999.99999999   20.        ]\n",
      "f1: 0.1057779177175145, f2: 1.3578800800197242, x: [  80.           80.70698561 3000.           20.        ]\n",
      "f1: 3.267169232465817, f2: 1.2106321287708068, x: [  80.           99.54552598 3000.           20.        ]\n",
      "f1: 4.539228912454223, f2: 1.164382866868747, x: [  79.9999544   106.18682298 2999.99999994   20.        ]\n",
      "f1: 5.07225538938066, f2: 1.1466165863032907, x: [  80.          108.8493445  3000.           19.99999999]\n",
      "f1: 2.7000673072932315, f2: 1.2332569691345148, x: [  80.           96.43743934 3000.           20.        ]\n",
      "f1: 4.354998892008906, f2: 1.1707310510864704, x: [  80.          105.25096034 3000.           20.        ]\n",
      "f1: 0.059308591784342606, f2: 1.3605089336847664, x: [  80.           80.39716525 3000.           20.        ]\n",
      "f1: 1.631022590367061, f2: 1.2799327034210344, x: [  80.           90.28789489 3000.           20.        ]\n",
      "f1: 0.9463876207957227, f2: 1.3130539847908194, x: [  80.           86.11926653 2999.99999997   19.99999978]\n",
      "f1: 0.9576989774760526, f2: 1.312483629854023, x: [  80.           86.18977748 3000.           20.        ]\n",
      "f1: 0.9346257857947576, f2: 1.3136478931287592, x: [  80.           86.04588605 3000.           20.        ]\n",
      "f1: 1.108345848500761, f2: 1.304964640030534, x: [  80.           87.12341611 2999.99999978   19.99999999]\n",
      "f1: 0.568449664377903, f2: 1.332593616828235, x: [  79.99999999   83.72920434 3000.           20.        ]\n",
      "f1: -0.19859050682168536, f2: 1.3754138247408394, x: [  80.           78.65552228 3000.           20.        ]\n",
      "f1: 0.22564668865487666, f2: 1.3511761275353984, x: [  80.           81.50073763 3000.           20.        ]\n",
      "f1: 1.8089940715922272, f2: 1.271761116460559, x: [  80.           91.34038317 3000.           20.        ]\n",
      "f1: 1.8208907365085278, f2: 1.2712209389046447, x: [  80.           91.41030562 3000.           19.99999997]\n",
      "f1: -0.6164080467810895, f2: 1.400767118703681, x: [  80.           75.74897739 3000.           20.        ]\n",
      "f1: -0.04314238452941626, f2: 1.366365207391854, x: [  80.           79.70984987 3000.           20.        ]\n",
      "f1: 2.183402480014064, f2: 1.255111271649556, x: [  79.99999999   93.51589628 3000.           20.        ]\n",
      "f1: 1.0459262556394169, f2: 1.3080628628996087, x: [  79.99999926   86.73778742 3000.           20.        ]\n",
      "f1: 0.47487647951237594, f2: 1.3375818490749538, x: [  80.           83.12683927 3000.           19.99999999]\n",
      "f1: 1.2967265737659597, f2: 1.2957585115815573, x: [  80.           88.27701842 3000.           20.        ]\n",
      "f1: 1.3028250394598433, f2: 1.2954640330164553, x: [  80.           88.31411228 3000.           20.        ]\n",
      "f1: 0.284577275117441, f2: 1.347920360607208, x: [  80.           81.88814563 2999.99999978   20.        ]\n",
      "f1: 2.4234662665344953, f2: 1.2448015767904785, x: [  79.99999999   94.88455457 3000.           20.        ]\n",
      "f1: 1.135921119991642, f2: 1.3036035981760763, x: [  80.           87.2932335  3000.           19.99999999]\n",
      "f1: 2.5102170484440256, f2: 1.2411432371758335, x: [  79.99999123   95.37430216 3000.           19.99999998]\n",
      "f1: -0.2707155547476401, f2: 1.3796808241394247, x: [  80.           78.16150377 3000.           20.        ]\n",
      "f1: 1.9217517133801845, f2: 1.2666711443628813, x: [  80.           92.00097903 3000.           20.        ]\n",
      "f1: 3.602730307964105, f2: 1.197859482892613, x: [  80.          101.33973823 3000.           19.99999999]\n",
      "f1: 0.9720173510145532, f2: 1.311762852066071, x: [  79.99999905   86.27894965 3000.           20.        ]\n",
      "f1: 3.3704244866527198, f2: 1.2066551473823324, x: [  80.          100.10104716 3000.           20.        ]\n",
      "f1: 2.4337602633260538, f2: 1.2443656259069407, x: [  80.           94.94280184 3000.           19.99999999]\n",
      "f1: 0.601637741471897, f2: 1.3308391460900402, x: [  80.           83.94180981 3000.           19.99999999]\n",
      "f1: 0.584072160808952, f2: 1.3317667885761548, x: [  80.           83.82935047 3000.           20.        ]\n",
      "f1: 4.254851325785278, f2: 1.1742291227043309, x: [  79.99999987  104.73869745 2999.99999999   20.        ]\n",
      "f1: 1.7689876627195495, f2: 1.2735831613028112, x: [  80.           91.10485256 3000.           19.99999999]\n",
      "f1: 0.023006805053286384, f2: 1.3625744285063675, x: [  80.           80.15430075 3000.           19.99999999]\n",
      "f1: 4.0292949469637795, f2: 1.1822321935700844, x: [  79.99999693  103.57567784 3000.           20.        ]\n",
      "f1: 2.789379623609871, f2: 1.229602799934963, x: [  79.99999965   96.93354036 3000.           20.        ]\n",
      "f1: 4.096102492787314, f2: 1.17984349685188, x: [  80.          103.92151098 3000.           20.        ]\n",
      "f1: 1.9879584306285403, f2: 1.2637133113100807, x: [  80.           92.38665324 3000.           19.99999999]\n",
      "f1: 2.0272803377089157, f2: 1.2619672006983729, x: [  80.           92.61495507 3000.           19.99999999]\n",
      "f1: 1.4506645740906592, f2: 1.2883917449412794, x: [  80.           89.20862581 3000.           20.        ]\n",
      "f1: 0.33132832261873935, f2: 1.345355928161977, x: [  80.           82.19418679 3000.           20.        ]\n",
      "f1: 0.32118488223658087, f2: 1.3459109499865511, x: [  80.           82.12788279 3000.           20.        ]\n",
      "f1: 2.868747160107097, f2: 1.2263847742200038, x: [  79.9999998    97.37228067 2999.99999998   20.        ]\n",
      "f1: -0.22258180797003893, f2: 1.3768282756391736, x: [  80.           78.49153965 3000.           20.        ]\n",
      "f1: 3.920727102045772, f2: 1.1861473117861876, x: [  80.          103.01119991 3000.           19.99999999]\n",
      "f1: 0.8843311339805036, f2: 1.3161975806416617, x: [  80.           85.73139637 3000.           20.        ]\n",
      "f1: 3.9549143085755367, f2: 1.184909965848874, x: [  80.          103.18928364 3000.           20.        ]\n",
      "f1: 3.8718888879417794, f2: 1.1879225357420224, x: [  79.99996635  102.7562364  3000.           20.        ]\n",
      "f1: 0.436309290156131, f2: 1.33965588064528, x: [  80.           82.87729396 3000.           19.99999999]\n",
      "f1: 2.200245925681453, f2: 1.2543835768466451, x: [  79.99999993   93.61257728 2999.98866422   20.        ]\n",
      "f1: 4.138220259478807, f2: 1.1783455471956756, x: [  80.          104.13894434 3000.           19.99999996]\n",
      "f1: 2.5636103312654415, f2: 1.2389087013733304, x: [  80.           95.67449701 3000.           20.        ]\n",
      "f1: 1.5143608997961533, f2: 1.285383420130438, x: [  80.           89.59127204 3000.           20.        ]\n",
      "f1: 0.5226885058571331, f2: 1.3350253608484701, x: [  80.           83.43516625 3000.           19.99999999]\n",
      "f1: 1.4378878799877193, f2: 1.2889979608317346, x: [  80.           89.13167392 2999.99999998   20.        ]\n",
      "f1: 2.192615333173985, f2: 1.2547104795115447, x: [  79.99999997   93.56879023 2999.99999997   20.        ]\n",
      "f1: 4.823596331016767, f2: 1.1547957548101515, x: [  80.          107.61548056 3000.           20.        ]\n",
      "f1: 2.711457584076668, f2: 1.2327889818965785, x: [  80.           96.50085058 3000.           20.        ]\n",
      "f1: 2.3574966823415897, f2: 1.2476072246756325, x: [  79.99999995   94.51042188 3000.           20.        ]\n",
      "f1: 1.6097831565487828, f2: 1.2809194304399139, x: [  80.           90.16146845 3000.           20.        ]\n",
      "f1: 3.331765958646628, f2: 1.2081391768156267, x: [  80.           99.89342311 3000.           20.        ]\n",
      "f1: 0.8102001725000642, f2: 1.3199855829740448, x: [  80.           85.26574477 3000.           20.        ]\n",
      "f1: 4.069455633673021, f2: 1.1807943786931143, x: [  80.          103.78371107 3000.           20.        ]\n",
      "f1: 1.38130778405287, f2: 1.2916938013818762, x: [  80.           88.79009984 2999.99999998   20.        ]\n",
      "f1: -0.11612448873139547, f2: 1.3705886616531884, x: [  80.           79.21659597 3000.           20.        ]\n",
      "f1: 4.7907594202260855, f2: 1.155889873695126, x: [  80.          107.45148242 3000.           20.        ]\n",
      "f1: 3.8622921231330967, f2: 1.1882719186040114, x: [  80.          102.70609274 3000.           20.        ]\n",
      "f1: 5.172556290255213, f2: 1.1433693680668724, x: [  80.          109.34310396 3000.           20.        ]\n",
      "f1: 5.24656303395722, f2: 1.1409921567388415, x: [  79.99999995  109.70599821 3000.           20.        ]\n",
      "f1: 2.3719743854702275, f2: 1.2469897353654202, x: [  80.           94.59265592 3000.           20.        ]\n",
      "f1: 0.9052659991428992, f2: 1.3151343075108166, x: [  80.           85.86244088 3000.           20.        ]\n",
      "f1: 5.29849636792388, f2: 1.139333366012389, x: [  80.          109.95993982 3000.           20.        ]\n",
      "f1: 4.912953741875355, f2: 1.1518350761313656, x: [  80.          108.06050014 3000.           19.99999999]\n",
      "f1: 1.3711853473253006, f2: 1.2921780521949782, x: [  80.           88.72885202 3000.           20.        ]\n",
      "f1: 3.3010365011257874, f2: 1.2093230359810951, x: [  80.           99.72807551 3000.           20.        ]\n",
      "f1: 2.1022397883527133, f2: 1.2586602522980967, x: [  80.           93.04861571 3000.           20.        ]\n",
      "f1: 2.2849600166152193, f2: 1.2507160302370417, x: [  80.           94.09732847 3000.           19.99999992]\n",
      "f1: 5.053051833799409, f2: 1.1472416640114094, x: [  80.          108.75455388 3000.           20.        ]\n",
      "f1: -0.6517186716303609, f2: 1.402982515285366, x: [  80.           75.49821153 3000.           20.        ]\n",
      "f1: 3.551158573161823, f2: 1.1997942649982853, x: [  80.          101.06606072 3000.           20.        ]\n",
      "f1: 5.058109244647474, f2: 1.1470769390863496, x: [  80.          108.77952576 3000.           20.        ]\n",
      "f1: 1.8801881006495411, f2: 1.2685396134218734, x: [  80.           91.75803012 3000.           20.        ]\n",
      "f1: 1.0828725403703863, f2: 1.3062260953722686, x: [  80.           86.96624863 3000.           20.        ]\n",
      "f1: -0.3186675384105801, f2: 1.382542362055184, x: [  80.           77.83132262 2999.99999999   20.        ]\n",
      "f1: 0.35720489196111715, f2: 1.343943464186662, x: [  80.           82.36309079 2999.99999999   20.        ]\n",
      "f1: -0.2872242371003689, f2: 1.3806637419197116, x: [  80.           78.04798823 3000.           20.        ]\n",
      "f1: 1.3415489110238752, f2: 1.2935992724248777, x: [  80.           88.54928726 3000.           19.99999999]\n",
      "f1: 0.14719443861991457, f2: 1.3555512646512342, x: [  80.           80.98211893 3000.           20.        ]\n",
      "f1: 4.956006948511522, f2: 1.150417231874036, x: [  80.          108.27426165 3000.           20.        ]\n",
      "f1: 0.6334977360529657, f2: 1.3291620534000819, x: [  79.99999972   84.14540184 2999.99999997   20.        ]\n",
      "f1: 0.4022737092725157, f2: 1.3414950971643198, x: [  80.           82.65644418 3000.           20.        ]\n",
      "f1: -0.5742622638664123, f2: 1.3981382254520747, x: [  80.           76.04720209 3000.           20.        ]\n",
      "f1: 0.5388510126920308, f2: 1.334164809225084, x: [  80.           83.53913657 3000.           20.        ]\n",
      "f1: 1.1931873243176476, f2: 1.3007919332470081, x: [  80.           87.64484605 3000.           19.99999999]\n",
      "f1: 2.5461126760967216, f2: 1.2396395499476938, x: [  79.99999695   95.57622307 3000.           20.        ]\n",
      "f1: 0.49937615299026855, f2: 1.336269838428991, x: [  80.           83.28497371 3000.           20.        ]\n",
      "f1: 4.870501611653067, f2: 1.153238611339725, x: [  80.          107.84930814 3000.           20.        ]\n",
      "f1: -0.2802405611270106, f2: 1.3802476517588997, x: [  80.           78.0960289  2999.99999999   20.        ]\n",
      "f1: 0.701772993249903, f2: 1.3255963393378571, x: [  80.           84.58004549 2999.98897084   20.        ]\n",
      "f1: -0.6788439134097589, f2: 1.4046923948692562, x: [  80.           75.30500877 3000.           20.        ]\n",
      "f1: -0.11154337091946444, f2: 1.3703222706675975, x: [  80.           79.24764804 3000.           20.        ]\n",
      "f1: 0.5781320850819042, f2: 1.3320809698471296, x: [  80.           83.79128644 3000.           20.        ]\n",
      "f1: 3.7244854361876203, f2: 1.1933312530196156, x: [  80.          101.98294668 3000.           20.        ]\n",
      "f1: 1.2305276915682344, f2: 1.298969285598435, x: [  80.           87.87335685 3000.           19.99999999]\n",
      "f1: -0.05573199277552922, f2: 1.3670906662542004, x: [  80.           79.62498034 3000.           20.        ]\n",
      "f1: -0.664946590914382, f2: 1.4038154806393497, x: [  80.           75.40405595 2999.99999999   20.        ]\n",
      "f1: 1.712659249467674, f2: 1.276163093737675, x: [  80.           90.77219304 2999.99999999   20.        ]\n",
      "f1: 1.063961112878909, f2: 1.3071652017889404, x: [  80.           86.84938327 3000.           20.        ]\n",
      "f1: 0.5889108118225856, f2: 1.331511044509364, x: [  80.          83.8603438 3000.          20.       ]\n",
      "f1: -0.5691724126120207, f2: 1.39782186174653, x: [  80.          76.0831389 3000.          20.       ]\n",
      "f1: -0.5983005767940766, f2: 1.3996356079136762, x: [  80.           75.87724995 3000.           20.        ]\n",
      "f1: -0.13551158327266646, f2: 1.3717179481507351, x: [  80.           79.08504997 3000.           19.9999998 ]\n",
      "f1: -0.2957428721674356, f2: 1.3811718545040024, x: [  80.           77.98934852 3000.           20.        ]\n",
      "f1: 2.0382390204643066, f2: 1.2614819735736145, x: [  80.           92.67848064 2999.99999979   20.        ]\n",
      "f1: 1.5040025823120717, f2: 1.2858710687180743, x: [  80.           89.52915734 3000.           20.        ]\n",
      "f1: -0.08231733757517157, f2: 1.3686268421064571, x: [  80.           79.44546436 2999.99999999   20.        ]\n",
      "f1: 0.36839280668280866, f2: 1.3433342971590705, x: [  80.           82.43601045 3000.           20.        ]\n",
      "f1: 3.456849731582275, f2: 1.2033586029415024, x: [  79.99999999  100.56366249 3000.           19.9999999 ]\n",
      "f1: 1.1964242726891126, f2: 1.300633598898993, x: [  80.           87.66467869 3000.           20.        ]\n",
      "f1: 0.4459931673974623, f2: 1.339134107635934, x: [  80.           82.94002315 3000.           20.        ]\n",
      "f1: 0.7756595515453886, f2: 1.3217628962248096, x: [  80.           85.0479081  2999.99999997   19.99999999]\n",
      "f1: 1.6167253337987597, f2: 1.2805966417878252, x: [  80.           90.20281084 3000.           20.        ]\n",
      "f1: -0.6719398298974414, f2: 1.4042565200341963, x: [  80.           75.35423092 3000.           20.        ]\n",
      "f1: 0.5545604819254671, f2: 1.33333013668329, x: [  80.           83.64006873 2999.99999997   20.        ]\n",
      "f1: 4.717329165111292, f2: 1.1583486085113675, x: [  80.          107.08383922 3000.           19.99999999]\n",
      "f1: 1.8985489355324718, f2: 1.2677131040686316, x: [  79.99999998   91.86543264 2999.99999981   20.        ]\n",
      "f1: 1.569455452999354, f2: 1.2827998184540605, x: [  80.           89.92093109 3000.           20.        ]\n",
      "f1: 2.304024330070039, f2: 1.2498965209815764, x: [  79.99999999   94.20607442 3000.           19.99999999]\n",
      "f1: 3.3875549327939374, f2: 1.2059994189900056, x: [  80.          100.19291238 3000.           20.        ]\n",
      "f1: 3.9776814539450367, f2: 1.1840882470898269, x: [  80.          103.30770912 3000.           20.        ]\n",
      "f1: 0.4407959566468724, f2: 1.339414077884602, x: [  79.99999843   82.9063616  3000.           20.        ]\n",
      "f1: 4.159926209800883, f2: 1.1775759369675964, x: [  80.          104.25082437 3000.           20.        ]\n",
      "f1: 0.8943076412781666, f2: 1.315690524673054, x: [  80.           85.79387058 3000.           20.        ]\n",
      "f1: 0.5261657121823243, f2: 1.3348400658449764, x: [  80.           83.45754539 3000.           20.        ]\n",
      "f1: 2.601619902193211, f2: 1.2373259938809267, x: [  80.           95.88762165 3000.           20.        ]\n",
      "f1: 4.69095045749834, f2: 1.1592359682044322, x: [  79.99999991  106.95146035 3000.           20.        ]\n",
      "f1: 3.325774519188864, f2: 1.2083697048168678, x: [  80.           99.86120615 3000.           20.        ]\n",
      "f1: 1.5085145943930138, f2: 1.2856586228784928, x: [  79.99999684   89.55621654 2999.99999999   20.        ]\n",
      "f1: 0.4665166020888154, f2: 1.33803051626497, x: [  79.99999996   83.07281108 3000.           20.        ]\n",
      "f1: 2.7631177915569753, f2: 1.2306736447482822, x: [  80.           96.78792854 3000.           19.99999997]\n",
      "f1: 2.8295557575443513, f2: 1.227970406541084, x: [  80.           97.15588014 3000.           20.        ]\n",
      "f1: 1.8426018487430351, f2: 1.2702370539808798, x: [  80.           91.53777461 3000.           19.99999997]\n",
      "f1: 1.5922273852250297, f2: 1.2817369204491418, x: [  79.999999     90.05683392 3000.           20.        ]\n",
      "f1: 2.551125201497472, f2: 1.2394300139841405, x: [  80.          95.6043876 3000.          20.       ]\n",
      "f1: 2.2623324324065868, f2: 1.2516909749060332, x: [  79.99999997   93.96809357 3000.           20.        ]\n",
      "f1: 2.797008929870649, f2: 1.2292922698325437, x: [  80.           96.97580135 3000.           20.        ]\n",
      "f1: -0.3271988240387909, f2: 1.3830535528386037, x: [  80.           77.77243219 3000.           20.        ]\n",
      "f1: 4.456991155839163, f2: 1.1672026728066205, x: [  80.        105.770109 3000.         20.      ]\n",
      "f1: 1.554472391502767, f2: 1.2835007501973856, x: [  80.           89.83139949 3000.           20.        ]\n",
      "f1: 1.0377843013286487, f2: 1.3084687667907127, x: [  80.           86.68736066 3000.           20.        ]\n",
      "f1: 1.2766695564264154, f2: 1.2967285645143605, x: [  79.99999991   88.15491164 3000.           20.        ]\n",
      "f1: 4.347722748675427, f2: 1.1709840760091474, x: [  80.          105.21382632 2999.99999984   19.99999999]\n",
      "f1: 5.1903150300713286, f2: 1.1427974876893676, x: [  80.          109.43029421 3000.           20.        ]\n",
      "f1: 3.5931791487868088, f2: 1.1982170485821395, x: [  80.          101.28910855 3000.           20.        ]\n",
      "f1: 4.578741477834458, f2: 1.1630350831803369, x: [  79.99999817  106.38650935 3000.           20.        ]\n",
      "f1: 4.373952542494888, f2: 1.1700727701867597, x: [  79.99999997  105.34762944 3000.           20.        ]\n",
      "f1: -0.5302475820005977, f2: 1.3954103859349563, x: [  80.           76.35740779 3000.           20.        ]\n",
      "f1: 1.375953580012862, f2: 1.2919498690979472, x: [  80.           88.75770843 3000.           20.        ]\n",
      "f1: 2.8257528271640457, f2: 1.2281246218307575, x: [  80.           97.13485608 2999.99999997   20.        ]\n",
      "f1: 4.544935454855188, f2: 1.1641876195745993, x: [  79.99998757  106.2157058  3000.           20.        ]\n",
      "f1: -0.44897537102744434, f2: 1.3904201116156876, x: [  80.           76.92690903 3000.           20.        ]\n",
      "f1: 0.9811606139297474, f2: 1.3113032438575305, x: [  80.           86.33584546 3000.           20.        ]\n",
      "f1: 4.462092092708667, f2: 1.1670278975075186, x: [  80.          105.79600628 2999.99795533   20.        ]\n",
      "f1: 2.3340037414205805, f2: 1.2486113424413274, x: [  79.99999989   94.37682842 3000.           19.99999998]\n",
      "f1: 0.41575816809987837, f2: 1.340765422611866, x: [  80.           82.74401253 3000.           20.        ]\n",
      "f1: 3.9862206663106035, f2: 1.183780519286735, x: [  80.          103.35209166 3000.           20.        ]\n",
      "f1: 4.854271034856292, f2: 1.1537766680828176, x: [  80.          107.76845447 2999.99999876   20.        ]\n",
      "f1: 2.383110310520826, f2: 1.24651545241832, x: [  80.           94.65585986 3000.           20.        ]\n",
      "f1: 4.468738765889466, f2: 1.1667984549712278, x: [  80.         105.8297417 3000.          20.       ]\n",
      "f1: -0.4648852454163126, f2: 1.391392293749802, x: [  80.           76.81575565 3000.           20.        ]\n",
      "f1: 1.1676726791988785, f2: 1.302042191303856, x: [  80.           87.48836154 2999.99999996   19.99999999]\n",
      "f1: 0.2716995325546243, f2: 1.348629598869488, x: [  80.           81.80364437 3000.           20.        ]\n",
      "f1: 0.5038545915960977, f2: 1.3360304687910756, x: [  80.           83.31384758 3000.           20.        ]\n",
      "f1: 0.2596366462767656, f2: 1.349295084581834, x: [  80.           81.72441079 2999.99999978   20.        ]\n",
      "f1: 3.9386542528951813, f2: 1.1854979527024818, x: [  80.          103.10462216 3000.           19.99999999]\n",
      "f1: 1.3081975959899894, f2: 1.2952048005788654, x: [  79.99999918   88.34677715 3000.           20.        ]\n",
      "f1: 2.2528477673073968, f2: 1.252100374313889, x: [  80.           93.91387013 3000.           20.        ]\n",
      "f1: 0.0760983098897489, f2: 1.3595571545235818, x: [  80.           80.50924325 3000.           20.        ]\n",
      "f1: 1.3277842469243313, f2: 1.2942611044445445, x: [  80.           88.46576432 3000.           20.        ]\n",
      "f1: 3.050443833981731, f2: 1.2191191675097375, x: [  79.99999969   98.36932418 3000.           20.        ]\n",
      "f1: 4.948507871488212, f2: 1.1506637957855488, x: [  79.99999972  108.23705847 2999.99999997   20.        ]\n",
      "f1: 3.944769887186851, f2: 1.1852766922184172, x: [  80.          103.13647267 3000.           20.        ]\n",
      "f1: 1.657125608093089, f2: 1.278723426221272, x: [  80.           90.44302945 2999.99999999   20.        ]\n",
      "f1: 4.222158309165573, f2: 1.1753783436375873, x: [  80.          104.57092685 3000.           20.        ]\n",
      "f1: 0.18534802856610968, f2: 1.3534176348827844, x: [  80.           81.23475171 3000.           20.        ]\n",
      "f1: 1.6013147410070423, f2: 1.281313545245969, x: [  79.99999998   90.11101125 3000.           20.        ]\n",
      "f1: -0.010711163321742535, f2: 1.3645022997521534, x: [  80.           79.92806135 3000.           20.        ]\n",
      "f1: 3.0246639947296146, f2: 1.2201415662591195, x: [  80.           98.22847605 3000.           20.        ]\n",
      "f1: 2.95331659794862, f2: 1.2229856600689768, x: [  80.           97.8376118  3000.           19.99999998]\n",
      "f1: 1.0679259464797868, f2: 1.3069681313058712, x: [  80.           86.87389744 3000.           20.        ]\n",
      "f1: 2.652646446139522, f2: 1.2352115412854048, x: [  79.99999993   96.17299149 3000.           20.        ]\n",
      "f1: 1.75564593865463, f2: 1.274192692840151, x: [  80.           91.02617002 3000.           20.        ]\n",
      "f1: 3.4654639585425424, f2: 1.203031616932645, x: [  80.          100.60965598 3000.           19.9999999 ]\n",
      "f1: -0.450072199392982, f2: 1.3904870604906816, x: [  80.           76.91925126 3000.           20.        ]\n",
      "f1: 3.841953047369494, f2: 1.1890142941837427, x: [  80.          102.59968326 3000.           19.99999999]\n",
      "f1: 0.5156647878076168, f2: 1.3353999122127578, x: [  80.           83.38994363 3000.           19.99999984]\n",
      "f1: 4.016908493591773, f2: 1.1826767393124082, x: [  80.         103.5114345 3000.          20.       ]\n",
      "f1: -0.3974507938694304, f2: 1.3872872405798793, x: [  80.           77.28578521 3000.           20.        ]\n",
      "f1: -0.22777524395766785, f2: 1.3771351049704696, x: [  80.           78.45599693 3000.           20.        ]\n",
      "f1: 2.2139114851368773, f2: 1.2537856116585981, x: [  79.99999999   93.69094407 3000.           20.        ]\n",
      "f1: 2.9607340912489915, f2: 1.2226889791048021, x: [  79.99999999   97.87831992 3000.           20.        ]\n",
      "f1: 1.683077689861426, f2: 1.2775248382000328, x: [  80.           90.59700363 3000.           20.        ]\n",
      "f1: -0.037996586292502896, f2: 1.3660690572443124, x: [  80.           79.74451292 3000.           20.        ]\n",
      "f1: 2.073461896359079, f2: 1.2599264899693852, x: [  80.           92.88236729 3000.           19.99999999]\n",
      "f1: 2.9469003634656104, f2: 1.2232424798414698, x: [  80.           97.80238501 3000.           19.99999999]\n",
      "f1: 2.094439674503294, f2: 1.259003080783049, x: [  79.99999774   93.00358226 3000.           20.        ]\n",
      "f1: 1.6992790039845904, f2: 1.276778446277539, x: [  80.           90.6929938  3000.           19.99999999]\n",
      "f1: 2.2407158804112144, f2: 1.2526247052097954, x: [  79.99999771   93.84446498 3000.           20.        ]\n",
      "f1: 1.7842035281060422, f2: 1.2728891685677994, x: [  79.99999995   91.1945049  2999.99999997   20.        ]\n",
      "f1: 4.189125808017137, f2: 1.1765431743582364, x: [  80.         104.4011402 3000.          20.       ]\n",
      "f1: 2.531904131683075, f2: 1.2402339773739488, x: [  80.           95.49635234 3000.           20.        ]\n",
      "f1: 0.6543598510612592, f2: 1.3280676539822776, x: [  80.          84.2784491 3000.          20.       ]\n",
      "f1: 3.6691193495785863, f2: 1.1953835432672053, x: [  80.          101.69096289 3000.           20.        ]\n",
      "f1: 4.984192441960398, f2: 1.1494920329937401, x: [  80.          108.41397586 3000.           20.        ]\n",
      "f1: -0.16879010227537772, f2: 1.3736636320193176, x: [  80.          78.8587358 3000.          20.       ]\n",
      "f1: 1.5829577426697334, f2: 1.2821692322144393, x: [  80.           90.00153802 3000.           20.        ]\n",
      "f1: -0.5430114739159168, f2: 1.3961995947641506, x: [  80.           76.26758061 3000.           20.        ]\n",
      "f1: 2.576336922123037, f2: 1.2384231780689818, x: [  80.           95.74651965 3000.           19.99919782]\n",
      "f1: 3.497741075802389, f2: 1.2018089527608213, x: [  79.99999997  100.78180466 2999.99999998   20.        ]\n",
      "f1: 2.112163804753841, f2: 1.2582245534493735, x: [  79.99999994   93.10587737 3000.           20.        ]\n",
      "f1: 0.7558576203134106, f2: 1.3227853874613233, x: [  80.           84.92277164 3000.           20.        ]\n",
      "f1: 2.504777399157899, f2: 1.2413714988092373, x: [  80.           95.34367368 3000.           20.        ]\n",
      "f1: 0.7206876703787669, f2: 1.3246078792901506, x: [  80.           84.70006265 3000.           20.        ]\n",
      "f1: -0.24946264987316255, f2: 1.3784188782696822, x: [  80.           78.30739883 3000.           20.        ]\n",
      "f1: 1.3341399266353096, f2: 1.293955372561213, x: [  80.          88.5043399 3000.          20.       ]\n",
      "f1: 5.262143182576645, f2: 1.140493706917249, x: [  79.99999983  109.782243   3000.           20.        ]\n",
      "f1: 1.6667230594215754, f2: 1.278279742820959, x: [  80.           90.50000184 3000.           20.        ]\n",
      "f1: 2.0795585486947097, f2: 1.2596578891045667, x: [  79.99999995   92.91761213 3000.           20.        ]\n",
      "f1: 0.9770191036362288, f2: 1.3115113547661426, x: [  80.           86.31007912 2999.99999999   20.        ]\n",
      "f1: 4.177985156672569, f2: 1.1769368658122388, x: [  80.          104.34381509 3000.           20.        ]\n",
      "f1: 2.407815274170628, f2: 1.24546534873457, x: [  80.           94.79592686 3000.           20.        ]\n",
      "f1: 4.837936518622407, f2: 1.154318981103096, x: [  80.          107.68702173 3000.           20.        ]\n",
      "f1: 1.4472930173347875, f2: 1.2885516246856779, x: [  80.           89.18832594 3000.           20.        ]\n",
      "f1: 3.6264973912725345, f2: 1.1969712060724815, x: [  80.          101.46561534 3000.           20.        ]\n",
      "f1: 4.4019711845086995, f2: 1.1691018219203542, x: [  80.          105.49037038 3000.           20.        ]\n",
      "f1: 1.3869540860195673, f2: 1.291423945118669, x: [  80.           88.82424558 3000.           19.99999999]\n",
      "f1: 1.8841004653747015, f2: 1.2683633513591026, x: [  80.           91.78092621 3000.           20.        ]\n",
      "f1: 3.1441586413709772, f2: 1.2154257299445517, x: [  80.           98.87964584 3000.           20.        ]\n",
      "f1: 4.232948187849332, f2: 1.174998661338756, x: [  80.          104.62632704 3000.           19.99999996]\n",
      "f1: 4.710533105915629, f2: 1.1585770142506524, x: [  80.          107.04974955 2999.99999999   20.        ]\n",
      "f1: 3.0110455513305756, f2: 1.2206827809101333, x: [  80.           98.15398998 3000.           20.        ]\n",
      "f1: 1.6567238577252525, f2: 1.2787420114625818, x: [  80.           90.44064382 3000.           19.99999997]\n",
      "f1: 1.0490849370585948, f2: 1.3079054878039238, x: [  80.           86.75734359 3000.           20.        ]\n",
      "f1: 3.042195558003526, f2: 1.2194459808060274, x: [  80.           98.32428186 3000.           20.        ]\n",
      "f1: 2.733306721485973, f2: 1.2318928843414971, x: [  80.           96.62237123 3000.           20.        ]\n",
      "f1: 3.228477469625591, f2: 1.2121333210196839, x: [  80.           99.33656117 2999.99999998   19.99999999]\n",
      "f1: -0.7014969004211039, f2: 1.4061257517445946, x: [  80.           75.14327953 3000.           20.        ]\n",
      "f1: 4.0104361289110715, f2: 1.1829092621285573, x: [  80.          103.47784794 3000.           20.        ]\n",
      "f1: 2.415048620689263, f2: 1.24515843341244, x: [  80.           94.83689781 3000.           20.        ]\n",
      "f1: 0.9955475013487015, f2: 1.3105811478323572, x: [  79.99999999   86.42529354 3000.           20.        ]\n",
      "f1: 2.2986930090619784, f2: 1.2501255187023703, x: [  80.           94.17567633 3000.           20.        ]\n",
      "f1: 0.7282397045189913, f2: 1.3242158370105492, x: [  80.           84.74793424 3000.           20.        ]\n",
      "f1: 2.7312969785107115, f2: 1.2319752217041262, x: [  80.           96.61119982 3000.           20.        ]\n",
      "f1: 2.6861102940062365, f2: 1.2338312011680235, x: [  80.           96.35968185 2999.99999999   20.        ]\n",
      "f1: 0.40773698501890626, f2: 1.3411993105756477, x: [  80.           82.69193398 3000.           19.99999996]\n",
      "f1: 3.471221955302899, f2: 1.2028132042841226, x: [  80.          100.64038752 2999.99999999   20.        ]\n",
      "f1: 1.9282767830280436, f2: 1.2663786290046946, x: [  80.           92.03906134 3000.           19.99999999]\n",
      "f1: 2.1167994710118263, f2: 1.2580212086496863, x: [  79.99999924   93.13261255 3000.           20.        ]\n",
      "f1: 3.7952717751686933, f2: 1.1907238202804598, x: [  79.99999964  102.3550387  3000.           19.99999999]\n",
      "f1: 3.928176580542563, f2: 1.185877336800445, x: [  80.          103.05003103 3000.           20.        ]\n",
      "f1: -0.43490126376659577, f2: 1.3895620018688315, x: [  80.           77.02510322 3000.           20.        ]\n",
      "f1: 4.886863361198073, f2: 1.1526970182239384, x: [  80.          107.93075396 2999.99999998   20.        ]\n",
      "f1: 4.813751977050511, f2: 1.1551234199230882, x: [  80.          107.56634095 2999.99999997   19.99999998]\n",
      "f1: 2.6324201260281486, f2: 1.236048443029659, x: [  79.99998732   96.05996515 3000.           20.        ]\n",
      "f1: 2.0588493038347124, f2: 1.2605710574957367, x: [  80.           92.79783726 3000.           19.9999997 ]\n",
      "f1: 3.5118723901468094, f2: 1.2012749172689798, x: [  80.          100.85708104 3000.           19.99999999]\n",
      "f1: 1.4586156159281356, f2: 1.2880149791021296, x: [  79.999999     89.25647923 3000.           19.99999997]\n",
      "f1: 5.10814285439548, f2: 1.1454513555308155, x: [  80.          109.02626757 3000.           20.        ]\n",
      "f1: 2.2092654527746376, f2: 1.2539871943622516, x: [  80.           93.66430822 3000.           20.        ]\n",
      "f1: 3.258209506143917, f2: 1.2109792224851252, x: [  80.           99.49717575 3000.           19.99999997]\n",
      "f1: -0.5921436171045771, f2: 1.3992515679082345, x: [  80.           75.92081622 3000.           20.        ]\n",
      "f1: 2.4853464596218875, f2: 1.2421883937099003, x: [  80.           95.23415915 3000.           20.        ]\n",
      "f1: 3.0962180645974655, f2: 1.2173106097871216, x: [  80.           98.61891667 3000.           20.        ]\n",
      "f1: 2.6161631741451163, f2: 1.23672214913294, x: [  80.           95.96904248 3000.           20.        ]\n",
      "f1: 1.2081189698820718, f2: 1.3000620859100942, x: [  80.           87.73629423 2999.99999999   19.99999999]\n",
      "f1: 3.4757447989551986, f2: 1.202641741333343, x: [  80.          100.66452038 3000.           19.99999993]\n",
      "f1: 0.20509258392612453, f2: 1.3523178526927775, x: [  80.           81.36518166 3000.           20.        ]\n",
      "f1: 3.5749757865831104, f2: 1.198899479894383, x: [  80.          101.19254433 3000.           20.        ]\n",
      "f1: 0.6202432439963428, f2: 1.329858910288239, x: [  80.           84.06076292 3000.           20.        ]\n",
      "f1: 3.5647873718118275, f2: 1.1992819837322726, x: [  80.          101.13845713 3000.           20.        ]\n",
      "f1: 4.909134538945401, f2: 1.1519611213738816, x: [  80.          108.04151716 3000.           20.        ]\n",
      "f1: 1.562932747932853, f2: 1.2831048079935137, x: [  80.           89.8819655  2999.99999979   19.99999998]\n",
      "f1: 5.024970560854997, f2: 1.1481576766366446, x: [  80.          108.61579308 3000.           20.        ]\n",
      "f1: -0.6051080731297335, f2: 1.4000606686164567, x: [  79.99999835   75.82904965 3000.           20.        ]\n",
      "f1: -0.5060524658747058, f2: 1.3939184734465102, x: [  80.           76.52739401 3000.           19.99999999]\n",
      "f1: -0.6112784024209434, f2: 1.4004462619322946, x: [  80.           75.78533762 3000.           20.        ]\n",
      "f1: 3.634160087844906, f2: 1.196685270740699, x: [  80.          101.50616585 3000.           20.        ]\n",
      "f1: -0.26071928029409125, f2: 1.3790867882652917, x: [  80.           78.2301592  2999.99999997   20.        ]\n",
      "f1: 4.938670535905539, f2: 1.1509874899415695, x: [  80.          108.18823621 2999.9999987    20.        ]\n",
      "f1: 1.0735136260208968, f2: 1.3066905641078943, x: [  80.           86.90843377 3000.           20.        ]\n",
      "f1: 3.167576086007649, f2: 1.2145084486024524, x: [  80.           99.00675414 3000.           20.        ]\n",
      "f1: 1.9542206723883093, f2: 1.2652177520905883, x: [  80.           92.19032218 2999.99999978   19.99999998]\n",
      "f1: 3.702338253572283, f2: 1.1941508359955888, x: [  80.          101.86624968 3000.           19.99999997]\n",
      "f1: 0.8499487737502166, f2: 1.3179500139777283, x: [  80.           85.51573981 3000.           20.        ]\n",
      "f1: 0.12327861398381366, f2: 1.356894407725685, x: [  79.99999999   80.82335842 3000.           20.        ]\n",
      "f1: -0.5111340693090436, f2: 1.3942313689570915, x: [  80.           76.49172383 3000.           20.        ]\n",
      "f1: 1.0227401466164585, f2: 1.3092198815158325, x: [  80.           86.59410697 3000.           20.        ]\n",
      "f1: 1.6476751329565433, f2: 1.279160807632391, x: [  80.           90.38689446 3000.           20.        ]\n",
      "f1: 1.4278446121250743, f2: 1.2894751406197345, x: [  80.           89.07113832 3000.           20.        ]\n",
      "f1: 1.7635131769822683, f2: 1.2738331536446057, x: [  80.           91.07257512 3000.           20.        ]\n",
      "f1: 0.31323174404922516, f2: 1.34634665657887, x: [  80.           82.07585855 3000.           20.        ]\n",
      "f1: 3.95356959057234, f2: 1.1849585570444188, x: [  80.          103.18228471 3000.           20.        ]\n",
      "f1: 0.1624577947854036, f2: 1.3546963636964824, x: [  80.           81.08327922 3000.           20.        ]\n",
      "f1: 1.5526350776599351, f2: 1.2835867889514747, x: [  80.           89.82041444 3000.           20.        ]\n",
      "f1: 4.15158166413526, f2: 1.1778716152710875, x: [  79.99999961  104.20782757 3000.           20.        ]\n",
      "f1: 1.2641401614952126, f2: 1.297335754915539, x: [  80.           88.07854712 3000.           20.        ]\n",
      "f1: 1.6755005681237884, f2: 1.2778744051863138, x: [  80.           90.55207549 3000.           20.        ]\n",
      "f1: 2.66917200482165, f2: 1.2345292576430222, x: [  79.99999999   96.26523066 3000.           20.        ]\n",
      "f1: 4.504883602247704, f2: 1.1655575728790057, x: [  80.          106.01300815 3000.           20.        ]\n",
      "f1: 1.1642698832567195, f2: 1.3022092325896906, x: [  80.           87.46747061 3000.           19.99999998]\n",
      "f1: 0.10020318530664118, f2: 1.3581945711025185, x: [  80.           80.66988057 3000.           19.99999984]\n",
      "f1: 3.665034823849879, f2: 1.1955353977957612, x: [  80.          101.66938914 3000.           20.        ]\n",
      "f1: 0.037142825215943594, f2: 1.3617688769887952, x: [  80.           80.24896026 3000.           20.        ]\n",
      "f1: 3.999301972269892, f2: 1.1833096076457594, x: [  80.          103.42004482 3000.           19.99999997]\n",
      "f1: 2.064587924951574, f2: 1.2603177860332846, x: [  80.           92.83104275 3000.           19.99999999]\n",
      "f1: 3.915336138956686, f2: 1.1863428074791933, x: [  80.          102.98308987 3000.           20.        ]\n",
      "f1: 4.221620150767368, f2: 1.1753972929566263, x: [  80.          104.56816297 3000.           19.99999996]\n",
      "f1: 2.5217521188809777, f2: 1.240659308039367, x: [  79.99999873   95.43924083 3000.           19.99999999]\n",
      "f1: -0.1288098981519035, f2: 1.3713272187942225, x: [  80.           79.13054722 3000.           20.        ]\n",
      "f1: 3.9938813628041725, f2: 1.1835046847580335, x: [  80.          103.39189223 3000.           19.9999997 ]\n",
      "f1: 0.6161243682440808, f2: 1.3300757083813137, x: [  80.           84.03444366 3000.           20.        ]\n",
      "f1: 1.5197436700699924, f2: 1.2851302508301083, x: [  80.           89.62353338 3000.           19.99999997]\n",
      "f1: 0.9299561496283463, f2: 1.313883935259192, x: [  80.          86.0167355 3000.          20.       ]\n",
      "f1: 3.7691218994586695, f2: 1.191684917512368, x: [  80.          102.21773847 3000.           20.        ]\n",
      "f1: 3.4013108795352918, f2: 1.2054736931360104, x: [  80.          100.26662029 3000.           20.        ]\n",
      "f1: 1.2035083187316824, f2: 1.3002873282231353, x: [  79.99999857   87.70806538 3000.           20.        ]\n",
      "f1: 0.6119443740193276, f2: 1.3302958430896648, x: [  80.           84.00772543 3000.           20.        ]\n",
      "f1: 3.880214823549686, f2: 1.1876189754855555, x: [  80.        102.799769 3000.         20.      ]\n",
      "f1: 0.22013753017607077, f2: 1.3514818335141154, x: [  79.99999997   81.46442639 3000.           19.99999999]\n",
      "f1: 3.901019223395916, f2: 1.1868629216748372, x: [  79.99996215  102.90837062 3000.           20.        ]\n",
      "f1: 3.235706991441189, f2: 1.2118523687352936, x: [  80.           99.37563946 3000.           19.99999998]\n",
      "f1: 4.333030057733963, f2: 1.171495557075606, x: [  79.99999929  105.13880135 3000.           19.99999984]\n",
      "f1: 2.2043331738100194, f2: 1.2542013122686635, x: [  80.           93.63602301 2999.99999999   20.        ]\n",
      "f1: 2.5396293771899288, f2: 1.2399106486483573, x: [  80.           95.53978806 3000.           20.        ]\n",
      "f1: 5.240584967367843, f2: 1.1411835960602181, x: [  80.          109.67672922 3000.           19.99999999]\n",
      "f1: 0.8198848470269288, f2: 1.3194886645293549, x: [  80.           85.3267231  2999.99999997   20.        ]\n",
      "f1: 4.588309968873331, f2: 1.162709734948949, x: [  79.99998223  106.43478982 3000.           19.99999995]\n",
      "f1: 4.991963760783223, f2: 1.1492373548801451, x: [  80.          108.45246629 3000.           20.        ]\n",
      "f1: 0.0415520578953627, f2: 1.361517938543572, x: [  80.           80.27846312 3000.           20.        ]\n",
      "f1: 0.7156451913903645, f2: 1.324869864187936, x: [  80.           84.66808383 3000.           19.99999991]\n",
      "f1: 4.556726272017832, f2: 1.1637851314903356, x: [  80.          106.27531619 3000.           19.99999999]\n",
      "f1: 3.7087270062077393, f2: 1.193914225586239, x: [  80.          101.89992672 3000.           20.        ]\n",
      "f1: 2.919351951495514, f2: 1.2243471375568826, x: [  80.           97.65099273 3000.           20.        ]\n",
      "f1: 0.5511124953436223, f2: 1.3335131863944778, x: [  80.           83.61792611 3000.           20.        ]\n",
      "f1: 1.5362550948789282, f2: 1.2843546773938033, x: [  80.           89.72242131 3000.           19.99999997]\n",
      "f1: 5.253778006400588, f2: 1.140761243311166, x: [  80.          109.74131288 3000.           20.        ]\n",
      "f1: 3.348721452227239, f2: 1.2074875623354426, x: [  80.           99.98453937 3000.           19.99999999]\n",
      "f1: 2.1597824836239097, f2: 1.2561407343255475, x: [  80.           93.38014935 3000.           20.        ]\n",
      "f1: 4.848189399676794, f2: 1.1539784856329534, x: [  80.          107.73814279 3000.           20.        ]\n",
      "f1: 5.169167582239402, f2: 1.1434785976646975, x: [  80.          109.32645848 3000.           20.        ]\n",
      "f1: 3.9107062910916826, f2: 1.1865107859558757, x: [  80.          102.95894239 2999.99999984   19.99999999]\n",
      "f1: 3.5864986037807505, f2: 1.1984673565746258, x: [  80.          101.25368073 3000.           19.99999992]\n",
      "f1: 3.597921502662848, f2: 1.1980394670623569, x: [  80.          101.31425044 3000.           19.99999999]\n",
      "f1: -0.4613065066949807, f2: 1.3911734139548373, x: [  80.           76.84077231 3000.           20.        ]\n",
      "f1: 1.25574364254248, f2: 1.2977431845749448, x: [  80.           88.02733465 3000.           20.        ]\n",
      "f1: 1.2641401614949792, f2: 1.2973357549157667, x: [  80.           88.07854712 3000.           20.        ]\n",
      "f1: 0.3910023618748418, f2: 1.3421060267853249, x: [  80.           82.58317658 3000.           20.        ]\n",
      "f1: 0.17460003743414743, f2: 1.3540175552110962, x: [  80.           81.16366379 3000.           20.        ]\n",
      "f1: 4.698641708139688, f2: 1.1589770149433847, x: [  80.          106.99007507 3000.           20.        ]\n",
      "f1: 0.9576989776305468, f2: 1.3124836296490865, x: [  80.           86.18977748 3000.           20.        ]\n",
      "f1: -0.4874536960694427, f2: 1.3927752751059546, x: [  80.           76.65780607 3000.           20.        ]\n",
      "f1: 1.7466515577278905, f2: 1.2746041502091878, x: [  79.99999998   90.97308743 3000.           20.        ]\n",
      "f1: 0.5324117915155113, f2: 1.3345079314113024, x: [  79.99996903   83.49770013 3000.           20.        ]\n",
      "f1: 1.1442087154716971, f2: 1.3031954573835682, x: [  80.           87.34420667 2999.99999997   19.99999996]\n",
      "f1: 3.8674678260542836, f2: 1.1880832436764739, x: [  80.          102.73315326 3000.           20.        ]\n",
      "f1: 2.4272511917620867, f2: 1.2446412273320202, x: [  80.           94.90597525 3000.           20.        ]\n",
      "f1: 3.1119106788342674, f2: 1.216692583976917, x: [  80.           98.70433821 3000.           19.99999999]\n",
      "f1: 1.2837600224154873, f2: 1.2963853642636123, x: [  80.           88.19809765 3000.           19.99999997]\n",
      "f1: 4.395406874285914, f2: 1.1693293924384427, x: [  79.99996993  105.45692303 3000.           20.        ]\n",
      "f1: 3.3632952293634855, f2: 1.2069283849100365, x: [  79.99999993  100.06279027 2999.99999999   20.        ]\n",
      "f1: 3.3539690531028747, f2: 1.2072861216102664, x: [  80.          100.01272236 3000.           20.        ]\n",
      "f1: -0.7084911949467018, f2: 1.406569308836488, x: [  80.           75.09327394 3000.           20.        ]\n",
      "f1: 2.278095305286065, f2: 1.2510115424678219, x: [  80.           94.05814017 3000.           20.        ]\n",
      "f1: 2.026501401665068, f2: 1.262001712687376, x: [  80.           92.61043804 3000.           20.        ]\n",
      "f1: 0.20924932312376965, f2: 1.3520867030967354, x: [  79.99999971   81.39261361 3000.           20.        ]\n",
      "f1: 2.47893390681301, f2: 1.24245836678535, x: [  80.           95.19798978 2999.99999998   20.        ]\n",
      "f1: 2.6661751748892075, f2: 1.234652895586906, x: [  80.           96.24851011 3000.           20.        ]\n",
      "f1: 0.14097641223763574, f2: 1.3559000511861259, x: [  80.           80.94087174 3000.           20.        ]\n",
      "f1: 2.04548103247213, f2: 1.2611616526923537, x: [  80.           92.72043751 3000.           19.99999989]\n",
      "f1: 0.6508328384581228, f2: 1.3282524673553446, x: [  80.           84.25597053 3000.           19.99999999]\n",
      "f1: 1.1143994141310176, f2: 1.3046654516094525, x: [  80.           87.16072425 3000.           19.99999999]\n",
      "f1: 4.670114285337413, f2: 1.15993842056597, x: [  80.          106.84678031 3000.           20.        ]\n",
      "f1: 1.4340490100013008, f2: 1.2891802864035378, x: [  80.           89.10854006 3000.           20.        ]\n",
      "f1: 3.682873624393273, f2: 1.1948726437897053, x: [  80.          101.76357693 3000.           20.        ]\n",
      "f1: 0.9412444154194272, f2: 1.313313571686567, x: [  80.           86.08718644 3000.           20.        ]\n",
      "f1: 4.574520484598136, f2: 1.163178754641224, x: [  80.          106.36520031 3000.           20.        ]\n",
      "f1: 4.75950356685917, f2: 1.1569343995722585, x: [  80.          107.29514774 3000.           20.        ]\n",
      "f1: 0.19507459743902741, f2: 1.3528754900557043, x: [  80.           81.2990303  3000.           19.99999997]\n",
      "f1: 1.7269856194520994, f2: 1.2755053042917168, x: [  79.99999991   90.85691591 3000.           20.        ]\n",
      "f1: 3.2201073776531466, f2: 1.2124588615909597, x: [  80.           99.29129847 3000.           20.        ]\n",
      "f1: 3.4813866976969874, f2: 1.2024279561522413, x: [  80.          100.69461599 3000.           20.        ]\n",
      "f1: 0.5087548825626227, f2: 1.3357687140269587, x: [  80.          83.3454298 3000.          20.       ]\n",
      "f1: 3.5276114088220187, f2: 1.2006810244946735, x: [  80.          100.94085543 3000.           19.99999999]\n",
      "f1: 3.812241090849916, f2: 1.190101502164251, x: [  79.99999675  102.44403574 3000.           20.        ]\n",
      "f1: 1.0575275424957913, f2: 1.3074851879625686, x: [  80.           86.80959041 3000.           19.99999999]\n",
      "f1: -0.05807026786980649, f2: 1.3672255480111488, x: [  80.           79.60920751 3000.           20.        ]\n",
      "f1: 5.2682451406403485, f2: 1.140298676285766, x: [  80.          109.81208997 3000.           20.        ]\n",
      "f1: -0.1747097952999861, f2: 1.374010708049311, x: [  80.           78.81841021 3000.           19.99999997]\n",
      "f1: 4.433495037915851, f2: 1.1680124882749956, x: [  80.          105.65073806 3000.           20.        ]\n",
      "f1: 5.080126801652268, f2: 1.146360684809614, x: [  80.         108.8881747 3000.          20.       ]\n",
      "f1: 3.8280344449965074, f2: 1.1895231828574806, x: [  80.          102.5268006  3000.           19.99999999]\n",
      "f1: 2.675680681506365, f2: 1.2342608721265884, x: [  80.           96.30153527 3000.           20.        ]\n",
      "f1: 2.684454070895466, f2: 1.2338994007929704, x: [  80.           96.35045051 3000.           20.        ]\n",
      "f1: 4.586431583271062, f2: 1.1627734233853384, x: [  80.          106.42532459 3000.           20.        ]\n",
      "f1: 1.1740947610949244, f2: 1.3017271272650857, x: [  80.           87.52777532 2999.99999996   19.99999999]\n",
      "f1: 4.56145340862489, f2: 1.1636239490307805, x: [  80.          106.29920194 3000.           19.99999991]\n",
      "f1: 4.531163766966729, f2: 1.1646582595268622, x: [  79.99997607  106.14604071 3000.           20.        ]\n",
      "f1: 2.843430763635045, f2: 1.227408473985416, x: [  79.9999846    97.23253529 3000.           20.        ]\n",
      "f1: -0.5004754695152688, f2: 1.3935753447593842, x: [  80.           76.56652247 2999.99999999   20.        ]\n",
      "f1: -0.3545395756199405, f2: 1.3846960742974042, x: [  79.99999999   77.58340111 3000.           20.        ]\n",
      "f1: 4.1445450933927575, f2: 1.1781211245348369, x: [  80.          104.17155712 3000.           20.        ]\n",
      "f1: 2.1304629438695386, f2: 1.2574228917454897, x: [  79.99996635   93.21134257 3000.           20.        ]\n",
      "f1: 1.3217695699530125, f2: 1.2945506532784157, x: [  80.           88.42924297 3000.           19.99999997]\n",
      "f1: 0.38574586494458696, f2: 1.3423912749675946, x: [  80.           82.54898537 3000.           19.9999997 ]\n",
      "f1: 3.263141141821685, f2: 1.2107881337691686, x: [  80.           99.52379171 3000.           20.        ]\n",
      "f1: -0.6606620943044608, f2: 1.403545502437174, x: [  80.           75.43456562 3000.           20.        ]\n",
      "f1: 2.1430269626455103, f2: 1.256872682740265, x: [  80.          93.2837336 3000.          20.       ]\n",
      "f1: 0.42831614236466686, f2: 1.3400870636006654, x: [  80.         82.825481 3000.         20.      ]\n",
      "f1: 3.018659843222769, f2: 1.220380083314085, x: [  80.           98.19564331 3000.           20.        ]\n",
      "f1: 0.5457773378138602, f2: 1.333796587899062, x: [  80.           83.58365271 3000.           20.        ]\n",
      "f1: 0.07087679752455539, f2: 1.3598529165253121, x: [  79.99999997   80.47440429 2999.99999967   19.99999999]\n",
      "f1: 2.4764916840017754, f2: 1.2425612362692484, x: [  80.           95.18421105 3000.           20.        ]\n",
      "f1: 5.160522693114072, f2: 1.1437574036302343, x: [  80.          109.28398297 3000.           19.99999999]\n",
      "f1: 2.7560966078450613, f2: 1.2309604500227662, x: [  80.           96.74896152 3000.           20.        ]\n",
      "f1: 3.3113906796788197, f2: 1.2089237207124268, x: [  80.           99.78381939 3000.           20.        ]\n",
      "f1: 3.1882513291017758, f2: 1.213700437791325, x: [  80.           99.11884245 3000.           20.        ]\n",
      "f1: 5.232260550923561, f2: 1.1414503442432036, x: [  80.          109.63595923 3000.           20.        ]\n",
      "f1: 3.6591932300479906, f2: 1.1957526841138006, x: [  80.         101.6385269 3000.          20.       ]\n",
      "f1: 4.19769540780571, f2: 1.176240627264315, x: [  80.          104.44521436 3000.           20.        ]\n",
      "f1: 0.21275823207557104, f2: 1.3518916716500122, x: [  80.           81.41576362 3000.           20.        ]\n",
      "f1: 4.262136442868832, f2: 1.1739735314603137, x: [  80.          104.77604609 3000.           19.99999989]\n",
      "f1: 0.16795298050731866, f2: 1.3543890169032713, x: [  80.           81.11966854 3000.           20.        ]\n",
      "f1: 4.602869350121738, f2: 1.1622147943134296, x: [  80.          106.50824266 3000.           19.99999997]\n",
      "f1: 3.1794428138784885, f2: 1.2140444716714922, x: [  80.           99.07110366 3000.           20.        ]\n",
      "f1: 3.8864937354918974, f2: 1.1873905008151964, x: [  80.          102.83256669 3000.           20.        ]\n",
      "f1: 3.6758175908456763, f2: 1.1951346512174044, x: [  80.          101.72633193 3000.           19.99999999]\n",
      "f1: 2.610151960861522, f2: 1.236981096786762, x: [  79.99925708   95.93477743 3000.           20.        ]\n",
      "f1: 2.3124137107451546, f2: 1.2495364447173327, x: [  80.           94.25388909 3000.           20.        ]\n",
      "f1: 1.8003734216333864, f2: 1.2721530140982948, x: [  80.           91.28968199 3000.           20.        ]\n",
      "f1: 4.994459147660462, f2: 1.1491556153018478, x: [  80.          108.46482275 3000.           20.        ]\n",
      "f1: 3.8002440387698706, f2: 1.1905413529741455, x: [  79.99999967  102.38112485 3000.           20.        ]\n",
      "f1: 0.5609533710095364, f2: 1.3329909671023532, x: [  80.           83.68110772 3000.           19.99999997]\n",
      "f1: -0.579902145235766, f2: 1.3984890584471465, x: [  80.           76.00736195 3000.           20.        ]\n",
      "f1: 0.5949295295737379, f2: 1.331193155845701, x: [  80.           83.89887992 3000.           19.99999999]\n",
      "f1: 0.37898304944137573, f2: 1.3427585152736567, x: [  80.           82.50497527 3000.           20.        ]\n",
      "f1: 3.437951944792759, f2: 1.204076942706073, x: [  80.          100.46268873 3000.           19.99999997]\n",
      "f1: 0.8638263641494407, f2: 1.317241761991043, x: [  80.           85.60284964 3000.           20.        ]\n",
      "f1: 2.9817765050416387, f2: 1.221848603731302, x: [  80.           97.99371133 3000.           20.        ]\n",
      "f1: 0.7247131705176193, f2: 1.324398859180398, x: [  80.           84.72558326 3000.           20.        ]\n",
      "f1: -0.6035116045575056, f2: 1.3999609227113616, x: [  80.           75.84035748 3000.           20.        ]\n",
      "f1: 4.5228752632742095, f2: 1.164941487804177, x: [  79.99999921  106.10411334 2999.99999999   19.99999999]\n",
      "f1: -0.2802405611318406, f2: 1.380247651789912, x: [  80.           78.0960289  2999.99999999   20.        ]\n",
      "f1: 4.088215097260594, f2: 1.18012469882685, x: [  80.          103.88074163 3000.           20.        ]\n",
      "f1: 4.872868704883075, f2: 1.1531602251404098, x: [  79.99999829  107.86109364 3000.           20.        ]\n",
      "f1: 1.4816040163988387, f2: 1.2869276230228355, x: [  80.           89.39469449 3000.           20.        ]\n",
      "f1: 1.6230532404519338, f2: 1.2803026465456524, x: [  80.           90.24047858 3000.           20.        ]\n",
      "f1: 1.0949269620834199, f2: 1.3056286525986969, x: [  80.           87.04065844 2999.99999957   20.        ]\n",
      "f1: 3.5159702790695455, f2: 1.201120197064537, x: [  80.          100.87889965 2999.99999999   19.99999999]\n",
      "f1: 2.3784284495603645, f2: 1.2467147832829046, x: [  80.           94.62929226 3000.           20.        ]\n",
      "f1: 1.148507485357683, f2: 1.3029839172751259, x: [  80.           87.37063468 3000.           20.        ]\n",
      "f1: 0.7374491656223776, f2: 1.3237382721860065, x: [  80.           84.80627552 3000.           20.        ]\n",
      "f1: 2.4928333210493063, f2: 1.2418734323844096, x: [  80.           95.27637068 3000.           20.        ]\n",
      "f1: 1.1164954968189198, f2: 1.3045619079080837, x: [  80.          87.1736387 3000.          20.       ]\n",
      "f1: 1.1220149558908301, f2: 1.304289384777864, x: [  80.          87.2076362 3000.          20.       ]\n",
      "f1: -0.07709920592631868, f2: 1.3683248694490993, x: [  80.           79.48073147 3000.           20.        ]\n",
      "f1: 4.441143084757291, f2: 1.1677486934335581, x: [  80.         105.6896084 3000.          20.       ]\n",
      "f1: 5.019172353127908, f2: 1.1483483185256473, x: [  79.99988173  108.58703259 3000.           20.        ]\n",
      "f1: 3.4603296453137085, f2: 1.203226470015642, x: [  80.          100.58224505 3000.           19.99999999]\n",
      "f1: 1.759888290918529, f2: 1.273998772957868, x: [  80.           91.05119658 3000.           20.        ]\n",
      "f1: 2.988048404038583, f2: 1.2215984933742676, x: [  79.99999999   98.02807876 3000.           19.99999981]\n",
      "f1: 5.197617494938406, f2: 1.1425625929999903, x: [  80.          109.46612705 3000.           20.        ]\n",
      "f1: 3.580059660861451, f2: 1.1987087630750572, x: [  79.99999999  101.21952226 2999.99999999   20.        ]\n",
      "f1: 0.9017384573937454, f2: 1.3153132713438591, x: [  80.           85.84037379 3000.           20.        ]\n",
      "f1: 0.8943076412781794, f2: 1.3156905246730362, x: [  80.           85.79387058 3000.           20.        ]\n",
      "f1: -0.5492694284932265, f2: 1.3965870810733945, x: [  80.           76.22350094 3000.           20.        ]\n",
      "f1: 1.4979580882719596, f2: 1.286155956320817, x: [  79.99999684   89.49288817 2999.99999999   20.        ]\n",
      "f1: 4.5128341129364475, f2: 1.1652851931243138, x: [  80.          106.05327744 3000.           19.99999998]\n",
      "f1: 5.2068169073756065, f2: 1.1422668997566556, x: [  80.          109.51125142 3000.           19.99999999]\n",
      "f1: 2.7069145172697917, f2: 1.2329755725032125, x: [  79.99999995   96.47556365 3000.           20.        ]\n",
      "f1: 0.8594427958745738, f2: 1.3174653455446113, x: [  80.           85.57534351 2999.99999997   19.99999999]\n",
      "f1: 1.1022985792576838, f2: 1.3052637414773016, x: [  80.          87.0861308 3000.          20.       ]\n",
      "f1: 2.9680706487329713, f2: 1.2223957702099755, x: [  79.99999964   97.91856696 2999.99999999   19.99999998]\n",
      "f1: 4.780357688144718, f2: 1.1562371495560386, x: [  80.          107.39948058 3000.           20.        ]\n",
      "f1: 3.2254334151081836, f2: 1.2122516817380569, x: [  80.           99.32010232 3000.           19.99999999]\n",
      "f1: 3.2380781645620464, f2: 1.2117602655430149, x: [  80.           99.38845318 3000.           19.99999999]\n",
      "f1: 3.20968695397758, f2: 1.212864726553013, x: [  79.99998463   99.23490702 3000.           20.        ]\n",
      "f1: 4.774427702792097, f2: 1.156435279695325, x: [  80.          107.36982328 3000.           20.        ]\n",
      "f1: 1.18579622620974, f2: 1.3011537021574682, x: [  80.           87.59954427 3000.           20.        ]\n",
      "f1: 0.43031977939665356, f2: 1.3399789360940646, x: [  80.           82.83847197 3000.           20.        ]\n",
      "f1: 1.4055180572274515, f2: 1.2905380071078287, x: [  80.           88.93641785 3000.           20.        ]\n",
      "f1: 2.972852163073188, f2: 1.2222047886293042, x: [  80.           97.94478904 3000.           20.        ]\n",
      "f1: 1.4761117781096402, f2: 1.2871871295615382, x: [  80.           89.36169265 3000.           20.        ]\n",
      "f1: 4.704004436483593, f2: 1.1587965696798692, x: [  80.          107.01699091 3000.           20.        ]\n",
      "f1: 4.370254306240994, f2: 1.1702011204955522, x: [  80.          105.32877435 3000.           20.        ]\n",
      "f1: 5.151538337830567, f2: 1.1440473865949754, x: [  80.          109.23982199 3000.           20.        ]\n",
      "f1: 2.052093289415577, f2: 1.2608694069859812, x: [  79.99999993   92.7587291  3000.           20.        ]\n",
      "f1: 3.712049483677628, f2: 1.1937912377773283, x: [  79.99999989  101.91743603 3000.           20.        ]\n",
      "f1: 1.009734827527404, f2: 1.3098703479272253, x: [  80.           86.51341034 3000.           20.        ]\n",
      "f1: 1.6817117127425096, f2: 1.2775878355043881, x: [  80.           90.58890581 3000.           19.99999997]\n",
      "f1: 4.488043992218438, f2: 1.1661351641271351, x: [  80.          105.92766513 3000.           20.        ]\n",
      "f1: 4.361629105462192, f2: 1.170500641382857, x: [  80.          105.28478645 3000.           20.        ]\n",
      "f1: 0.7983582645833931, f2: 1.3205940283012907, x: [  79.99999999   85.19112438 2999.99999993   20.        ]\n",
      "f1: 1.9032812186110568, f2: 1.2675003660617332, x: [  80.           91.89309403 3000.           19.99999999]\n",
      "f1: 0.300054524641232, f2: 1.347069591631438, x: [  80.           81.98958911 3000.           20.        ]\n",
      "f1: 2.50010310404019, f2: 1.2415678523987856, x: [  80.           95.31734044 3000.           19.99999998]\n",
      "f1: -0.15672902648698095, f2: 1.372957411365244, x: [  79.99999885   78.94083225 3000.           20.        ]\n",
      "f1: 1.4670521497030098, f2: 1.2876155696811011, x: [  80.           89.30722838 3000.           20.        ]\n",
      "f1: 3.251183363761075, f2: 1.2112516321685327, x: [  80.           99.45924341 3000.           20.        ]\n",
      "f1: 3.1009656950310727, f2: 1.2171235518718944, x: [  79.99999783   98.64476607 3000.           20.        ]\n",
      "f1: 3.402880914890301, f2: 1.2054137409038976, x: [  80.          100.27502958 3000.           19.99999992]\n",
      "f1: 0.6247359499928414, f2: 1.3296225935101647, x: [  79.99999843   84.08946003 3000.           20.        ]\n",
      "f1: -0.13829046419125235, f2: 1.3718800568781697, x: [  79.99999999   79.06617668 3000.           19.99999998]\n",
      "f1: 1.2170214765330476, f2: 1.2996275776726285, x: [  80.          87.7907719 3000.          20.       ]\n",
      "f1: 4.663636729195462, f2: 1.1601570802712193, x: [  79.99999972  106.81421622 3000.           20.        ]\n",
      "f1: 4.428380204128266, f2: 1.1681890144116067, x: [  80.         105.6247345 3000.          20.       ]\n",
      "f1: 4.061983197584945, f2: 1.1810614717025796, x: [  80.          103.74503571 3000.           20.        ]\n",
      "f1: 1.8344228524556454, f2: 1.2706074088377617, x: [  80.           91.48977541 3000.           20.        ]\n",
      "f1: 0.6659340794792366, f2: 1.3274617708996561, x: [  80.          84.3521726 3000.          20.       ]\n",
      "f1: 0.16979951733003754, f2: 1.3542857926307583, x: [  79.99999993   81.13189264 3000.           20.        ]\n",
      "f1: 2.536886358407723, f2: 1.240025422327153, x: [  80.           95.52436751 3000.           20.        ]\n",
      "f1: 4.158919124249638, f2: 1.1776116087820938, x: [  80.          104.24563616 2999.9999998    20.        ]\n",
      "f1: 1.0075947485730865, f2: 1.309977486594589, x: [  80.           86.50012417 3000.           20.        ]\n",
      "f1: 1.1814717349974877, f2: 1.3013655250194283, x: [  79.99999999   87.57302758 3000.           20.        ]\n",
      "f1: -0.3756222896172105, f2: 1.3859671156164552, x: [  79.99999976   77.43732211 3000.           20.        ]\n",
      "f1: 5.16121604303298, f2: 1.1437350338389638, x: [  80.          109.28739024 3000.           20.        ]\n",
      "f1: 1.1589822161486902, f2: 1.3024689408580465, x: [  79.99999995   87.43499785 3000.           19.99999999]\n",
      "f1: 3.003876720557557, f2: 1.22096844900139, x: [  79.99996272   98.11472694 3000.           20.        ]\n",
      "f1: 1.7933342461333923, f2: 1.2724733107166677, x: [  80.           91.24826115 3000.           19.99999999]\n",
      "f1: 2.0073045029237018, f2: 1.2628532664313266, x: [  79.99999909   92.49904558 3000.           20.        ]\n",
      "f1: 0.236976067726139, f2: 1.3505481801390504, x: [  80.           81.5753595  3000.           19.99999998]\n",
      "f1: 3.4901077745283535, f2: 1.2020977564979936, x: [  80.         100.7411196 3000.          19.9999997]\n",
      "f1: 3.5206412784282466, f2: 1.2009439167250966, x: [  80.          100.90376395 3000.           20.        ]\n",
      "f1: 3.294875921513781, f2: 1.2095608246728835, x: [  80.           99.69489396 3000.           20.        ]\n",
      "f1: 0.45306254331769263, f2: 1.3387536359071166, x: [  80.           82.98578648 3000.           19.99999992]\n",
      "f1: 3.8549550928971508, f2: 1.1885395478002083, x: [  80.          102.66771976 3000.           20.        ]\n",
      "f1: -0.2643899427135432, f2: 1.3793048765908216, x: [  79.99999684   78.20495248 2999.99999999   20.        ]\n",
      "f1: -0.14208155275997014, f2: 1.3721013319889823, x: [  80.           79.04042153 3000.           20.        ]\n",
      "f1: 1.283020240823514, f2: 1.2964211604422038, x: [  80.           88.19359287 3000.           19.99999993]\n",
      "f1: 1.6409675152412913, f2: 1.2794715428176562, x: [  80.           90.34703064 3000.           20.        ]\n",
      "f1: 1.8632673545354745, f2: 1.2693028569187546, x: [  80.           91.65894001 3000.           20.        ]\n",
      "f1: 4.49668329025073, f2: 1.1658387254725266, x: [  80.          105.97145761 3000.           20.        ]\n",
      "f1: -0.5609723566151849, f2: 1.3973126859806515, x: [  80.           76.14099959 3000.           20.        ]\n",
      "f1: 2.836882452963989, f2: 1.2276734734954264, x: [  80.           97.19637212 2999.99999999   19.99999999]\n",
      "f1: 1.9594389969347106, f2: 1.2649846727128071, x: [  80.           92.22071664 3000.           20.        ]\n",
      "f1: 1.719903241345017, f2: 1.275830349581497, x: [  80.           90.81504227 3000.           20.        ]\n",
      "f1: 2.1549339704694384, f2: 1.256352394038375, x: [  80.           93.35225994 3000.           20.        ]\n",
      "f1: 5.03249570617725, f2: 1.1479119768061399, x: [  80.          108.65299521 3000.           20.        ]\n",
      "f1: -0.15183952500758546, f2: 1.3726714301502323, x: [  80.           78.97409108 3000.           20.        ]\n",
      "f1: 3.8497112198686994, f2: 1.1887309449997416, x: [  80.          102.64028529 3000.           20.        ]\n",
      "f1: 4.529688610029346, f2: 1.1647084394803322, x: [  79.99999999  106.13859476 3000.           20.        ]\n",
      "f1: 0.2381035406914164, f2: 1.3504857400733548, x: [  80.           81.58278196 2999.99999997   20.        ]\n",
      "f1: 0.6966400575313958, f2: 1.3260606247336175, x: [  80.           84.54817677 3000.           19.99686573]\n",
      "f1: 4.38217856125244, f2: 1.1697874417892224, x: [  80.          105.38955698 3000.           19.99999997]\n",
      "f1: 0.9958097750113639, f2: 1.310567995649391, x: [  80.           86.42692334 2999.99999999   20.        ]\n",
      "f1: 5.001444587582704, f2: 1.1489268973414546, x: [  80.          108.49940521 3000.           20.        ]\n",
      "f1: 3.6503123538313664, f2: 1.1960832649996382, x: [  80.         101.5915896 3000.          20.       ]\n",
      "f1: -0.6967869119604783, f2: 1.4058273235125787, x: [  80.           75.17693478 3000.           20.        ]\n",
      "f1: 1.2147188505519708, f2: 1.2997399170208586, x: [  80.           87.77668454 3000.           20.        ]\n",
      "f1: 0.4937299319558568, f2: 1.3365718289285553, x: [  80.           83.24855651 3000.           19.99999998]\n",
      "f1: 1.5455331263905514, f2: 1.2839200176569912, x: [  79.99996652   89.77791036 3000.           20.        ]\n",
      "f1: 1.931236179130813, f2: 1.2662460332122156, x: [  79.99999995   92.05632803 2999.99999997   20.        ]\n",
      "f1: 3.1410786480375075, f2: 1.2155465426252272, x: [  80.           98.86291569 3000.           20.        ]\n",
      "f1: 2.4886398453154217, f2: 1.242049813801127, x: [  80.           95.25272983 3000.           20.        ]\n",
      "f1: 4.569035325859672, f2: 1.163365565465597, x: [  79.99999999  106.33750115 3000.           20.        ]\n",
      "f1: -0.37228165301172855, f2: 1.3857654506432548, x: [  80.           77.46048746 3000.           19.99999999]\n",
      "f1: 1.0550225004625748, f2: 1.3076098501980469, x: [  80.           86.79409131 3000.           20.        ]\n",
      "f1: 3.804360598674852, f2: 1.1903903528837514, x: [  80.          102.40271693 3000.           19.99999999]\n",
      "f1: 1.7865048643177872, f2: 1.2727843122857212, x: [  80.           91.20805682 3000.           19.99999999]\n",
      "f1: -0.33896702831165393, f2: 1.3837597391947087, x: [  80.           77.69112445 3000.           19.99999999]\n",
      "f1: 1.4739932118702852, f2: 1.287287279649294, x: [  79.99999989   89.34895923 3000.           19.99999998]\n",
      "f1: 0.26602759701575185, f2: 1.3489423725566336, x: [  80.           81.76639853 3000.           20.        ]\n",
      "f1: -0.38551371234169046, f2: 1.3865647959688145, x: [  80.           77.36869121 3000.           20.        ]\n",
      "f1: 3.0154963083504835, f2: 1.22050581716575, x: [  80.           98.17833962 3000.           19.99999999]\n",
      "f1: 1.401234899270225, f2: 1.290742239000804, x: [  79.99999989   88.91054944 3000.           20.        ]\n",
      "f1: 1.7261505338177214, f2: 1.275543616047822, x: [  80.           90.85197965 2999.99999996   19.99999999]\n",
      "f1: 5.256847013597699, f2: 1.1406630658790105, x: [  80.         109.7563311 3000.          20.       ]\n",
      "f1: 3.1043499517412143, f2: 1.2169902230188454, x: [  80.          98.6631912 3000.          20.       ]\n",
      "f1: 5.23616982433798, f2: 1.1413250501081937, x: [  80.          109.65510732 3000.           20.        ]\n",
      "f1: 2.858828883750005, f2: 1.2267854266861882, x: [  79.99999999   97.3175612  2999.99999983   19.99999999]\n",
      "f1: 2.403692698416748, f2: 1.2456403828901714, x: [  80.           94.77256794 3000.           19.99999999]\n",
      "f1: 0.8678903618199493, f2: 1.3170345906261047, x: [  80.           85.62834264 2999.99999998   20.        ]\n",
      "f1: 1.9501801253125863, f2: 1.2653983199308845, x: [  80.           92.16678086 3000.           20.        ]\n",
      "f1: 1.5740963128703351, f2: 1.2825829837703036, x: [  80.           89.94864472 3000.           19.9999997 ]\n",
      "f1: -0.6474084297695494, f2: 1.4027114577735897, x: [  80.           75.52886624 2999.99999998   20.        ]\n",
      "f1: -0.12330708278674417, f2: 1.3710066761756432, x: [  80.           79.16788587 3000.           20.        ]\n",
      "f1: 0.7440130998159791, f2: 1.3233982414014758, x: [  80.           84.84783309 2999.99999984   19.99999999]\n",
      "f1: 1.6124799491112187, f2: 1.2807940067288972, x: [  80.           90.17753077 3000.           20.        ]\n",
      "f1: 5.0925755373478205, f2: 1.1459563465029543, x: [  79.99999995  108.94955686 3000.           20.        ]\n",
      "f1: 0.7565158709502805, f2: 1.3227513560859836, x: [  80.           84.92693436 2999.99999997   20.        ]\n",
      "f1: 2.4969055786021337, f2: 1.241702228410896, x: [  80.           95.29932257 3000.           19.99999998]\n",
      "f1: 2.413649221952589, f2: 1.2452177915664453, x: [  80.           94.82897275 3000.           20.        ]\n",
      "f1: 2.2470359588674644, f2: 1.2523514527853128, x: [  80.           93.88062878 3000.           19.99999999]\n",
      "f1: 3.846083923119523, f2: 1.1888638257175432, x: [  79.99996215  102.62127448 2999.99999999   20.        ]\n",
      "f1: 3.495065520900404, f2: 1.2019101503606686, x: [  80.          100.76754589 3000.           20.        ]\n",
      "f1: -0.6881251830111906, f2: 1.4052790675202098, x: [  79.99999999   75.2387879  3000.           20.        ]\n",
      "f1: 2.9575498474663253, f2: 1.2228163118782072, x: [  80.           97.86084647 3000.           20.        ]\n",
      "f1: -0.7047188206613896, f2: 1.4063300178745495, x: [  80.          75.1202486 3000.          20.       ]\n",
      "f1: 4.5070236892315405, f2: 1.1654842345587992, x: [  80.          106.02384918 3000.           20.        ]\n",
      "f1: 0.8532744003766335, f2: 1.317780174841954, x: [  80.           85.5366229  3000.           19.99999999]\n",
      "f1: 1.8614085515072218, f2: 1.2693867945105366, x: [  80.           91.64804809 3000.           19.99999998]\n",
      "f1: 1.4271893832484706, f2: 1.2896960334079188, x: [  80.           89.06859859 3000.           19.99688504]\n",
      "f1: 0.5609533695677953, f2: 1.3329909703569658, x: [  80.           83.68110772 3000.           19.99999992]\n",
      "f1: 3.645067814118771, f2: 1.1962786256115046, x: [  80.          101.56386092 3000.           20.        ]\n",
      "f1: 2.1304629437912213, f2: 1.2574228917894024, x: [  79.99996635   93.21134257 3000.           20.        ]\n",
      "f1: 3.3202511571453064, f2: 1.2085823488078964, x: [  80.          99.8314969 3000.          20.       ]\n",
      "f1: 0.18907319463231498, f2: 1.3532099379140758, x: [  79.99999853   81.25937425 3000.           20.        ]\n",
      "f1: 2.649758953982001, f2: 1.2353308814555775, x: [  80.           96.15686564 3000.           19.99999998]\n",
      "f1: 1.8487947488831609, f2: 1.2699568633231837, x: [  80.           91.57410145 3000.           20.        ]\n",
      "f1: 0.6464602735780962, f2: 1.3284817036829994, x: [  80.           84.2280947  3000.           19.99999999]\n",
      "f1: -0.49868165252691776, f2: 1.3934650393305412, x: [  80.           76.57910372 3000.           20.        ]\n",
      "f1: 4.8330433955788035, f2: 1.1544815946890512, x: [  79.99999992  107.66261592 3000.           20.        ]\n",
      "f1: 0.3110690079450196, f2: 1.3464652226025564, x: [  80.           82.06170564 3000.           19.99999998]\n",
      "f1: 1.4605593772267995, f2: 1.287922916040924, x: [  79.99999946   89.26817451 3000.           19.99999999]\n",
      "f1: 0.03125876200188008, f2: 1.3621039915606348, x: [  80.           80.20957218 2999.99999997   20.        ]\n",
      "f1: 1.9935379298340143, f2: 1.2634650708420416, x: [  79.99999996   92.41908194 3000.           20.        ]\n",
      "f1: 5.2756752208748114, f2: 1.1400613421513257, x: [  80.          109.84842218 3000.           20.        ]\n",
      "f1: -0.2922109752367617, f2: 1.3809611109731224, x: [  80.           78.01366638 3000.           20.        ]\n",
      "f1: 1.4873451615229083, f2: 1.2866565383048418, x: [  80.           89.42917894 3000.           20.        ]\n",
      "f1: 2.5170220649822297, f2: 1.240857616874051, x: [  79.99999999   95.41262115 2999.99999998   20.        ]\n",
      "f1: 2.923637867495256, f2: 1.2241750653518617, x: [  80.           97.67456139 3000.           20.        ]\n",
      "f1: 1.5295513274189243, f2: 1.2846693797587432, x: [  80.           89.68228518 3000.           20.        ]\n",
      "f1: 1.2328912302697077, f2: 1.2988541985988593, x: [  79.99999999   87.88780093 3000.           20.        ]\n",
      "f1: 0.627202772732517, f2: 1.3294928590650357, x: [  80.           84.10521499 3000.           20.        ]\n",
      "f1: -0.1718667029830083, f2: 1.3738439789212598, x: [  79.99999995   78.83778019 2999.99999997   20.        ]\n",
      "f1: 0.30500771332202414, f2: 1.3467976964158235, x: [  80.          82.0220276 3000.          20.       ]\n",
      "f1: 0.8391497915600925, f2: 1.3185020171120614, x: [  80.           85.447893   2999.99999999   20.        ]\n",
      "f1: 4.805984415409676, f2: 1.1553823413523334, x: [  80.          107.52755208 2999.99955086   19.99999999]\n",
      "f1: 0.49274902259444897, f2: 1.3366243149677064, x: [  80.           83.24222818 3000.           20.        ]\n",
      "f1: 2.8927911414663927, f2: 1.2254152574891706, x: [  80.           97.50480526 2999.99999996   20.        ]\n",
      "f1: -0.3901639224326327, f2: 1.3868460815149046, x: [  80.           77.33640491 3000.           20.        ]\n",
      "f1: 3.0053173855515394, f2: 1.2209111043578713, x: [  79.99996359   98.12261319 3000.           20.        ]\n",
      "f1: 4.805984415460886, f2: 1.1553821683649044, x: [  80.          107.52755208 3000.           19.99999999]\n",
      "f1: 0.6057483444505416, f2: 1.3306223715728207, x: [  80.          83.9681052 3000.          20.       ]\n",
      "f1: 4.4411430847570825, f2: 1.16774869343361, x: [  80.         105.6896084 3000.          20.       ]\n",
      "f1: 2.451100254000963, f2: 1.2436323971085703, x: [  80.           95.04083726 2999.99999999   19.99999999]\n",
      "f1: 0.6599257797136197, f2: 1.3277761768223442, x: [  80.           84.31391003 3000.           20.        ]\n",
      "f1: 0.6078553447810996, f2: 1.330511303765479, x: [  80.           83.98158041 3000.           20.        ]\n",
      "f1: -0.20178516368075378, f2: 1.3756018910979535, x: [  80.           78.63370626 3000.           20.        ]\n",
      "f1: 1.8546959213302971, f2: 1.2696900610332402, x: [  80.           91.60870367 3000.           20.        ]\n",
      "f1: -0.5784977390283709, f2: 1.398401668862573, x: [  80.           76.01728463 3000.           20.        ]\n",
      "f1: 0.005164207162004207, f2: 1.363593471414948, x: [  80.           80.03466091 2999.99999997   20.        ]\n",
      "f1: 0.19156107352499266, f2: 1.3530712443693564, x: [  80.           81.27581684 3000.           20.        ]\n",
      "f1: 3.9281765805410322, f2: 1.1858773368008941, x: [  80.          103.05003103 3000.           20.        ]\n",
      "f1: 4.691707600052765, f2: 1.159210468239899, x: [  79.99999992  106.95526228 3000.           20.        ]\n",
      "f1: 1.4210683001253335, f2: 1.2897974268545636, x: [  80.           89.03027098 3000.           20.        ]\n",
      "f1: 2.0140788687966116, f2: 1.262552541170099, x: [  80.           92.53837053 3000.           20.        ]\n",
      "f1: -0.4882654931339152, f2: 1.3928251076135423, x: [  80.           76.65211849 3000.           20.        ]\n",
      "f1: 4.765562637715636, f2: 1.156731678040418, x: [  80.          107.32547163 3000.           20.        ]\n",
      "f1: 4.515985246342071, f2: 1.1651772924323387, x: [  80.          106.06923365 3000.           20.        ]\n",
      "f1: 0.13707409414431956, f2: 1.3561195630471878, x: [  79.99997213   80.91494748 3000.           20.        ]\n",
      "f1: 4.205133738131851, f2: 1.1759782295270247, x: [  79.99999926  104.48345466 3000.           20.        ]\n",
      "f1: 1.4665867627007505, f2: 1.2876375908204294, x: [  80.           89.30442969 3000.           20.        ]\n",
      "f1: 2.6393585071328873, f2: 1.2357610411401496, x: [  80.           96.09875932 3000.           20.        ]\n",
      "f1: 0.8446480005296101, f2: 1.3182208741512258, x: [  80.           85.48244335 3000.           20.        ]\n",
      "f1: 0.11816857908098152, f2: 1.3571821426446848, x: [  79.99999692   80.78939296 2999.99972926   20.        ]\n",
      "f1: 0.20088746853737566, f2: 1.3525518307392808, x: [  80.           81.33742075 3000.           20.        ]\n",
      "f1: 4.566275321674153, f2: 1.1634596005490205, x: [  80.          106.32356086 2999.99999996   20.        ]\n",
      "f1: 3.7193433938816676, f2: 1.1935213788917567, x: [  80.          101.95586435 3000.           20.        ]\n",
      "f1: 1.5635949063388506, f2: 1.2830738349355602, x: [  80.           89.88592189 3000.           20.        ]\n",
      "f1: 2.865341367451879, f2: 1.2265223026145895, x: [  80.           97.35349437 3000.           20.        ]\n",
      "f1: 5.303792794870062, f2: 1.1391646262968647, x: [  80.          109.98580513 3000.           20.        ]\n",
      "f1: -0.034439631839487596, f2: 1.3658644730818108, x: [  80.           79.76846441 3000.           20.        ]\n",
      "f1: 3.7171795745218357, f2: 1.1936014317916372, x: [  79.99999849  101.94446452 3000.           20.        ]\n",
      "f1: 4.18480548596342, f2: 1.1766957968400178, x: [  80.          104.37891338 3000.           20.        ]\n",
      "f1: 2.279903987555057, f2: 1.2509336597024734, x: [  80.           94.0684669  3000.           19.99999999]\n",
      "f1: 0.8147390176940176, f2: 1.3197529309841523, x: [  79.9999798    85.29430952 3000.           20.        ]\n",
      "f1: 2.6232953487466686, f2: 1.2364263666555593, x: [  80.           96.00894689 3000.           20.        ]\n",
      "f1: -0.4240274640923696, f2: 1.3889002328539288, x: [  80.           77.10088342 3000.           20.        ]\n",
      "f1: 3.3632952295038825, f2: 1.206928384905017, x: [  79.99999993  100.06279027 2999.99999999   20.        ]\n",
      "f1: 4.129064935793615, f2: 1.1786706419512487, x: [  80.         104.0917185 3000.          20.       ]\n",
      "f1: 2.572702112508162, f2: 1.23852952449729, x: [  80.           95.72551899 3000.           20.        ]\n",
      "f1: 0.856488240010069, f2: 1.3176161116079397, x: [  80.           85.55679918 3000.           20.        ]\n",
      "f1: 1.96578604243779, f2: 1.264701370294074, x: [  79.99999984   92.25767177 3000.           20.        ]\n",
      "f1: 2.7847703439225415, f2: 1.229790524532966, x: [  79.99999997   96.90799971 2999.99999993   20.        ]\n",
      "f1: 3.5377963845814406, f2: 1.2002972108671295, x: [  80.          100.99503017 3000.           19.99999999]\n",
      "f1: -0.2170663632599028, f2: 1.3765026718731597, x: [  80.          78.5292685 3000.          20.       ]\n",
      "f1: 2.3327361588887987, f2: 1.2486655928152888, x: [  80.           94.36961498 3000.           20.        ]\n",
      "f1: 4.492147629618652, f2: 1.1659943265896333, x: [  80.          105.94846867 3000.           20.        ]\n",
      "f1: 2.0510784017264387, f2: 1.2609142468992807, x: [  80.           92.75285296 3000.           19.99999999]\n",
      "f1: 5.134330826560754, f2: 1.1446034757013792, x: [  79.99999677  109.15518941 3000.           19.99999996]\n",
      "f1: 0.26525017031856485, f2: 1.3489852615463895, x: [  80.           81.76129208 3000.           20.        ]\n",
      "f1: 1.7938648981264758, f2: 1.2724491550206474, x: [  80.           91.25138433 3000.           20.        ]\n",
      "f1: 0.5941284507732552, f2: 1.3312354514282718, x: [  80.           83.89375186 3000.           20.        ]\n",
      "f1: 1.3906496386667442, f2: 1.2912474208547735, x: [  80.           88.84658714 3000.           20.        ]\n",
      "f1: 4.419245291968996, f2: 1.1685055629525196, x: [  79.99990121  105.57820227 3000.           20.        ]\n",
      "f1: 1.9818250063314715, f2: 1.263986382569935, x: [  80.           92.3509919  3000.           19.99999995]\n",
      "f1: 3.2530360117422195, f2: 1.211179783887314, x: [  80.           99.46924678 3000.           20.        ]\n",
      "f1: -0.3928656692204072, f2: 1.3870095947843177, x: [  80.           77.31764056 3000.           20.        ]\n",
      "f1: 2.0424470316704273, f2: 1.2612958141008763, x: [  80.           92.70286219 3000.           19.99999999]\n",
      "f1: 2.464234318597508, f2: 1.2430779499520732, x: [  80.           95.11502629 3000.           20.        ]\n",
      "f1: 1.979498761222237, f2: 1.2640899982876792, x: [  79.99999997   92.33746283 3000.           20.        ]\n",
      "f1: 0.1991430021335785, f2: 1.3526489346792672, x: [  80.           81.32590152 3000.           20.        ]\n",
      "f1: -0.3599815580260125, f2: 1.3850238102200432, x: [  79.99999929   77.54572009 3000.           19.99999985]\n",
      "f1: 0.8041317852209614, f2: 1.3202972653035172, x: [  79.99999999   85.2275137  2999.99999993   20.        ]\n",
      "f1: 5.029944129705362, f2: 1.1479952682395125, x: [  80.          108.64038239 3000.           20.        ]\n",
      "f1: 1.4962991553049465, f2: 1.2862341270043347, x: [  79.99999974   89.48293476 2999.99999999   20.        ]\n",
      "f1: 5.148166214089512, f2: 1.144156288194904, x: [  80.          109.22324234 3000.           19.99999999]\n",
      "f1: 5.122411771721903, f2: 1.144989124552889, x: [  79.99999835  109.09653155 2999.99999997   20.        ]\n",
      "f1: 0.09448282738033788, f2: 1.3585175086833297, x: [  80.           80.63178848 3000.           19.99999999]\n",
      "f1: -0.6846740001064506, f2: 1.405060829855257, x: [  79.99999989   75.26341839 3000.           19.9999999 ]\n",
      "f1: 5.2800649940062705, f2: 1.1399211971860146, x: [  79.99999995  109.86988197 3000.           20.        ]\n",
      "f1: 0.0953370833927271, f2: 1.3584692666192155, x: [  79.99999985   80.637478   3000.           19.99999999]\n",
      "f1: 0.7335366290016142, f2: 1.323941091061, x: [  80.           84.78149478 2999.99999989   20.        ]\n",
      "f1: 4.348069706826958, f2: 1.170972006142954, x: [  79.99999999  105.21559731 3000.           20.        ]\n",
      "f1: -0.2120806665414905, f2: 1.376208563629463, x: [  80.           78.56335798 3000.           20.        ]\n",
      "f1: 3.678110645170359, f2: 1.1950494857193965, x: [  80.          101.73843725 3000.           19.99999997]\n",
      "f1: 1.6230532404518674, f2: 1.2803026465456966, x: [  80.           90.24047858 3000.           20.        ]\n",
      "f1: 4.082912558601867, f2: 1.1803138667252548, x: [  80.          103.85332423 3000.           19.99999999]\n",
      "f1: 1.696875887756978, f2: 1.2768890679084122, x: [  80.           90.67876215 3000.           19.99999999]\n",
      "f1: 4.024578254415484, f2: 1.182401389577788, x: [  80.         103.5512205 3000.          20.       ]\n",
      "f1: 3.1142111134115904, f2: 1.2166020699499804, x: [  80.           98.71685422 3000.           20.        ]\n",
      "f1: -0.20441368239633767, f2: 1.3757566949441749, x: [  80.           78.6157518  3000.           19.99999999]\n",
      "f1: -0.6567628606020051, f2: 1.4032999527481549, x: [  80.           75.46232114 2999.99999998   20.        ]\n",
      "f1: 4.785142591365101, f2: 1.1560773591392155, x: [  80.          107.42340513 3000.           19.99999997]\n",
      "f1: 3.5240046125481337, f2: 1.2008170395905904, x: [  79.99999991  100.92166352 3000.           20.        ]\n",
      "f1: 3.1884984005232786, f2: 1.2136907925954488, x: [  80.           99.12018116 3000.           20.        ]\n",
      "f1: 5.1280555624746915, f2: 1.144806439062385, x: [  80.         109.1243123 3000.          20.       ]\n",
      "f1: -0.21776004017700756, f2: 1.376543608954533, x: [  80.           78.52452434 3000.           20.        ]\n",
      "f1: 0.37329353607845084, f2: 1.3430677472096533, x: [  80.           82.4679317  2999.99999999   20.        ]\n",
      "f1: 3.0452325664935027, f2: 1.2193256139880821, x: [  80.           98.34086889 3000.           20.        ]\n",
      "f1: 2.854240597328993, f2: 1.2269709156133446, x: [  80.           97.29223697 3000.           20.        ]\n",
      "f1: 3.731473249472222, f2: 1.193073071696137, x: [  79.99999695  102.01973649 3000.           20.        ]\n",
      "f1: 3.306990044104869, f2: 1.2090933820216438, x: [  80.           99.76013146 3000.           20.        ]\n",
      "f1: 0.48753257553322915, f2: 1.3369035551870823, x: [  79.99999999   83.20856623 3000.           20.        ]\n",
      "f1: 1.9949177627528498, f2: 1.2634037054010783, x: [  80.           92.4271     3000.           19.99999997]\n",
      "f1: 5.272002107225841, f2: 1.1401786503213807, x: [  80.          109.83046259 3000.           20.        ]\n",
      "f1: 3.2440826769715474, f2: 1.2115271352685364, x: [  80.           99.42089395 3000.           20.        ]\n",
      "f1: 4.879844556589397, f2: 1.1529292491913374, x: [  80.          107.89582315 3000.           20.        ]\n",
      "f1: 4.1316785755621686, f2: 1.1785778047945463, x: [  80.          104.10520259 3000.           20.        ]\n",
      "f1: 2.5570462872977795, f2: 1.239182692294951, x: [  79.99999999   95.63764346 3000.           20.        ]\n",
      "f1: 1.9615740268168969, f2: 1.264889755291664, x: [  79.99997034   92.23312364 3000.           20.        ]\n",
      "f1: -0.1276518970287672, f2: 1.3712597438582528, x: [  80.           79.13840615 3000.           20.        ]\n",
      "f1: 2.432398170141244, f2: 1.244423281841885, x: [  79.99999999   94.93509666 3000.           20.        ]\n",
      "f1: 3.828034445671461, f2: 1.1895231826582322, x: [  80.          102.5268006  3000.           19.99999999]\n",
      "f1: 1.719903241347661, f2: 1.275830349579616, x: [  80.           90.81504227 3000.           20.        ]\n",
      "f1: 2.9941773316284435, f2: 1.2213542400650395, x: [  80.           98.06165107 3000.           19.9999997 ]\n",
      "f1: 4.006297751600974, f2: 1.183058013834612, x: [  80.          103.45636729 3000.           19.99999997]\n",
      "f1: 1.5783307856382995, f2: 1.2823852208000797, x: [  79.99999901   89.97392293 3000.           20.        ]\n",
      "f1: 0.10338673338745204, f2: 1.3580149411957634, x: [  80.           80.69107214 3000.           20.        ]\n",
      "f1: 0.37836026071632683, f2: 1.3427923538073543, x: [  80.           82.5009212  3000.           19.99999999]\n",
      "f1: 5.283585629215625, f2: 1.139808838537109, x: [  80.          109.88708994 3000.           20.        ]\n",
      "f1: 2.0987858128522876, f2: 1.2588120099259887, x: [  79.99999997   93.02867793 3000.           20.        ]\n",
      "f1: 1.1029903037329813, f2: 1.3052295230503097, x: [  80.           87.09039657 3000.           19.9999999 ]\n",
      "f1: 5.197600020552946, f2: 1.1425662422430443, x: [  80.          109.46612705 3000.           19.99993612]\n",
      "f1: 0.2601468529507825, f2: 1.3492669169012537, x: [  80.           81.72776358 3000.           19.99999997]\n",
      "f1: 4.123492834726104, f2: 1.1788686446872596, x: [  80.          104.06296554 3000.           19.99999997]\n",
      "f1: 4.0746402098416965, f2: 1.1806091765246667, x: [  80.         103.8105366 3000.          20.       ]\n",
      "f1: 2.675680679796153, f2: 1.234260872876048, x: [  80.           96.30153527 3000.           19.99999999]\n",
      "f1: 0.14468392633392288, f2: 1.355692050446859, x: [  80.           80.96546801 3000.           20.        ]\n",
      "f1: 1.1287799515149537, f2: 1.3039556192940949, x: [  80.           87.2492876  3000.           19.99999999]\n",
      "f1: 2.837272021690684, f2: 1.227657691022787, x: [  80.           97.19852464 3000.           20.        ]\n",
      "f1: 1.035970488933559, f2: 1.3085592504534052, x: [  80.           86.67612276 3000.           20.        ]\n",
      "f1: 1.8477579573096972, f2: 1.2700037574197964, x: [  80.           91.56802075 3000.           20.        ]\n",
      "f1: 2.7625969325874644, f2: 1.2306949135270397, x: [  80.           96.78503835 3000.           19.99999997]\n",
      "f1: 2.244753124312108, f2: 1.2524501193040394, x: [  79.99999997   93.86756857 3000.           20.        ]\n",
      "f1: 1.636296751193604, f2: 1.279688065442975, x: [  80.           90.31926159 3000.           20.        ]\n",
      "f1: 2.9772246475499027, f2: 1.2220302336347737, x: [  80.           97.96876159 3000.           20.        ]\n",
      "f1: -0.32039035345464956, f2: 1.3826455413637377, x: [  80.           77.81943383 3000.           20.        ]\n",
      "f1: 0.80413178499645, f2: 1.3202972656883496, x: [  79.99999999   85.2275137  2999.99999997   19.99999999]\n",
      "f1: 2.8617388285207364, f2: 1.2266678330218013, x: [  80.           97.33361869 3000.           20.        ]\n",
      "f1: 0.7070090838270257, f2: 1.3253189413209063, x: [  80.           84.61328651 3000.           20.        ]\n",
      "f1: 4.61313601850267, f2: 1.161866321560301, x: [  80.          106.5599987  3000.           19.99999998]\n",
      "f1: 2.942829395232539, f2: 1.2234055175096745, x: [  80.           97.78002777 3000.           20.        ]\n",
      "f1: 0.22076906830993157, f2: 1.3514467773794068, x: [  80.           81.46858975 3000.           19.99999998]\n",
      "f1: -0.12143106771124595, f2: 1.3708974543372816, x: [  80.           79.18061131 3000.           20.        ]\n",
      "f1: 3.293086728655765, f2: 1.2096299129928154, x: [  80.          99.6852551 3000.          20.       ]\n",
      "f1: 0.8373388367481889, f2: 1.3185946607511565, x: [  80.           85.43651003 3000.           20.        ]\n",
      "f1: 0.027136065648183074, f2: 1.3623389549999456, x: [  80.           80.18196321 3000.           20.        ]\n",
      "f1: -0.6128635594111775, f2: 1.4005453866995263, x: [  80.           75.77410348 3000.           19.99999999]\n",
      "f1: 4.2051829539363155, f2: 1.1759764881280634, x: [  79.99999979  104.48370804 3000.           20.        ]\n",
      "f1: -0.2670619367985036, f2: 1.379463605864767, x: [  80.           78.18660418 3000.           20.        ]\n",
      "f1: -0.5543603133412932, f2: 1.3969025704029163, x: [  80.           76.18762305 2999.99999997   20.        ]\n",
      "f1: 4.232948192814475, f2: 1.174998660029424, x: [  80.          104.62632704 3000.           19.99999999]\n",
      "f1: 1.3591461431796885, f2: 1.292754775963427, x: [  80.           88.65595132 3000.           20.        ]\n",
      "f1: 5.0820347293909345, f2: 1.1462986850610046, x: [  80.          108.89758455 3000.           20.        ]\n",
      "f1: 4.181680107697994, f2: 1.176806255248779, x: [  79.99999985  104.36283131 3000.           19.99999984]\n",
      "f1: -0.594364810002458, f2: 1.399390074005944, x: [  80.           75.90510208 2999.99999998   20.        ]\n",
      "f1: 1.67218769045051, f2: 1.2780273416354122, x: [  80.           90.53242496 3000.           20.        ]\n",
      "f1: 4.520446102420192, f2: 1.165024602916428, x: [  79.99999976  106.09181758 2999.99999999   20.        ]\n",
      "f1: 3.618985980619599, f2: 1.197251710003199, x: [  80.         101.4258497 3000.          20.       ]\n",
      "f1: 2.9974504394605535, f2: 1.22122406372949, x: [  79.99998223   98.07956063 3000.           19.99999996]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAr8AAAIQCAYAAACIUwbVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABIL0lEQVR4nO3dd3hUVcLH8d9MAoEACb1pQCEUlQ4iUiQixRXUXdRdZEVAV8VG0Vc3FgQVxF0VscDC2igKrmAFdldAiqCICtKUDlnpnUwKmSGZef+4GgmkzZ07mXK/n+eZRzL3nvP8zPvu+tvruec4fD6fTwAAAIANOEMdAAAAACgrlF8AAADYBuUXAAAAtkH5BQAAgG1QfgEAAGAblF8AAADYBuUXAAAAthEb6gDhzuv16sCBA6pSpYocDkeo4wAAAOAcPp9PGRkZql+/vpzO4p/tUn5LcODAASUlJYU6BgAAAEqwd+9eXXjhhcXeQ/ktQZUqVSQZv8yEhIQQpwEAAMC5XC6XkpKS8ntbcSi/Jfh1qUNCQgLlFwAAIIyVZokqL7wBAADANii/AAAAsA3KLwAAAGyD8gsAAADboPwCAADANii/AAAAsA3KLwAAAGyD8gsAAADboPwCAADANii/AAAAsA3KLwAAAGyD8gsAAADboPwCAADANmJDHQBnSU+X/vUvac8eqUYN6Y9/lBo0CHUqAACAqEH5DRfTpkkPPSSdPi2VKyd5PNIjj0g33CDNm2d8BwAAgICw7CEc/Otf0rBhxp99PqP4/uqzz6Q6dSSvNzTZAAAAogjlN9R8Pumpp6T4eOnMmcLvOXlSqlyZAgwAABAgym+obdokbd8uZWcXLL916kgOx28/nz5tfAcAAADTKL+hlp5u/PXsolulinT4cMHvJOnYMemSS8ouGwAAQJSh/IZa48bGX30+4681akgZGZLTKVWseP79W7dKV15ZdvkAAACiCOU31OrXl9q1++3nkyd/K755eYWP+eYb6aqryiYfAABAFKH8hoN33/3tz16v8cnKknJyih6zcqWUkhL0aAAAANGE8hsOLrlEeuUV/8etWCENGWJ5HAAAgGhF+Q0Xw4dLgwf7P27GDGOrNAAAAJSI8htOpk+XBg3yf9yzz0rPPGN5HAAAgGgTduXX4/EoNTVVsbGxSktLK/W4BQsWyOFwaPr06edd+/jjj3X55ZerW7du6t69u3788UfrAltt5kypf3//x40ZYxyHDAAAgCKFVflNS0tT9+7ddfDgQeUVtdNBIbKysvTkk08Weu3bb7/V4MGDNXv2bK1cuVJ33nmn+vTpo4yMDKtiW+/DD6Vevfwf9+KL0vjx1ucBAACIEmFVfjMzMzVr1iwNHTrUr3FPPfWU7r333kKvPf/88+rbt6+aNGkiSbrtttuUm5tb6BPisLJokdSsmf/jnnzSeHoMAACA84RV+W3RooWSk5P9GvPDDz/o22+/1d13313o9S+++EIdOnTI/9npdKp9+/ZasmRJQFnLxNat5o40HjxY+ugj6/MAAABEuLAqv/7yer26//77NXnyZDnOPQpY0vHjx+VyuVTnnAJZt25d7dmzp9A53W63XC5XgU9IHTpkrgDfdJP01VfW5wEAAIhgEV1+X3/9dXXt2lWtWrUq9Hp2drYkKS4ursD3cXFx+dfONWHCBCUmJuZ/kpKSrA1txsGDUs2a/o/r2lXavdv6PAAAABEqYsvvvn379MYbb2js2LFF3hMfHy/JeJp7NrfbnX/tXI899pjS09PzP3v37rUss2kOh3T4sHROiS+V5GQKMAAAwC9iQx3ArMWLF8vhcOi6664r8P3zzz+v6dOna9y4ceratasSExN1+PDhAvccOnRIjRo1KnTeuLi4854UhwWnU0pPlypU8G+czyc1bmx++QQAAEAUidjyO3To0PN2hXA4HEpNTdWQs4787dGjh9auXZv/s8/n07p16/TEE0+UVVTrxMVJGRlSlSr+j61bVzpyRKpVy/pcAAAAESKilj0MHDhQg/w8AS01NVULFy7Uzp07JUnvvfeeYmJiNNjMUcLhoHJl6cQJc2MvuEAqYq0zAACAHYTVk1+Px6PevXvr1KlTkqQBAwYoKSlJc+fOlSTl5OTI6Ty/rz///PP673//m//n6dOna/ny5ZKkjh07avr06RowYIAqVqwop9Opzz//XFXMPD0NF9WqSQcOSPXr+zfuzBkpIcEozwkJwckGAAAQxhw+n88X6hDhzOVyKTExUenp6UoIt8K4Y4fUtKm5sZmZUqVK1uYBAAAIAX/6WkQte8A5mjQxngAXssdxiapUkXJyrM8EAAAQxii/ka5ePWnTJv/H+XzG+uEzZ6zPBAAAEKYov9Hgssuks3a0KLW8PGPpQ26u9ZkAAADCEOU3WrRrJ33xhf/jzpwxCnBenvWZAAAAwgzlN5r06CF99ZX/4zweKTFR8nqtzwQAABBGKL/RpnNnad48/8dlZUkNGxprgQEAAKIU5Tca3XST9PLL/o/bt89YP0wBBgAAUYryG61GjpTMHOG8ZYuUnEwBBgAAUYnyG83GjZPGjvV/3O7dUrNmlscBAAAINcpvtBszRnrsMf/H7dgh1a1rfR4AAIAQovzawXPPSffe6/+4w4elpCTr8wAAAIQI5dcupkwx1gH7a98+qVMny+MAAACEAuXXTl5+WXr++eLvqVDh/O/WrJGuuio4mQAAAMoQ5ddu/vpXafz4wq+VLy/l5BR+beVKqWXL4OUCAAAoA5RfO3r8cWnEiPO/93iKH7d5s3TRRUGJBAAAUBYov3Y1aZL00EP+j/vf/6SmTS2PAwAAUBYov3b20ktS377+j9uxQ2rRwvo8AAAAQUb5tbsFC6T+/Uu+Lza24M8//ihdeWVwMgEAAAQJ5RfShx9Kw4cXfb1cOSk39/zvv/lGat06eLkAAAAsRvmF4ZVXpPvvP//72FjpzJmix23cyEEYAAAgYlB+8ZvXX5d+//uC3xX2xPdc+/ZJDRoEJRIAAICVKL8o6OOPpW7d/B+3d6904YXW5wEAALAQ5Rfn+/JLqWdP/8ft388aYAAAENYovyjc4sVSnz7+j9u4UerXz/o8AAAAFqD8omj//a90yy3+j1u4UGrb1vo8AAAAAaL8ongffCBdd53/49avl2rWtDwOAABAICi/KNnChVK7dv6PO35cqlrV8jgAAABmUX5ROmvXSl26+D8uPV2qVs36PAAAACZQflF6q1ZJHTr4P+7UKalWLcnnszwSAACAPyi/8M9330n9+/s/7tgx4wkwBRgAAIQQ5Rf++/BD6a9/9X9cerpUqRIFGAAAhAzlF+Y8/7w0dKj/406fNl6C83otjwQAAFASyi/Me/ttqWtX/8e5XMYaYAowAAAoY5RfBGblSnO7QJw4IZUvL+XmWp8JAACgCJRfBG7VKunaa/0fl5cnlStnLIUAAAAoA5RfWOM//5Fuvtnc2MqVJbfb2jwAAACFoPzCOnPnSrfe6v84r1eqXZslEAAAIOgov7DW7NnS9dcXf4/Dcf53Lpd0wQUsgQAAAEFF+YX1PvtMuu++oq/7fIUX4CNHpBo1jBPhAAAAgoDyi+CYPFl67rnCrzmdRR90cfq0UYCPHw9eNgAAYFuUXwTPY49JDz10/vcl7e/r9Uo1a0q7dgUnFwAAsC3KL4LrpZek2283NzY5Wdq+3do8AADA1ii/CL4ZM6TUVHNjmzWTVq+2Ng8AALAtyi/KxoQJ0qefmhvbubP07bfW5gEAALZE+UXZueEGac0ac2OvuEJatMjaPAAAwHYovyhbHTuaL7F9+kgLFlibBwAA2ArlF2WvVy9p2TJzY6+/Xpo3z9o8AADANii/CI2UFPNPgG+5RXrjDUvjAAAAe6D8InR69ZJWrTI39u67pZEjLY0DAACiH+UXodWli/mX4F55RXrgAWvzAACAqEb5Reh17Cht2WJu7OTJ0qBB1uYBAABRi/KL8NC8uXTokLmx774r9e1rbR4AABCVKL8IH3XqSCdPSuXK+T/23/+WrrrK+kwAACCqUH4RXqpWNQpwxYr+j125Umra1PJIAAAgelB+EX4qVZLS06X4eP/H7tghValifSYAABAVKL8IT+XKGQW4QgX/x2ZmGgXa67U+FwAAiGiUX4Sv2FgpK8vck9zsbKlWLSkvz/pcAAAgYlF+Ed6cTuMJcO3a/o89ccIYd+aM9bkAAEBEovwi/Dkc0uHD0kUX+T/2xAnj5blTp6xOBQAAIhDlF5Fjzx6pZUv/x+XlSdWrS0ePWp8JAABEFMovIsvGjdIVV/g/zuczlkD88IP1mQAAQMSg/CLyfPONdNll5sa2a2cUaAAAYEuUX0SmzZula64xN7Z1a+m116zNAwAAIgLlF5FryRLpr381N3b4cOmhh6zNAwAAwh7lF5Ht+eelDz80N/bll6V77rE2DwAACGuUX0S+/v2lyZPNjf3nP6Wbb7Y2DwAACFthV349Ho9SU1MVGxurtLS0Yu/98ssv1b9/f6WkpKhbt25q2bKlXnnllQL3DBkyRJ06dVJKSkr+57777gvi3wFC4r77pE8+MTf2ww+lzp0tjQMAAMJTbKgDnC0tLU233nqrmjZtqrxSHEs7e/ZstWnTRk899ZQkacOGDWrXrp0aN26sfv365d/3/vvv6yIzByQgstx4o7RihdS9u/9jV6+WOnUydpIAAABRK6zKb2ZmpmbNmqV9+/Zp5syZJd4/fPhwJSUl5f/cunVrVa1aVTt37gxmTISzq66SNmwwdnTw15o1xl7AR45YnwsAAISFsCq/LVq0kCTt27evVPdfeuml+X/2er166623FBcXp1tuuSUo+RAhWrUyjkOuU8f/sUePShUqSNnZkjPsVgUBAIAAhVX5NWvcuHF67bXXVLNmTS1atEgXXHBBgesTJkzQtm3blJubq9atW+upp55SnSKKkdvtltvtzv/Z5XIFNTuCpHZt6cABqX59/8e63VJ8vJSRIZUrZ302AAAQMlHxaOvJJ5/UoUOHNHz4cHXv3l2bNm3Kv9a0aVNdddVVWrp0qZYtWya3261OnTopMzOz0LkmTJigxMTE/M/ZyyoQYerVkzIzJYfD/7Fut1S5sjEeAABEDYfP5/OFOsS5li9frquvvlp79uzx+0W1Ll26qH79+po7d26h110ul6pVq6apU6fqrrvuOu96YU9+k5KSlJ6eroSEBL+yIEzk5UmVKhmF1oydO6XGja3NBAAALONyuZSYmFiqvhbRT349Hs953zVv3lw//fRTkWMSEhJUq1Yt7dq1q9DrcXFxSkhIKPBBhIuJkXJyJLP/t0xOlrZvtzYTAAAIiYguv+3btz/vu4MHD6r+Wes8R4wYUeC62+3W8ePH1aBBg6DnQ5hJT5eaNjU3tlkz6euvrc0DAADKXESV34EDB2rQoEH5P2dkZGjKlCn5P69YsUKLFi3SHXfckf/d1KlT9f333+f/PG7cOFWrVo0dIexq2zapY0dzY7t0MX+UMgAACAthtduDx+NR7969derUKUnSgAEDlJSUlL9+NycnR86ztp967rnn9MYbb+jdd9+V0+mU2+3WW2+9pVtvvTX/nhdffFGjRo1SbGyssrOzVatWLS1btky1atUq0783hJE1a4wC/N13/o+9+Wbpqaekp5+2PhcAAAi6sHzhLZz4s4AaEebBB6XXXzc39ve/lz7+2NI4AADAHNu88AYE5LXXpBkzzI395BPpkkssjQMAAIKP8gt7u/126dNPzY3dulWqW9faPAAAIKgov8ANN0irVpkbe/iwVK2a5PVamwkAAAQF5ReQjJ0cjh41d5zxqVNSlSrmD9EAAABlhvIL/KpmTenECSk+3v+x2dnGuIMHrc8FAAAsQ/kFzla5snEYRpUq/o/1eqX69aVvv7U+FwAAsATlFzhXbKyxlKFqVXPjr7hCWrjQykQAAMAilF+gME6ndPKk+d0c+vWTZs60NhMAAAgY5RcozsGDUosW5sYOHixNmmRpHAAAEBjKL1CSTZuk224zN3bUKOnaa63NAwAATKP8AqUxa5b04ovmxn7+uVS7trV5AACAKZRfoLQeftg41tiMo0eNnSQ4DAMAgJCi/AL+uPFG6YsvzI3NypIqVjT+CgAAQoLyC/irRw9pxw5zYz0e4wnwvn3WZgIAAKVC+QXMSE42DsOoUMHc+KQkDsMAACAEKL+AWQkJUmam1LChufFXXCH97W/WZgIAAMWi/AKBiImR0tKk5s3NjU9NlcaMsTQSAAAoGuUXsMKWLVKTJubGPvOMdPvt1uYBAACFovwCVtm+XerZ09zYWbOkCy+0Ng8AADgP5Rew0uLF0vjx5sbu3y+VLy/l5lqbCQAA5KP8AlZ7/HFpzhxzY8+ckcqVk06etDYTAACQRPkFgmPAAGnjRvPjq1eXtm61Lg8AAJBE+QWCp2VL6cCB0t3rLOQ/ipdcIm3ebG0mAABsjvILBFO9esZxxuXLF32P0yl5vYVfa9lSevbZ4GQDAMCGKL9AsMXHSzk5UuPGhV8vqvj+6qmnpPvvtz4XAAA2RPkFyoLDIe3caSxlMGPKFAowAAAWoPwCZemnn6ROncyNnTJFatRIOnrU2kwAANgI5Rcoa6tXS0OGmBu7Z4+xjnjfPksjAQBgF5RfIBTeeUeaOtXc2Lw8qUEDafduazMBAGADlF8gVO65x9gLuLBtzkri8xkv0M2YYX0uAACiGOUXCKWWLaXsbONUNzOGDJH++ldLIwEAEM0ov0CoxcVJmZlSQoK58X//u9Srl7WZAACIUpRfIByULy+lp0v9+pkbv2SJ1LSptZkAAIhClF8gnMyfb/5FuB07jJ0g8vKszQQAQBSh/ALh5p57pPffNzf20CFj+cSpU5ZGAgAgWlB+gXD0pz9JS5eaG5udLVWrJn36qbWZAACIApRfIFxdfbW0dav58b//vTR2rFVpAACICpRfIJw1ayYdOWJuL2BJevpp6fbbrc0EAEAEo/wC4a5WLcnjkapUMTd+1izp4outzQQAQISi/AKRICZGcrmkSy4xNz4tzThIw+OxNBYAAJGG8gtEkp9+ku6+29zY3FzjQI39+63NBABABKH8ApFm2jRp7lzz4y+8UPrxR+vyAAAQQSi/QCS6+Wbphx/Mj2/RQnrzTevyAAAQISi/QKRq00bavt38+Lvukvr2tSwOAACRgPILRLImTSS3W6pY0dz4f/9b6tDB2kwAAIQxyi8Q6cqXN051M7ud2dq1Ur16RokGACDKUX6BaLF7t3TllebGHjokVapkzAEAQBSj/ALR5OuvpXvvNTc2L09q3FiaP9/aTAAAhBHKLxBtpkyRPv3U/PgbbpD+7/+sywMAQBih/ALR6IYbpPR08y/CvfQSL8IBAKIS5ReIVgkJxpHIiYnmxq9da4w9c8baXAAAhBDlF4hmsbHSqVNS69bmxrtcxpHI//ufpbEAAAgVyi9gB+vXS+PGmRvr80kXXSRt2mRlIgAAQoLyC9jFE09IH3xQ8n3lyxf+fatW0gsvWJsJAIAyRvkF7OSWW4wnuA5H4dfLl5c8nqLHP/qo+b2EAQAIA5RfwG5atJCysqQKFc6/Vlzx/dU33xgv03m91mcDACDIKL+AHVWsKGVmGscam5GRIZUrJx0+bG0uAACCjPIL2FVMjHTggNSzp7nxXq9Ut660caO1uQAACCLKL2B3ixdLTz9tfnzr1oGNBwCgDFF+AUhPPSUtXGh+/Nix0qWXWhYHAIBgofwCMFx3nbGWt3Jlc+O3bJEqVZLy8qzNBQCAhSi/AH5TubKUni7Vrm1ufHa2sYvE0aPW5gIAwCKUXwAFOZ3GLg7t2pkbn5trlOcvvrA2FwAAFqD8Aijc2rXSffeZH9+zp5Saal0eAAAsQPkFULTJk6UlS8yP/9vfjN0gAAAIE5RfAMW75hpjHXBcnLnxGzdKVapIbre1uQAAMIHyC6BkCQnGy2zVqpkbn5lpvAi3YYO1uQAA8FPYlV+Px6PU1FTFxsYqLS2t2Hu//PJL9e/fXykpKerWrZtatmypV1555bz7pk2bpvbt26tLly7q27ev9u/fH6T0QBRzOqUTJ6SWLc3P0aaN9Pe/WxYJAAB/hVX5TUtLU/fu3XXw4EHllWKv0NmzZ6tNmzZavny5Vq5cqXfffVcPPfSQFixYkH/PRx99pKefflqff/65vvrqK11xxRXq16+fvF5vMP9WgOi1caM0erT58X/9q/kjlQEACFBYld/MzEzNmjVLQ4cOLdX9w4cP16hRo/J/bt26tapWraqdO3fmfzdu3DgNHjxYNWvWlCSNGDFCmzdv1sJATrMC7O6ZZ6RNmySHw9z4L76QLrhA8vmszQUAQAnCqvy2aNFCycnJpb7/0ksvVZUqVSRJXq9Xb7zxhuLi4nTLLbdIkk6cOKEffvhBHTp0yB+TmJiopk2bakkRb7C73W65XK4CHwCFaNHCOBHul/8M+u3AAeNQjWPHrM0FAEAxwqr8mjVu3DjVq1dPkyZN0qJFi3TBBRdIkvbs2SNJqlOnToH769atm3/tXBMmTFBiYmL+JykpKbjhgUhWqZLkcklNmhR/X1FPiLOzpVq1pA8/tD4bAACFiIry++STT+rQoUMaPny4unfvrk2bNkmSsrOzJUlx52zRFBcXl3/tXI899pjS09PzP3v37g1ueCAabN8u/fJvXApV0vKGm282PgAABFlUlF9Jcjgcuueee9S8eXM988wzkqT4+HhJxlKGs7nd7vxr54qLi1NCQkKBD4BS+OAD6Z13zI//8EMpKYl1wACAoIro8uvxeM77rnnz5vrpp58kSY0aNZIkHT58uMA9hw4dyr8GwEJDhkhbtpgfv2+fFB9vLKUAACAIIrr8tm/f/rzvDh48qPr160uSqlWrprZt22rt2rX5110ul7Zv366ebLUEBEfz5lJOjlSxornxOTlS9erS7t3W5gIAQBFWfgcOHKhBgwbl/5yRkaEpU6bk/7xixQotWrRId9xxR/53Tz75pGbMmKHjx49Lkl599VW1aNFC1113XdkFB+wmLs54ma1Vq+LvK6og5+VJjRtLEyZYnw0AYGuxoQ5wNo/Ho969e+vUqVOSpAEDBigpKUlz586VJOXk5Mjp/K2vP/fcc3rjjTf07rvvyul0yu1266233tKtt96af0///v115MgR9erVSxUqVFC1atU0f/78AvMACJING6TnnpOeeKLw67m5xY9//HFpwQLpq6+szwYAsCWHz8fbJcVxuVxKTExUeno6L78BZu3YITVtan58YqK0d6/5PYUBAFHNn77G408AwdekiXTqlBRr8l82padLCQnSl19aGgsAYD+UXwBlIzFR8nikX15INaV7d+nhh63LBACwHcovgLLjcEj790tnvbjqt4kTpS5drMsEALAVyi+AsjdzpvEiW1HHHpfk66+NnSJycqzNBQCIepRfAKHRt6+UmSlVq2Zu/K97CU+caG0uAEBUo/wCCJ34eOnYMWNPX7MeflgaMMC6TACAqEb5BRBaTqe0c6d0//3m5/jXv6SWLa3LBACIWpRfAOHh9deNdcBmbd4sxcRIR45YlwkAEHUovwDCR9++Ulqa+RfhvF6pTh3pl1MhAQA4F+UXQHhp2FA6c0aqV8/8HH/8ozRsmHWZAABRg/ILIPzExEgHDgS2H/C0adIFFxhPgwEA+AXlF0D4mjlTevtt8+MPHJDKl5eOH7cuEwAgolF+AYS3oUOlvXuNXSHMyMuTataUFi+2NhcAICJRfgGEvwsvlDwe469m9e4t3XmndZkAABGJ8gsgMsTEGE+Ab73V/Bxvvy0lJEhut3W5AAARhfILILLMni1Nnmx+fEaGVKGC9N131mUCAEQMyi+AyHPffcbLbGb3A5akjh2lV1+1LhMAICJQfgFEpnr1pNxcqVEj83OMGCH1729dJgBA2KP8AohcTqe0a5d0++3m5/j4Y2M7tGPHrMsFAAhblF8AkW/GDOmrr8wvgzhzRqpVS3r/fWtzAQDCDuUXQHTo3Fk6fVqqX9/8HLfeKv35z9ZlAgCEHcovgOgRFyft3y/17Gl+jtmzpbp1jfXEAICoQ/kFEH0WL5YefdT8+MOHpXLlpA0brMsEAAgLlF8A0elvf5PWrAlsjjZtpIcftiQOACA8UH4BRK+OHY2X2QLZDm3iRKlpU8nnsy4XACBkKL8AoltsrLEd2kMPmZ9jxw5jGcThw9blAgCEBOUXgD289JI0fbr58Xl5xotw48ZZFgkAUPYovwDsY/Bg6ehRKSbG/ByjR0s9eliXCQBQpii/AOylZk1jG7O2bc3PsWyZlJgoZWdblwsAUCYovwDsad06Y0cIs1wuqVIl6bPPrMsEAAg6yi8A+3r0UeNltkDceKN0223W5AEABF3A5ff06dPav3//ed//+OOPgU4NAMGXnCx5PFJCgvk53nvPGO92W5cLABAUAZXfefPmqUmTJurbt69atWqlNWdtKD9o0KCAwwFAmShXTkpPD+wJbkaGFB8v/fyzdbkAAJYLqPyOGzdOa9eu1fr16/XOO+/ozjvv1OzZsyVJPjaEBxBpZs0yXmYzy+uVGjaUPvnEskgAAGuVuvw++uijysnJKfDdmTNnVKdOHUlS+/bt9eWXX2ratGl65pln5HA4rE0KAGUhJcV4Chwba36OP/xB6tLF2BsYABBWSl1+J02apPT0dEnSkCFDlJWVpdq1a2vjxo3591SvXl2LFy/Wli1bCnwPABElIcE4Fvnaa83P8fXXRoH+/nvrcgEAAlbq8lu/fn2tX79ekjRr1ixlZWVp1qxZql27doH7ypcvrzlz5mjFihWWBgWAMvef/0i/LOUy7fLLAztaGQBgqVKX34cffljXX3+9unXrJkl67733dODAASUmJhZ6f5cuXaxJCAChdOut0t69gS2DePllqUULY00wACCkHD4/3kzbuHGj5s+fr9GjR6tRo0ZKS0uTw+FQcnKyWrdurTZt2qh169b63e9+F8zMZcrlcikxMVHp6elKCGQrJACRr2VLafPm4u9xOKSi/ms1NlbaudN4KQ4AYBl/+ppf5fdXTZo00erVq1WpUiVt3LhR69evz/9s3rxZGRkZpsOHG8ovgAIefVR64YWS73M6i37S+9xz0mOPWZsLAGws6OW3OD6fL6p2eqD8AjjPwYPSpZdKp06Zn6NpU2nLFqMkAwAC4k9fs/y/daOp+AJAoerVk06ckP7yF/NzbN8uVa4sZWVZlwsAUCIeOQCAGQ6H9MYb0rRppR9TuXLBn0+fNr57+WVrswEAikT5BYBA3H23tHp1yffFx0uZmYVfe+ghKSmp6BflAACWofwCQKA6dZJyc6W6dQu/HhcnZWcXP8e+fVL58sZyCABA0FB+AcAKMTHGi3Bjxpx/ze0u3Ry5uVKzZtKQIZZGAwD8hvILAFYaO1Zav95YE2zWjBnGMoi8PKtSAQB+QfkFAKu1bi3l5Ej165fu/sK2O9u3TypXTvr2W2uzAYDNUX4BIBjKl5f275fuvbf4+4o7DMPnk664QrrvPuvzAYBNUX4BIJimTJE2bTp/m7NfFVV8z/aPfxjjc3OtzQYANkT5BYBga9FCcrmkhg3Nz5GVZSyD2LjRulwAYEOUXwAoCw6HlJYm3X57YPO0bi0NG2ZJJACwI8ovAJSlGTOMEhyIadOkWrWKPjQDAFAkyi8AlLWGDaUzZ6SEBPNzHDsmVakiLVpkXS4AsAHKLwCEQmyslJ5uHG0ciD59pJQUSyIBgB1QfgEglF56SdqwIbBDMVaskCpUMJ4GAwCKRfkFgFBr1cpYBnHBBebncLuNdcDz5lmXCwCiEOUXAMJBTIxxqtuQIYHNc8st0jXXWBIJAKIR5RcAwsk77xi7QZQrZ36OpUulSpWkQ4csiwUA0YLyCwDhpmFDYxnDlVeanyM7W6pXT3riCetyAUAUoPwCQDhyOKSvv5beeiuweZ57TqpZU/J4rMkFABGO8gsA4eyOO6QjR4zdHMw6ftwY//PP1uUCgAhF+QWAcFerlnT6tNSli/k5fD5jOUWvXtblAoAIRPkFgEixapU0a1ZgcyxZIlWsKGVkWJMJACIM5RcAIsltt0k5OVJSkvk5cnKMo5UDXU8MABGI8gsAkSYuzli/O2pUYPP85S9So0bGkggAsImwK78ej0epqamKjY1VWlpasfcuWbJEN9xwg3r06KFOnTrp2muv1caNGwvcM2TIEHXq1EkpKSn5n/vuuy+IfwcAUEYmTpR++imwPYH37JFiY415AMAGwqr8pqWlqXv37jp48KDy8vJKvH/YsGG6/vrrtXTpUn3zzTfq0KGDevbsqaNHjxa47/3339fy5cvzP1OmTAnW3wIAlK1LLjH2BG7SxPwcXq902WWBP0kGgAgQVuU3MzNTs2bN0tChQ0t1f4cOHXTnnXfm/zxy5EgdPXpUS5YsCVZEAAg/Doe0fbv08MOBzTNpklS1qnTypBWpACAshVX5bdGihZKTk0t9//vvvy+n87e/hQq/7IPpdrstzwYAYe/FF409fWvUMD9HerpUvbr0ySeWxQKAcBJW5TdQq1evVsWKFdWvX78C30+YMEEpKSnq2rWr7r//fh0+fLjIOdxut1wuV4EPAESM6tWlY8ekjh0Dm+cPf5A6d+ZlOABRJ2rKr8/n07hx4zR+/HjVrFkz//umTZvqqquu0tKlS7Vs2TK53W516tRJmZmZhc4zYcIEJSYm5n+SAtlOCABCZc0aac6cwOZYvVoqX17atMmaTAAQBhw+X/j9z/rly5fr6quv1p49e3TRRReVasyYMWO0e/duzSphA3iXy6Vq1app6tSpuuuuu8677na7CyybcLlcSkpKUnp6uhISEvz6+wCAkMvJkRo0kM55EdhvDz0kvfSSNZkAwGIul0uJiYml6mtR8eR36tSp+uGHH/TOO++UeG9CQoJq1aqlXbt2FXo9Li5OCQkJBT4AELEqVJCOHJEGDAhsnokTpUqVeBkOQMSL+PI7Z84czZs3Tx988IFiY2O1e/fuArs9jBgxosD9brdbx48fV4MGDco6KgCEzpw50pYtUkyM+Tmys401xS+8YF0uAChjEVV+Bw4cqEGDBuX/vGDBAqWmpuqJJ57Q5s2b9f3332vx4sVatWpV/j1Tp07V999/n//zuHHjVK1aNd1yyy1lmh0AQq55c+nMGeNFtkA8+ignwwGIWLGhDnA2j8ej3r1769SpU5KkAQMGKCkpSXPnzpUk5eTkFNjabOjQoTp27Jh69OhRYJ4xY8bk//nFF1/UqFGjFBsbq+zsbNWqVUvLli1TrVq1gv83BADhxuGQvvpKevNNqZD3Hkptzx5jScXWrdLFF1uXDwCCLCxfeAsn/iygBoCIkpUlXXih9MsDB9P+/nfpkUcsiQQAZtjuhTcAgAm/vsAWyBNgyVgGUaGC9PPP1uQCgCCi/AKA3f3zn8byhZJehostZqWc2y01bCiV8nh6AAgVyi8AQGrWTPJ4pLZti74nN7fkeaZPN3aE8HgsiwYAVqL8AgAMTqe0bp00eXJg85w8KcXFSWdtOwkA4YLyCwAo6L77jAJbrlzp7i9qOUSvXlKLFmyJBiCsUH4BAOerWtVYunDzzSXfW9xyiB9/NMrx1q2WRQOAQFB+AQBFmztX+t//pMTEwq+X5sQ4r1e65BKJw4UAhAHKLwCgeA0aGHsB33//+dfy8ko/z7x5Uny8lJ5uWTQA8BflFwBQOq+/Ln38cWBznD5tLKl48UVLIgGAvyi/AIDS+/3vpYwMYzeHQDzyiHEsMluiAShjlF8AgH8qV5ZycqQHHwxsnrQ0qWJFadEiS2IBQGlQfgEA5rz6qnTwoLGO1yyvV+rTR2rf3vgzAAQZ5RcAYF7dulJWltSjR2DzrFtn7ByxYIE1uQCgCJRfAEDgvvhCWrPGOCUuENdfL7VsycEYAIKG8gsAsEbHjsaBF506BTbP5s3G6XI7d1qTCwDOQvkFAFjH4ZBWr5Y++SSwefLypCZNpFGjLIkFAL+i/AIArHfjjZLbLSUlBTbPpElS9erS3r2WxAIAyi8AIDjKl5d+/tnYFSIQJ08ap8xNnGhNLgC2RvkFAATXgw8aRxrXqRPYPA8/LCUkSMeOWZMLgC1RfgEAwZeQIB06JA0fHtg8GRlSrVrS3LnW5AJgO5RfAEDZeeUVaetW48W4QPzxj8bxyG63NbkA2AblFwBQtpo1M3ZzuOSSwOZJS5MqVJD+8x9LYgGwB8ovAKDsORzSTz9Jy5YFPtd11xmFOjc38LkARD3KLwAgdFJSjKfAHTsGNs/27cbBGDNmWBILQPSi/AIAQsvpNI5GXrky8LXAQ4ZITZvyFBhAkSi/AIDw0LWrdPp06dcCF1WUd+wwngKzFhhAISi/AIDwERdnrAV+6aWS7/X5ir9+3XVSnz4l3wfAVii/AIDw89BDkssl1a8f2DyLFknx8cbOEAAgyi8AIFxVqSLt31+6p8DFyckx9gS+5hrJ67UmG4CIRfkFAIS3hx6Sjh6VatQIbJ6lS6XYWGnTJmtyAYhIlF8AQPirWVM6dkx65JHA5vH5pFatjK3VWAsM2BLlFwAQOf7+d2M3h9jYwOb57jtji7XVq63JBSBiUH4BAJElOVk6c0YaNCjwuTp3li6/nKfAgI1QfgEAkWnmTOPJrTPAf5R9/70xx4oV1uQCENYovwCAyNWpk3E88pAhgc+VkmIcsMFTYCCqUX4BAJHvnXek7dulqlUDm2frVikmRtq505JYAMIP5RcAEB2aNJFOngx8LbDPZ8zVvTtPgYEoRPkFAESXmTOlVasCXwv85ZdSxYrS7t3W5AIQFii/AIDo06WLlJtrrAkOhNstNW4s3XknT4GBKEH5BQBEJ4fD2A1iyZLA53r7bal8eenrrwOfC0BIUX4BANHtmmskr9c42S0QubnGE+VLLjHmAxCRKL8AgOjncEgbNhjreAO1davxFHjbtsDnAlDmKL8AAPvo1s14anvRRYHNk5cnNW9urClmLTAQUSi/AAB7cTikPXuMp8CB7gixZo0UGystXWpNNgBBR/kFANhTt27GOt7u3Yu+Jyam5Hm8XmNdcUqKMR+AsEb5BQDYl8MhLV8ubdwoVahw/vW8vNLPtWKFVK6c9OablsUDYD3KLwAALVtKp09LDzwQ+Fx33SUlJ0tnzgQ+FwDLUX4BAPjVa68ZuzmUKxfYPLt2GTtCjB1rSSwA1qH8AgBwtmbNJI/H2NO3OKV5We7pp40jkk+dsiQagMBRfgEAKMyqVdLmzVKlSoVfL+1BFzk5UrVq0u23W5cNgGmUXwAAinLZZVJmprGON1CzZknVq/MUGAgxyi8AACX55z+lffukypUDm+fkSeMp8MMPW5MLgN8ovwAAlMYFF0gZGdKECaUfU7Fi4d9PnGi8VLdpkzXZAJQa5RcAAH+kpkqHDxe9Fvhsp08XfS03V2rVSurb17psAEpE+QUAwF+1axtrgceMKfoeh6N0c/3738ZT4O++syYbgGJRfgEAMGvsWCkrS0pIOP+az1f6eXJzpY4dpSZNOCIZCDLKLwAAgYiPl9LTpVGjAp9r507jKfDs2YHPBaBQlF8AAKwwcaKUnV26tcAlLYn485+lhg2NPYIBWIryCwCAVSpWNNYCT55c/H2lWRLx88/GfM8+a002AJIovwAAWO+++6S8POkPfwh8rqeeki6+2CjVAAJG+QUAIBicTumjj6R580q/80NR0tKkKlWkkSOtSAbYGuUXAIBguukm4ynwVVcVf5+zFP9IfuUV44W4L7+0JhtgQ5RfAACCzeGQVqyQtmyRKlQo/B6vt3Rz5eZK3btLzZuXfgyAfJRfAADKSvPmxqlvf/xj4HNt2ybFxEhvvBH4XICNUH4BAChr//qXtGOHsZtDoO6+W0pMlFyuwOcCbIDyCwBAKCQnG/sCT5wY+Fwul1GA77wz8LmAKBd25dfj8Sg1NVWxsbFKS0sr9t4lS5bohhtuUI8ePdSpUydde+212rhx43n3TZs2Te3bt1eXLl3Ut29f7d+/P0jpAQDw06hRxhHJtWoFPtfbb0v16vEUGChGWJXftLQ0de/eXQcPHlReXl6J9w8bNkzXX3+9li5dqm+++UYdOnRQz549dfTo0fx7PvroIz399NP6/PPP9dVXX+mKK65Qv3795OUlAQBAuIiPl44ckb74wtjNIRCHDhlPgQcNKt1hGoDNhFX5zczM1KxZszR06NBS3d+hQwfdeda/4hk5cqSOHj2qJUuW5H83btw4DR48WDVr1pQkjRgxQps3b9bChQutDQ8AQKB69JDcbuOvgXr3Xal8eemsfyYCCLPy26JFCyUnJ5f6/vfff1/Os/ZFrPDL9jFut1uSdOLECf3www/q0KFD/j2JiYlq2rRpgYIMAEDYcDiMJ8A//FC6vX+Lk5sr9eolNWgg5eRYkw+IcGFVfgO1evVqVaxYUf369ZMk7dmzR5JUp06dAvfVrVs3/9q53G63XC5XgQ8AAGWuTRujvF55ZeBz7d1r7CwxdWrgcwERLmrKr8/n07hx4zR+/Pj8JQ7Z2dmSpLi4uAL3xsXF5V8714QJE5SYmJj/SUpKCm5wAACK4nBIX39tHG98zj/LTLn3XqlGDemsd2MAu4ma8jt27Fg1aNBAo0aNyv8uPj5e0m/LIH7ldrvzr53rscceU3p6ev5n7969wQsNAEBpNGxoLFu4//7A5zpxQqpdW7rjDl6Igy1FRfmdOnWqfvjhB73zzjsFvm/UqJEk6fDhwwW+P3ToUP61c8XFxSkhIaHABwCAsPD661J6ulSpUuBzvfOOFBsrzZ8f+FxABIn48jtnzhzNmzdPH3zwgWJjY7V79+78l9mqVaumtm3bau3atfn3u1wubd++XT179gxVZAAAzEtIkDIzjdJa2LZoMTGln8vrlW64wdhj+PRp6zICYSyiyu/AgQM1aNCg/J8XLFig1NRUPfHEE9q8ebO+//57LV68WKtWrcq/58knn9SMGTN0/PhxSdKrr76qFi1a6Lrrrivz/AAAWKZfP2NbtJtuKvj92fvkOxylm+vYMWOv4ddfty4fEKZiQx3gbB6PR71799apU6ckSQMGDFBSUpLmzp0rScrJySmwtdnQoUN17Ngx9ThnP8QxY8bk/7l///46cuSIevXqpQoVKqhatWqaP39+gXkAAIhIDoc0b560bZuxO8S525n5u6b3wQelkSOlb7+V2rWzKiUQVhw+H6vdi+NyuZSYmKj09HTW/wIAwtuQIdKMGdbM1bmztGpV6Z8eAyHkT1/j8ScAANFi+nTjmORz9rc35euvjTXFixcHPhcQRii/AABEk1q1pEOHpDffDPypbV6e1Lu3dOmlxhZpQBSg/AIAEI3uvFM6c0b63e8Cn2vLFuNwjCefDHwuIMQovwAARKuYGOnf/5Y2bDD29A3U+PHGUojlywOfCwgRyi8AANGuVSvjKXC/fkXfU9olErm50tVXS02aGH8GIgzlFwAAu5g/Xzp1Sqpf//xr/m7+tHOn8RR45EgrkgFlhvILAICdJCZK+/dbtyXaK68YSyq2bbNmPiDIKL8AANjR7bcbyxaSkwOfKy9Pat5cat/e/yfIQBmj/AIAYFcxMdKOHdKuXZIVBzmtW2fM+d57gc8FBAnlFwAAu2vUSEpPl6ZNC3wun0+67TapZk3p6NHA5wMsRvkFAACGu++WMjKkdu0Cn+v4cal2balrV8nrDXw+wCKUXwAA8JvKlaW1a429fJ0W1ISvvjKWQnz0UeBzARag/AIAgPN17268EHfTTdbMd9NN0oUXStnZ1swHmET5BQAAhXM4pHnzjCUMFSsGPt/+/VKlStKYMYHPBZhE+QUAAMWrXt14Yvv889bM98wzxgEZ8+dbMx/gB8ovAAAonb/+1Xh5rW3bwOfKzZVuuMHYFcLlCnw+oJQovwAAoPQcDmM/37Q0YwlDoI4fN06du/vuwOcCSoHyCwAA/NewoZSZKb32mjXzvfGGUYJ/+sma+YAiUH4BAIB5DzwgnTkjNWni37jCnhq7XNJll0nNmrEUAkFD+QUAAIGJjZW2b5fWrDFeZCuNrKyir23fbjwFHjjQODEOsBDlFwAAWKNjR8njkR5/vPj7Srtt2pw5Uvny0tdfB54N+AXlFwAAWGv8eGM3h6uvLvz66dPFj4+L++3PublSly7SxRdLJ05YlxG2RfkFAADWi4mRli41XmDz94AMt/v879LSpBo1pB49WAqBgFB+AQBA8FxyiXFARmm2MouJKfmeZcskp1N6++3As8GWKL8AACD4pk0zljs0bFj0PXl5pZ/vzjulypWln38OPBtshfILAADKRoUKxvKFjRulWrUCny8ryyjTrVqxFAKlRvkFAABlq2VL6cgR6R//sGa+TZuMpRDPPGPNfIhqlF8AABAaw4YZ64GbNrVmvjFjjH2GN260Zj5EJcovAAAInYoVpW3bpG+/NZZFBCo3V2rd2lgKceZM4PMh6lB+AQBA6F1+ufFC3IwZ1sy3aZNxQMaECdbMh6hB+QUAAOHj9tulnBwpKcma+R5/XGrWTNq1y5r5EPEovwAAILzExRlbmK1bJ8XGBj7f9u1ScrLUrZtRrGFrlF8AABCe2rY11u2OHWvNfKtWGWuMH3mErdFsjPILAADC25gxkscjXXyxNfO9+KJxmtz06dbMh4hC+QUAAOGvXDlp925p507jz4Hy+aShQ6X4eE6JsxnKLwAAiByNGxtPgV980Zr5fj1yuXNnyeu1Zk6ENcovAACIPA8/LOXlSR06WDPf6tXGE+W33rJmPoQtyi8AAIhMTqf03XfS0aNSzZqBz+f1Sn/5i3ThhdKBA4HPh7BE+QUAAJGtZk2jAK9fL9WuXfL9JZ0kt3+/dMEFRgk+ftySiAgflF8AABAdWreWDh82TnVzFlNxSrvX7/79RrHu0oX1wFGE8gsAAKJLaqrxItv111sz39dfG1ujTZtmzXwIKcovAACIPuXLS599Jv34Y9HLHByO4ueIiSn487BhUqVK0jffWJMRIUH5BQAA0evSS42nwKNHn3+tpFPe8vLO/y47W7rySikhQTpxwpqMKFOUXwAAEP2eecYos1dcYc18GRlSjRpGueao5IhC+QUAAPbgdBpLFg4flho1Kv7ekpZE/GrLFmPeqVMDz4cyQfkFAAD2Uru2tGuXtHKlVLfu+ddjYvx/mnvvvVJcnLRihTUZETSUXwAAYE9du0oHD56/i0Nha33Pdu6LcL/yeKSUFCkx0VgWgbBE+QUAAPZ2993G3r8NG5bu/pLKsctlvBD3hz+wHjgMUX4BAADi4qS0NGnrVik+3po5P/lEKldOmjnTmvlgCcovAADAr5o1k7KyjD2CizslrrTy8qTBg6WqVaUNGwKfDwGj/AIAAJzr+uul3FypTx//xhVVmNPTpTZtpObNjWURCBnKLwAAQGEcDum//5VOnjROdisNr7f469u2GS/EDRzIeuAQofwCAAAUp2pVKTNTWras6J0eJP+WScyZY9z/wAMBx4N/KL8AAAClkZJiLIWYPbvw6yU99S3M5MlGoV60KKBoKD3KLwAAgD9uvdUouh07lu7+kk6L83qNtcWNG0unTgUcD8Wj/AIAAPjL4ZDWrDF2hqhVq/h7S7u2d/duqVo1qX174wkzgoLyCwAAYFZ8vHTkiLE/cLVq1sy5bp2xP/Cf/sRLcUFA+QUAAAhUs2bSiRPSggVGcbXCBx8YL8W98II180ES5RcAAMA6fftKHo/04IPWzfnoo0ahXrLEujltjPILAABgtVdfNUpw167WzJebK/XqJV10ES/FBYjyCwAAEAzlykkrV0qHDlm3Hvh//zPm6tKFl+JMovwCAAAEU506xnrgd9/17yCM4nz9tVGuhw7lpTg/UX4BAADKwp//LOXlSePGlbz3b2lNn24U6smTrZnPBii/AAAAZemJJ4wSfPvt1s35wAPGtmtr1lg3Z5Si/AIAAJQ1h0OaMUNKT5fq1rVmztOnpU6dpPr1pePHrZkzClF+AQAAQiUhQTp4UFq7Vipf3po5Dx6UataUevTgpbhChF359Xg8Sk1NVWxsrNLS0kq83+v1auLEiapYsaKWL19+3vWxY8eqTZs2SklJyf/079/f+uAAAABmtWsnud3SK69YN+eyZcZLcXffbd2cUSCsym9aWpq6d++ugwcPKi8vr8T7T548qV69emnr1q3Kyckp8r5JkyZp+fLl+Z+PPvrIytgAAADWGD7c2L1h0CDr5nzjDSk2Vpo61bo5I1hYld/MzEzNmjVLQ4cOLdX9WVlZ+tvf/qbHH388yMkAAADK0MyZxktxV19tzXx5edK990oxMdJ771kzZ4QKq/LbokULJScnl/r+Cy+8UB06dAhiIgAAgBBxOqWlS6Vjx6x7Kc7rlW67TYqLk775xpo5I0xYld9gefvtt5WSkqIuXbpo8ODB2rVrV5H3ut1uuVyuAh8AAICQqVHDeIntyy+NNbxW8HikK6+U6tWT9u2zZs4IEfXlt0GDBmrbtq2WLFmilStX6uKLL1b79u21f//+Qu+fMGGCEhMT8z9JSUllnBgAAKAQ3boZpXXKFHOHZBQ25tAhKSlJatvWWBphA1Fffu+44w6NGjVKsbGxcjqdGj16tCpUqKApU6YUev9jjz2m9PT0/M/evXvLODEAAEAx7r3XWL5wzz3+jSvuGOT1642X4m6+OeqPS4768nuumJgYXXTRRUUufYiLi1NCQkKBDwAAQNiZOtXYx7dvX+vm/PBDowS/+aZ1c4aZqC+/I0aMOO+7AwcOqEGDBiFIAwAAYKGYGGnBAsnlkvzYNKBYXq90111SYqJUyBkKkS6iyu/AgQM1yM997z777DN99tln+T+/+eabOnr0qO644w6r4wEAAIRGlSrSjh3S9u1SnTr+j69Y8fzvXC5jq7Xq1aWffw48Y5iIDXWAs3k8HvXu3VunTp2SJA0YMEBJSUmaO3euJCknJ0dOZ8G+3r9/fx04cECSNHLkSFWtWlVffPGFYmJiJEnjx4/XpEmTNHHiRHk8HsXFxWnJkiVq3rx52f2NAQAAlIUmTYyX2D79VOrf33iKWxqnTxd97eRJqWFD4yjmjRuNP0cwh88X5auaA+RyuZSYmKj09HTW/wIAgMgyapQ0aVLx98THS9nZpZ+zZUtp3TpjbXCY8KevRdSyBwAAAPjh5ZeNLcy6dCn6Hn+KryRt2mTsN9y5c+mfLIcRyi8AAEA0czqlVauMomrVccmStHq18cLdU09ZN2cZoPwCAADYgcNhHJd86JDxEltJfnl/qkTPPmvM/cgjgeUrI5RfAAAAO6lTRzp+XPrqq8J3efiVvye+vfiiUYKLOEgsXFB+AQAA7KhzZ2O976JFUuXKJd9f2iOV77/fWGrx+eeB5QsSyi8AAICd9eolZWRIEycWv9TBnw3CfD7p2muN7dF27w48o4UovwAAADC2RcvNlYYNs27OjAypcWPp6aetmzNAlF8AAAD85h//MJZDNG5s3Zxjx0r//rd18wWA8gsAAICCKlaUdu40Tn674AJr5hw+3Jp5AkT5BQAAQOEqVJD27ZN+/FFKTCzdmHNfjPv15127pKwsa/OZQPkFAABA8S69VDp1Slq71jjdrTjFvRiXmWlpLDMovwAAACiddu0kj0f6299KP+bXMlyuXOkO1wgyyi8AAAD88+ijRqm97bbSj7n55pKfGpcByi8AAADMmTXLOAmuc+fi76tRQ3r99bLJVALKLwAAAMxzOo2jks+cka66quALbw6H1KePtG1bWCx5kKTYUAcAAABAFIiNlVasMJZD7N5t7OzQqFHpjk4uQ5RfAAAAWMfhsPaADIux7AEAAAC2QfkFAACAbVB+AQAAYBuUXwAAANgG5RcAAAC2QfkFAACAbVB+AQAAYBuUXwAAANgG5RcAAAC2QfkFAACAbVB+AQAAYBuUXwAAANgG5RcAAAC2ERvqAOHO5/NJklwuV4iTAAAAoDC/9rRfe1txKL8lyMjIkCQlJSWFOAkAAACKk5GRocTExGLvcfhKU5FtzOv16sCBA6pSpYoyMjKUlJSkvXv3KiEhIdTRbMHlcvE7DwF+72WP33lo8Hsve/zOQyPaf+8+n08ZGRmqX7++nM7iV/Xy5LcETqdTF154oSTJ4XBIkhISEqLy/3HCGb/z0OD3Xvb4nYcGv/eyx+88NKL5917SE99f8cIbAAAAbIPyCwAAANug/PohLi5OY8aMUVxcXKij2Aa/89Dg9172+J2HBr/3ssfvPDT4vf+GF94AAABgGzz5BQAAgG1QfgEAAGAblF8AAADYBuUXAAAAtkH5DcCOHTvUuXNnpaSkhDpK1Pr44491+eWXq1u3burevbt+/PHHUEeKeh6PR6mpqYqNjVVaWlqo49jCBx98oN69e+uaa67R5ZdfrltuuYXffRB9+umn+t3vfqdrrrlGXbt2Vbt27TRnzpxQx7KV119/XQ6HQ8uXLw91lKg2duxYtWnTRikpKfmf/v37hzpWyHHCm0mzZs3SlClTFBMTE+ooUevbb7/V4MGDtXbtWjVp0kQzZ85Unz59tGXLFlWpUiXU8aJSWlqabr31VjVt2lR5eXmhjmMbt912m+bPn68+ffrI6/VqyJAhuvbaa7Vhwwa2JQqCf/zjHxo4cKBuv/12SdL8+fN144036rLLLlOrVq1CnC76HThwQC+88EKoY9jGpEmTeEh3Dp78mlSjRg2tWLFCycnJoY4StZ5//nn17dtXTZo0kWQUhNzcXE2fPj20waJYZmamZs2apaFDh4Y6iq3ceOON6tOnjyTjSPXhw4dr27ZtWrduXYiTRafx48dr4MCB+T+npKTI5/Np9+7dIUxlHw8++KAef/zxUMeAjVF+TbruuutUvnz5UMeIal988YU6dOiQ/7PT6VT79u21ZMmSEKaKbi1atOB/0IXA3LlzC/xcoUIFSZLb7Q5FnKjXvn17xcYa/+LzzJkzevHFF3XppZeqZ8+eIU4W/ebPn69y5crl/489IBQovwhLx48fl8vlUp06dQp8X7duXe3ZsydEqYCysXr1atWvX19dunQJdZSodv/996tWrVpasmSJPv/8c1WuXDnUkaJaVlaWnnjiCb388suhjmIrb7/9tlJSUtSlSxcNHjxYu3btCnWkkKP8IixlZ2dL0nnrHePi4vKvAdHI7XbrhRde0Ouvv65y5cqFOk5Umzx5so4dO5ZfDA4ePBjqSFFt9OjRGjZsmOrVqxfqKLbRoEEDtW3bVkuWLNHKlSt18cUXq3379tq/f3+oo4UU5fcsqampcjgcxX62bt0a6pi2EB8fL+n8f+3rdrvzrwHR6J577tGf/vQn/eEPfwh1FFuIjY3Vs88+K6/Xq4kTJ4Y6TtRat26d1qxZo2HDhoU6iq3ccccdGjVqlGJjY+V0OjV69GhVqFBBU6ZMCXW0kGK3h7M8/vjjeuCBB4q9p27dumWUxt5q1KihxMREHT58uMD3hw4dUqNGjUKUCgiu1NRUxcfH69lnnw11lKjm8XgKvLPhdDrVtGlT/fTTTyFMFd0WLlyo06dPq0ePHpKknJwcSdLIkSNVtWpVvfnmm7xvUAZiYmJ00UUX2X7pA+X3LAkJCUpISAh1DPyiR48eWrt2bf7PPp9P69at0xNPPBHCVEBwPP/889q7d69mzZolSfn/v9++fftQxopK7dq10+bNmwt8d/DgQdZYB9Ho0aM1evTo/J/T0tJ08cUXsw1XkI0YMUKvvPJKge8OHDigq666KkSJwgPLHhC2UlNTtXDhQu3cuVOS9N577ykmJkaDBw8OcTLAWlOnTtW7776rBx98UOvWrdP333+v+fPna9OmTaGOFpV++uknLVy4MP/nd999V9u2beO/WxB1PvvsM3322Wf5P7/55ps6evSo7rjjjhCmCj2Hz+fzhTpEJPrss880ceJEbd26VTk5OWrTpo0GDRqkO++8M9TRosrHH3+s8ePHq2LFinI6nZoyZYouu+yyUMeKWh6PR71799apU6e0YcMGXXHFFUpKSjpvKy5YJyMjQ1WrVpXX6z3v2jvvvKMhQ4aUfago99prr2nOnDlyOp3yer1yOBx6/PHH1bdv31BHs4WRI0fqm2++0Zo1a9S6dWs1b95c77//fqhjRaXZs2frzTfflNfrlcfjUVxcnMaNG2f7f8tB+QUAAIBtsOwBAAAAtkH5BQAAgG1QfgEAAGAblF8AAADYBuUXAAAAtkH5BQAAgG1QfgEAAGAblF8AAADYBuUXAAAAtkH5BQAbee2119SwYUPFxsbq//7v/0IdBwDKHMcbA4BNbNiwQR06dNCnn36qtm3bKjExUfHx8aGOBQBlKjbUAQAAZWPBggXq2LGjrrvuulBHAYCQofwCgA0kJydr165dkiSHw6FBgwZp5syZIU4FAGWPZQ8AYANHjhzRlVdeqXvvvVe33XabKleurMqVK4c6FgCUOV54AwAbqFy5stLS0tS1a1fVrVtXgwYNUrVq1XTzzTeHOhoAlCnKLwDYwMaNGyVJLVu2lCSNGDGCZQ8AbInyCwA2sH79eiUnJ6tSpUqSpJSUFFWpUiXEqQCg7FF+AcAG1q9fr9atW4c6BgCEHOUXAGxg/fr1atOmTahjAEDIUX4BIMp5vV5t2rSJJ78AIPb5BYCo53Q6lZWVFeoYABAW2OcXAGyoZ8+e2rBhg7KyslS9enXNnTtXV155ZahjAUDQUX4BAABgG6z5BQAAgG1QfgEAAGAblF8AAADYBuUXAAAAtkH5BQAAgG1QfgEAAGAblF8AAADYBuUXAAAAtkH5BQAAgG1QfgEAAGAblF8AAADYxv8DDWC50VqKhc8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "from pymoo.termination import get_termination\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.visualization.scatter import Scatter\n",
    "\n",
    "# Define the objective functions\n",
    "def f1(x):\n",
    "    return 4.9e-5 * (x[1]**2 - x[0]**2) * (x[3] - 1)\n",
    "\n",
    "def f2(x):\n",
    "    return 9.82e6 * (x[1]**2 - x[0]**2) / (x[2] * x[3] * (x[1]**3 - x[0]**3))\n",
    "\n",
    "# Define the bounds\n",
    "bounds = [(55, 80), (75, 110), (1000, 3000), (2, 20)]\n",
    "\n",
    "# Define the problem class\n",
    "class MyProblem(ElementwiseProblem):\n",
    "    def __init__(self):\n",
    "        super().__init__(n_var=4, n_obj=2, n_constr=0, xl=np.array([55, 75, 1000, 2]), xu=np.array([80, 110, 3000, 20]))\n",
    "    \n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        out[\"F\"] = [f1(x), f2(x)]\n",
    "\n",
    "# Instantiate the problem\n",
    "problem = MyProblem()\n",
    "\n",
    "# Define the algorithm\n",
    "algorithm = NSGA2(pop_size=1000)\n",
    "\n",
    "# Define the termination criterion\n",
    "termination = get_termination(\"n_gen\", 1000)\n",
    "\n",
    "# Perform the optimization\n",
    "res = minimize(problem, algorithm, termination, seed=1, save_history=True, verbose=True)\n",
    "\n",
    "# Plot the Pareto front\n",
    "plot = Scatter()\n",
    "plot.add(res.F, facecolor=\"none\", edgecolor=\"red\")\n",
    "plot.show()\n",
    "\n",
    "# Print the results\n",
    "print(\"Pareto front points:\")\n",
    "for i in range(len(res.F)):\n",
    "    print(f\"f1: {res.F[i][0]}, f2: {res.F[i][1]}, x: {res.X[i]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TL_GP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
